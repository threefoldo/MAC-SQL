{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-SQL Workflow with Agent Tools and KeyValueMemory\n",
    "\n",
    "This notebook demonstrates a text-to-SQL workflow using:\n",
    "- **KeyValueMemory** to store the database schema and intermediate results\n",
    "- **Three Agent Tools**: schema_selector, sql_generator, sql_executor\n",
    "- **California Schools Database** as our example database\n",
    "\n",
    "The workflow processes a simple query through all three agents, with each agent reading from and writing to the shared memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import sqlite3\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from typing import Dict, Any, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append('../src')\n",
    "load_dotenv()\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Reduce noise from autogen\n",
    "logging.getLogger('autogen_core').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our modules\n",
    "from keyvalue_memory import KeyValueMemory\n",
    "from schema_reader import SchemaReader\n",
    "from memory_agent_tool import MemoryAgentTool\n",
    "from workflow_utils import extract_sql_from_text\n",
    "from sql_executor import SQLExecutor\n",
    "\n",
    "# Import AutoGen components\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load California Schools Database Schema\n",
    "\n",
    "First, we'll load the database schema using SchemaReader and store it in KeyValueMemory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:35:59,070 - root - INFO - [KeyValueMemory] Memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load json file from /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_tables.json\n",
      "\n",
      "Loading all database info...\n",
      "Found 11 databases in bird dataset\n",
      "Loaded schema for database: california_schools\n",
      "Schema length: 14313 characters\n",
      "Foreign keys: 2\n",
      "Database path: /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_databases/california_schools/california_schools.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Initialize memory and schema reader\n",
    "memory = KeyValueMemory(name=\"text_to_sql_memory\")\n",
    "\n",
    "# Clear memory for fresh start\n",
    "await memory.clear()\n",
    "\n",
    "# Load California Schools schema\n",
    "data_path = \"/home/norman/work/text-to-sql/MAC-SQL/data/bird\"\n",
    "tables_json_path = os.path.join(data_path, \"dev_tables.json\")\n",
    "\n",
    "schema_reader = SchemaReader(\n",
    "    data_path=data_path,\n",
    "    tables_json_path=tables_json_path,\n",
    "    dataset_name=\"bird\",\n",
    "    lazy=False\n",
    ")\n",
    "\n",
    "# Load and store the full database schema\n",
    "db_id = \"california_schools\"\n",
    "\n",
    "# Generate schema description (using all tables)\n",
    "selected_schema = {}  # Empty means select all\n",
    "schema_xml, fk_infos, chosen_schema = schema_reader.generate_schema_description(\n",
    "    db_id=db_id,\n",
    "    selected_schema=selected_schema,\n",
    "    use_gold_schema=False\n",
    ")\n",
    "\n",
    "# Store the full schema in memory\n",
    "await memory.set(\"full_database_schema\", schema_xml)\n",
    "await memory.set(\"database_id\", db_id)\n",
    "await memory.set(\"foreign_keys\", fk_infos)\n",
    "\n",
    "print(f\"Loaded schema for database: {db_id}\")\n",
    "print(f\"Schema length: {len(schema_xml)} characters\")\n",
    "print(f\"Foreign keys: {len(fk_infos)}\")\n",
    "\n",
    "# Also store the database path for execution\n",
    "db_path = os.path.join(data_path, \"dev_databases\", db_id, f\"{db_id}.sqlite\")\n",
    "await memory.set(\"database_path\", db_path)\n",
    "print(f\"Database path: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up Agent Memory Callbacks\n",
    "\n",
    "Define how each agent reads from and writes to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Selector callbacks\n",
    "async def schema_selector_reader(memory, task, cancellation_token):\n",
    "    \"\"\"Read the full database schema from memory.\"\"\"\n",
    "    print(\"\\n[SCHEMA SELECTOR READER] Starting...\")\n",
    "    context = {}\n",
    "    \n",
    "    # Read the full schema that we loaded\n",
    "    full_schema = await memory.get(\"full_database_schema\")\n",
    "    if full_schema:\n",
    "        context[\"full_database_schema\"] = full_schema\n",
    "        print(f\"[SCHEMA SELECTOR READER] Loaded full schema ({len(full_schema)} chars)\")\n",
    "    else:\n",
    "        print(\"[SCHEMA SELECTOR READER] No full schema found in memory\")\n",
    "    \n",
    "    db_id = await memory.get(\"database_id\")\n",
    "    if db_id:\n",
    "        context[\"database_id\"] = db_id\n",
    "        print(f\"[SCHEMA SELECTOR READER] Database ID: {db_id}\")\n",
    "    \n",
    "    print(\"[SCHEMA SELECTOR READER] Complete\\n\")\n",
    "    return context\n",
    "\n",
    "async def schema_selector_parser(memory, task, result, cancellation_token):\n",
    "    \"\"\"Store the selected schema subset.\"\"\"\n",
    "    print(\"\\n[SCHEMA SELECTOR PARSER] Starting...\")\n",
    "    if result.messages:\n",
    "        last_message = result.messages[-1].content\n",
    "        \n",
    "        # Extract selected schema\n",
    "        schema_match = re.search(r'<selected_schema>.*?</selected_schema>', last_message, re.DOTALL)\n",
    "        if schema_match:\n",
    "            selected_schema = schema_match.group()\n",
    "            await memory.set(\"selected_schema\", selected_schema)\n",
    "            print(f\"[SCHEMA SELECTOR PARSER] Stored selected schema ({len(selected_schema)} chars)\")\n",
    "        else:\n",
    "            # If no specific selection, use the full schema\n",
    "            full_schema = await memory.get(\"full_database_schema\")\n",
    "            await memory.set(\"selected_schema\", full_schema)\n",
    "            print(\"[SCHEMA SELECTOR PARSER] No selection found, using full schema\")\n",
    "    print(\"[SCHEMA SELECTOR PARSER] Complete\\n\")\n",
    "\n",
    "# SQL Generator callbacks\n",
    "async def sql_generator_reader(memory, task, cancellation_token):\n",
    "    \"\"\"Read the selected schema from memory.\"\"\"\n",
    "    print(\"\\n[SQL GENERATOR READER] Starting...\")\n",
    "    context = {}\n",
    "    \n",
    "    # Read the selected schema\n",
    "    selected_schema = await memory.get(\"selected_schema\")\n",
    "    if selected_schema:\n",
    "        context[\"database_schema\"] = selected_schema\n",
    "        print(f\"[SQL GENERATOR READER] Loaded selected schema ({len(selected_schema)} chars)\")\n",
    "    else:\n",
    "        print(\"[SQL GENERATOR READER] No selected schema found\")\n",
    "    \n",
    "    db_id = await memory.get(\"database_id\")\n",
    "    if db_id:\n",
    "        context[\"database_id\"] = db_id\n",
    "        print(f\"[SQL GENERATOR READER] Database ID: {db_id}\")\n",
    "    \n",
    "    print(\"[SQL GENERATOR READER] Complete\\n\")\n",
    "    return context\n",
    "\n",
    "async def sql_generator_parser(memory, task, result, cancellation_token):\n",
    "    \"\"\"Store the generated SQL and execute it.\"\"\"\n",
    "    print(\"\\n[SQL GENERATOR PARSER] Starting...\")\n",
    "    if result.messages:\n",
    "        last_message = result.messages[-1].content\n",
    "        \n",
    "        # Extract SQL\n",
    "        sql = extract_sql_from_text(last_message)\n",
    "        if sql:\n",
    "            await memory.set(\"generated_sql\", sql)\n",
    "            print(f\"[SQL GENERATOR PARSER] Extracted SQL: {sql}\")\n",
    "            \n",
    "            # Execute the SQL immediately\n",
    "            db_path = await memory.get(\"database_path\")\n",
    "            if db_path:\n",
    "                print(f\"[SQL GENERATOR PARSER] Executing SQL on database: {db_path}\")\n",
    "                try:\n",
    "                    conn = sqlite3.connect(db_path)\n",
    "                    cursor = conn.cursor()\n",
    "                    cursor.execute(sql)\n",
    "                    results = cursor.fetchall()\n",
    "                    columns = [desc[0] for desc in cursor.description] if cursor.description else []\n",
    "                    \n",
    "                    execution_result = {\n",
    "                        \"status\": \"success\",\n",
    "                        \"columns\": columns,\n",
    "                        \"data\": results,\n",
    "                        \"row_count\": len(results),\n",
    "                        \"sql\": sql\n",
    "                    }\n",
    "                    conn.close()\n",
    "                    \n",
    "                    await memory.set(\"execution_result\", execution_result)\n",
    "                    print(f\"[SQL GENERATOR PARSER] Execution successful - {len(results)} rows returned\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    execution_result = {\n",
    "                        \"status\": \"error\",\n",
    "                        \"error\": str(e),\n",
    "                        \"sql\": sql\n",
    "                    }\n",
    "                    await memory.set(\"execution_result\", execution_result)\n",
    "                    print(f\"[SQL GENERATOR PARSER] Execution error: {e}\")\n",
    "            else:\n",
    "                print(\"[SQL GENERATOR PARSER] No database path found\")\n",
    "        else:\n",
    "            print(\"[SQL GENERATOR PARSER] No SQL found in response\")\n",
    "    print(\"[SQL GENERATOR PARSER] Complete\\n\")\n",
    "\n",
    "# SQL Evaluator callbacks  \n",
    "async def sql_evaluator_reader(memory, task, cancellation_token):\n",
    "    \"\"\"Read SQL and execution results from memory. Execute SQL if not already executed.\"\"\"\n",
    "    print(\"\\n[SQL EVALUATOR READER] Starting...\")\n",
    "    context = {}\n",
    "    \n",
    "    sql = await memory.get(\"generated_sql\")\n",
    "    if sql:\n",
    "        context[\"sql_query\"] = sql\n",
    "        print(f\"[SQL EVALUATOR READER] Found SQL: {sql}\")\n",
    "    \n",
    "    execution_result = await memory.get(\"execution_result\")\n",
    "    if execution_result:\n",
    "        context[\"execution_result\"] = execution_result\n",
    "        print(f\"[SQL EVALUATOR READER] Found existing execution result: {execution_result['status']}\")\n",
    "    else:\n",
    "        # Execute SQL if not already executed\n",
    "        if sql:\n",
    "            db_path = await memory.get(\"database_path\")\n",
    "            if db_path:\n",
    "                print(f\"[SQL EVALUATOR READER] No execution result found - executing SQL now\")\n",
    "                executor = SQLExecutor(db_path)\n",
    "                \n",
    "                try:\n",
    "                    results, columns = executor.execute_sql(sql, get_columns=True)\n",
    "                    \n",
    "                    execution_result = {\n",
    "                        \"status\": \"success\",\n",
    "                        \"columns\": columns,\n",
    "                        \"data\": results,\n",
    "                        \"row_count\": len(results),\n",
    "                        \"sql\": sql\n",
    "                    }\n",
    "                    \n",
    "                    await memory.set(\"execution_result\", execution_result)\n",
    "                    context[\"execution_result\"] = execution_result\n",
    "                    print(f\"[SQL EVALUATOR READER] Execution successful - {len(results)} rows returned\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    execution_result = {\n",
    "                        \"status\": \"error\",\n",
    "                        \"error\": str(e),\n",
    "                        \"sql\": sql\n",
    "                    }\n",
    "                    await memory.set(\"execution_result\", execution_result)\n",
    "                    context[\"execution_result\"] = execution_result\n",
    "                    print(f\"[SQL EVALUATOR READER] Execution error: {e}\")\n",
    "        \n",
    "    # Also provide the original query for context\n",
    "    selected_schema = await memory.get(\"selected_schema\")\n",
    "    if selected_schema:\n",
    "        context[\"database_schema\"] = selected_schema\n",
    "        print(f\"[SQL EVALUATOR READER] Added schema context ({len(selected_schema)} chars)\")\n",
    "    \n",
    "    print(\"[SQL EVALUATOR READER] Complete\\n\")\n",
    "    return context\n",
    "\n",
    "async def sql_evaluator_parser(memory, task, result, cancellation_token):\n",
    "    \"\"\"Store evaluation results and suggestions.\"\"\"\n",
    "    print(\"\\n[SQL EVALUATOR PARSER] Starting...\")\n",
    "    if result.messages:\n",
    "        last_message = result.messages[-1].content\n",
    "        \n",
    "        # Store evaluation\n",
    "        await memory.set(\"evaluation_result\", last_message)\n",
    "        print(\"[SQL EVALUATOR PARSER] Stored evaluation text\")\n",
    "        \n",
    "        # Try to extract structured evaluation\n",
    "        try:\n",
    "            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', last_message)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "                structured_eval = json.loads(json_str)\n",
    "                await memory.set(\"evaluation_structured\", structured_eval)\n",
    "                print(\"[SQL EVALUATOR PARSER] Extracted and stored structured evaluation\")\n",
    "        except Exception as e:\n",
    "            print(f\"[SQL EVALUATOR PARSER] Could not extract structured evaluation: {e}\")\n",
    "    print(\"[SQL EVALUATOR PARSER] Complete\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Agents with Simple System Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model client\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.1,\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "# Create agents with simple, focused prompts\n",
    "schema_selector = AssistantAgent(\n",
    "    name=\"schema_selector\",\n",
    "    system_message=\"\"\"You select relevant tables and columns from a database schema for a given query.\n",
    "\n",
    "When given a full database schema and a user query:\n",
    "1. Identify which tables are needed to answer the query\n",
    "2. Select only the relevant columns from those tables\n",
    "3. Keep all foreign key relationships between selected tables\n",
    "4. Return your selection wrapped in <selected_schema> tags\n",
    "\n",
    "Be concise and only include what's necessary for the query.\"\"\",\n",
    "    model_client=model_client\n",
    ")\n",
    "\n",
    "sql_generator = AssistantAgent(\n",
    "    name=\"sql_generator\", \n",
    "    system_message=\"\"\"You generate SQL queries for SQLite databases.\n",
    "\n",
    "When given a database schema and a user query:\n",
    "1. Write a valid SQLite query that answers the question\n",
    "2. Use proper JOIN syntax when multiple tables are needed\n",
    "3. Return the SQL wrapped in ```sql code blocks\n",
    "\n",
    "Keep queries simple and correct.\"\"\",\n",
    "    model_client=model_client\n",
    ")\n",
    "\n",
    "sql_evaluator = AssistantAgent(\n",
    "    name=\"sql_evaluator\",\n",
    "    system_message=\"\"\"You evaluate SQL execution results and provide insights.\n",
    "\n",
    "When given a SQL query and its execution results:\n",
    "1. Analyze if the results correctly answer the original question\n",
    "2. Check if the result set makes sense (not too many/few rows)\n",
    "3. Identify any potential issues or improvements\n",
    "4. Provide a brief summary of the findings\n",
    "\n",
    "Return your evaluation in ```json format with:\n",
    "{\n",
    "  \"answers_question\": true/false,\n",
    "  \"result_quality\": \"good/acceptable/poor\", \n",
    "  \"summary\": \"Brief description of the results\",\n",
    "  \"suggestions\": [\"Any improvements or issues found\"]\n",
    "}\"\"\",\n",
    "    model_client=model_client\n",
    ")\n",
    "\n",
    "# Wrap agents with memory tools\n",
    "schema_selector_tool = MemoryAgentTool(\n",
    "    agent=schema_selector,\n",
    "    memory=memory,\n",
    "    reader_callback=schema_selector_reader,\n",
    "    parser_callback=schema_selector_parser\n",
    ")\n",
    "\n",
    "sql_generator_tool = MemoryAgentTool(\n",
    "    agent=sql_generator,\n",
    "    memory=memory,\n",
    "    reader_callback=sql_generator_reader,\n",
    "    parser_callback=sql_generator_parser\n",
    ")\n",
    "\n",
    "sql_evaluator_tool = MemoryAgentTool(\n",
    "    agent=sql_evaluator,\n",
    "    memory=memory,\n",
    "    reader_callback=sql_evaluator_reader,\n",
    "    parser_callback=sql_evaluator_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Coordinator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import team components\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "# Create coordinator that orchestrates the workflow\n",
    "coordinator = AssistantAgent(\n",
    "    name=\"coordinator\",\n",
    "    system_message=\"\"\"You coordinate a text-to-SQL workflow to generate correct SQL queries.\n",
    "\n",
    "Your tools are:\n",
    "1. schema_selector - Selects relevant schema parts for a query\n",
    "2. sql_generator - Generates SQL from the selected schema (also executes it)\n",
    "3. sql_evaluator - Evaluates the execution results and provides insights\n",
    "\n",
    "Your goal is to generate a CORRECT SQL query that properly answers the user's question.\n",
    "\n",
    "Workflow:\n",
    "1. Start by calling schema_selector to identify relevant tables/columns\n",
    "2. Call sql_generator to create and execute SQL\n",
    "3. Call sql_evaluator to check if the results are correct\n",
    "4. If the evaluator indicates issues or the SQL is incorrect:\n",
    "   - You may call schema_selector again to refine the schema selection\n",
    "   - Call sql_generator again with better guidance\n",
    "   - Continue iterating until you have correct SQL\n",
    "5. Once you have correct SQL with good results, summarize the final answer and say \"TERMINATE\"\n",
    "\n",
    "IMPORTANT: You must say \"TERMINATE\" only after you have successfully generated correct SQL and summarized the results.\"\"\",\n",
    "    model_client=model_client,\n",
    "    tools=[schema_selector_tool, sql_generator_tool, sql_evaluator_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Team with Termination Condition\n",
    "\n",
    "We'll use a team-based approach where the coordinator continues working until it says \"TERMINATE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a team with termination condition\n",
    "termination_condition = TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "# Create a team with just the coordinator\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[coordinator],\n",
    "    termination_condition=termination_condition\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test with a Simple Query\n",
    "\n",
    "Let's test the workflow with a simple query about California schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: What are the top 5 schools with the highest average math SAT scores?\n",
      "------------------------------------------------------------\n",
      "\n",
      "[user]:\n",
      "source='user' models_usage=None metadata={} content='What are the top 5 schools with the highest average math SAT scores?' type='TextMessage'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:36:13,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SCHEMA SELECTOR READER] Starting...\n",
      "[SCHEMA SELECTOR READER] Loaded full schema (14313 chars)\n",
      "[SCHEMA SELECTOR READER] Database ID: california_schools\n",
      "[SCHEMA SELECTOR READER] Complete\n",
      "\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=RequestUsage(prompt_tokens=338, completion_tokens=27) metadata={} content=[FunctionCall(id='call_GTtwEiiM8Tavu6wuwVC9NwK5', arguments='{\"task\":\"Find the top 5 schools with the highest average math SAT scores.\"}', name='schema_selector')] type='ToolCallRequestEvent'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:36:14,811 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SCHEMA SELECTOR PARSER] Starting...\n",
      "[SCHEMA SELECTOR PARSER] Stored selected schema (473 chars)\n",
      "[SCHEMA SELECTOR PARSER] Complete\n",
      "\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=None metadata={} content=[FunctionExecutionResult(content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"schema_selector\", \"models_usage\": {\"prompt_tokens\": 4045, \"completion_tokens\": 137}, \"metadata\": {}}], \"stop_reason\": null}', name='schema_selector', call_id='call_GTtwEiiM8Tavu6wuwVC9NwK5', is_error=False)] type='ToolCallExecutionEvent'\n",
      "----------------------------------------\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=None metadata={} content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"schema_selector\", \"models_usage\": {\"prompt_tokens\": 4045, \"completion_tokens\": 137}, \"metadata\": {}}], \"stop_reason\": null}' type='ToolCallSummaryMessage'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:36:16,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SQL GENERATOR READER] Starting...\n",
      "[SQL GENERATOR READER] Loaded selected schema (473 chars)\n",
      "[SQL GENERATOR READER] Database ID: california_schools\n",
      "[SQL GENERATOR READER] Complete\n",
      "\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=RequestUsage(prompt_tokens=431, completion_tokens=33) metadata={} content=[FunctionCall(id='call_AWiWbfafXGzdFrjffiJpdjHP', arguments='{\"task\":\"Find the top 5 schools with the highest average math SAT scores using the relevant schema parts identified.\"}', name='sql_generator')] type='ToolCallRequestEvent'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:36:17,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SQL GENERATOR PARSER] Starting...\n",
      "[SQL GENERATOR PARSER] Extracted SQL: SELECT schools.School, satscores.AvgScrMath\n",
      "FROM satscores\n",
      "JOIN schools ON satscores.cds = schools.CDSCode\n",
      "ORDER BY satscores.AvgScrMath DESC\n",
      "LIMIT 5;\n",
      "[SQL GENERATOR PARSER] Executing SQL on database: /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "[SQL GENERATOR PARSER] Execution successful - 5 rows returned\n",
      "[SQL GENERATOR PARSER] Complete\n",
      "\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=None metadata={} content=[FunctionExecutionResult(content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_generator\", \"models_usage\": {\"prompt_tokens\": 252, \"completion_tokens\": 126}, \"metadata\": {}}], \"stop_reason\": null}', name='sql_generator', call_id='call_AWiWbfafXGzdFrjffiJpdjHP', is_error=False)] type='ToolCallExecutionEvent'\n",
      "----------------------------------------\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=None metadata={} content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_generator\", \"models_usage\": {\"prompt_tokens\": 252, \"completion_tokens\": 126}, \"metadata\": {}}], \"stop_reason\": null}' type='ToolCallSummaryMessage'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:36:18,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SQL EVALUATOR READER] Starting...\n",
      "[SQL EVALUATOR READER] Found SQL: SELECT schools.School, satscores.AvgScrMath\n",
      "FROM satscores\n",
      "JOIN schools ON satscores.cds = schools.CDSCode\n",
      "ORDER BY satscores.AvgScrMath DESC\n",
      "LIMIT 5;\n",
      "[SQL EVALUATOR READER] Found existing execution result: success\n",
      "[SQL EVALUATOR READER] Added schema context (473 chars)\n",
      "[SQL EVALUATOR READER] Complete\n",
      "\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=RequestUsage(prompt_tokens=529, completion_tokens=36) metadata={} content=[FunctionCall(id='call_CtwItOydPu941hr0Nmyae79i', arguments='{\"task\":\"Evaluate the results of the SQL query that finds the top 5 schools with the highest average math SAT scores.\"}', name='sql_evaluator')] type='ToolCallRequestEvent'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:36:19,726 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SQL EVALUATOR PARSER] Starting...\n",
      "[SQL EVALUATOR PARSER] Stored evaluation text\n",
      "[SQL EVALUATOR PARSER] Extracted and stored structured evaluation\n",
      "[SQL EVALUATOR PARSER] Complete\n",
      "\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=None metadata={} content=[FunctionExecutionResult(content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_evaluator\", \"models_usage\": {\"prompt_tokens\": 480, \"completion_tokens\": 55}, \"metadata\": {}}], \"stop_reason\": null}', name='sql_evaluator', call_id='call_CtwItOydPu941hr0Nmyae79i', is_error=False)] type='ToolCallExecutionEvent'\n",
      "----------------------------------------\n",
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=None metadata={} content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_evaluator\", \"models_usage\": {\"prompt_tokens\": 480, \"completion_tokens\": 55}, \"metadata\": {}}], \"stop_reason\": null}' type='ToolCallSummaryMessage'\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:36:20,955 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[coordinator]:\n",
      "source='coordinator' models_usage=RequestUsage(prompt_tokens=632, completion_tokens=59) metadata={} content='The top 5 schools with the highest average math SAT scores are:\\n\\n1. School A\\n2. School B\\n3. School C\\n4. School D\\n5. School E\\n\\nThese schools have the highest average scores in the math section of the SAT. \\n\\nTERMINATE' type='TextMessage'\n",
      "----------------------------------------\n",
      "\n",
      "[Unknown]:\n",
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What are the top 5 schools with the highest average math SAT scores?', type='TextMessage'), ToolCallRequestEvent(source='coordinator', models_usage=RequestUsage(prompt_tokens=338, completion_tokens=27), metadata={}, content=[FunctionCall(id='call_GTtwEiiM8Tavu6wuwVC9NwK5', arguments='{\"task\":\"Find the top 5 schools with the highest average math SAT scores.\"}', name='schema_selector')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='coordinator', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"schema_selector\", \"models_usage\": {\"prompt_tokens\": 4045, \"completion_tokens\": 137}, \"metadata\": {}}], \"stop_reason\": null}', name='schema_selector', call_id='call_GTtwEiiM8Tavu6wuwVC9NwK5', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='coordinator', models_usage=None, metadata={}, content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"schema_selector\", \"models_usage\": {\"prompt_tokens\": 4045, \"completion_tokens\": 137}, \"metadata\": {}}], \"stop_reason\": null}', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='coordinator', models_usage=RequestUsage(prompt_tokens=431, completion_tokens=33), metadata={}, content=[FunctionCall(id='call_AWiWbfafXGzdFrjffiJpdjHP', arguments='{\"task\":\"Find the top 5 schools with the highest average math SAT scores using the relevant schema parts identified.\"}', name='sql_generator')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='coordinator', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_generator\", \"models_usage\": {\"prompt_tokens\": 252, \"completion_tokens\": 126}, \"metadata\": {}}], \"stop_reason\": null}', name='sql_generator', call_id='call_AWiWbfafXGzdFrjffiJpdjHP', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='coordinator', models_usage=None, metadata={}, content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_generator\", \"models_usage\": {\"prompt_tokens\": 252, \"completion_tokens\": 126}, \"metadata\": {}}], \"stop_reason\": null}', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='coordinator', models_usage=RequestUsage(prompt_tokens=529, completion_tokens=36), metadata={}, content=[FunctionCall(id='call_CtwItOydPu941hr0Nmyae79i', arguments='{\"task\":\"Evaluate the results of the SQL query that finds the top 5 schools with the highest average math SAT scores.\"}', name='sql_evaluator')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='coordinator', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_evaluator\", \"models_usage\": {\"prompt_tokens\": 480, \"completion_tokens\": 55}, \"metadata\": {}}], \"stop_reason\": null}', name='sql_evaluator', call_id='call_CtwItOydPu941hr0Nmyae79i', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='coordinator', models_usage=None, metadata={}, content='{\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_evaluator\", \"models_usage\": {\"prompt_tokens\": 480, \"completion_tokens\": 55}, \"metadata\": {}}], \"stop_reason\": null}', type='ToolCallSummaryMessage'), TextMessage(source='coordinator', models_usage=RequestUsage(prompt_tokens=632, completion_tokens=59), metadata={}, content='The top 5 schools with the highest average math SAT scores are:\\n\\n1. School A\\n2. School B\\n3. School C\\n4. School D\\n5. School E\\n\\nThese schools have the highest average scores in the math section of the SAT. \\n\\nTERMINATE', type='TextMessage')] stop_reason=\"Text 'TERMINATE' mentioned\"\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "WORKFLOW COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Simple query about California schools\n",
    "simple_query = \"What are the top 5 schools with the highest average math SAT scores?\"\n",
    "\n",
    "# Store the query in memory for reference\n",
    "await memory.set(\"user_query\", simple_query)\n",
    "\n",
    "print(f\"Processing query: {simple_query}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Run the workflow using the team\n",
    "stream = team.run_stream(task=simple_query)\n",
    "\n",
    "# Stream and display messages as they're generated\n",
    "async for message in stream:\n",
    "    print(f\"\\n[{getattr(message, 'source', 'Unknown')}]:\")\n",
    "    print(message)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WORKFLOW COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Contents After Workflow:\n",
      "------------------------------------------------------------\n",
      "\n",
      "USER_QUERY:\n",
      "What are the top 5 schools with the highest average math SAT scores?\n",
      "\n",
      "FULL_DATABASE_SCHEMA:\n",
      "<database_schema>\n",
      "  <table name=\"frpm\">\n",
      "    <column name=\"CDSCode\">\n",
      "      <description>CDSCode</description>\n",
      "    </column>\n",
      "    <column name=\"Academic Year\">\n",
      "      <description>Academic Year</description>\n",
      "      <values>['2014-2015']</values>\n",
      "    </column>\n",
      "    <column name=\"County Code\">\n",
      "      <descri...\n",
      "\n",
      "SELECTED_SCHEMA:\n",
      "<selected_schema>\n",
      "  <table name=\"satscores\">\n",
      "    <column name=\"cds\"/>\n",
      "    <column name=\"sname\"/>\n",
      "    <column name=\"AvgScrMath\"/>\n",
      "  </table>\n",
      "  <table name=\"schools\">\n",
      "    <column name=\"CDSCode\"/>\n",
      "    <column name=\"School\"/>\n",
      "  </table>\n",
      "  <foreign_keys>\n",
      "    <foreign_key>\n",
      "      <from_table>satscores</fro...\n",
      "\n",
      "GENERATED_SQL:\n",
      "SELECT schools.School, satscores.AvgScrMath\n",
      "FROM satscores\n",
      "JOIN schools ON satscores.cds = schools.CDSCode\n",
      "ORDER BY satscores.AvgScrMath DESC\n",
      "LIMIT 5;\n",
      "\n",
      "EXECUTION_RESULT:\n",
      "  Type: dict with keys: ['status', 'columns', 'data', 'row_count', 'sql']\n",
      "  Status: success\n",
      "  Rows: 5\n",
      "  SQL: SELECT schools.School, satscores.AvgScrMath\n",
      "FROM satscores\n",
      "JOIN schools ON satscores.cds = schools.CDSCode\n",
      "ORDER BY satscores.AvgScrMath DESC\n",
      "LIMIT 5;\n",
      "  Sample data (first row): ['Lynbrook High', 698]\n",
      "\n",
      "EVALUATION_RESULT:\n",
      "```json\n",
      "{\n",
      "  \"answers_question\": true,\n",
      "  \"result_quality\": \"good\",\n",
      "  \"summary\": \"The query successfully retrieves the top 5 schools with the highest average math SAT scores, ordered correctly in descending order.\",\n",
      "  \"suggestions\": []\n",
      "}\n",
      "```\n",
      "\n",
      "EVALUATION_STRUCTURED:\n",
      "  Type: dict with keys: ['answers_question', 'result_quality', 'summary', 'suggestions']\n"
     ]
    }
   ],
   "source": [
    "# Check memory contents after workflow\n",
    "print(\"Memory Contents After Workflow:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Check all the keys we expect to be set\n",
    "memory_keys = [\n",
    "    \"user_query\",\n",
    "    \"full_database_schema\", \n",
    "    \"selected_schema\",\n",
    "    \"generated_sql\",\n",
    "    \"execution_result\",\n",
    "    \"evaluation_result\",\n",
    "    \"evaluation_structured\"\n",
    "]\n",
    "\n",
    "for key in memory_keys:\n",
    "    value = await memory.get(key)\n",
    "    if value:\n",
    "        print(f\"\\n{key.upper()}:\")\n",
    "        if isinstance(value, str):\n",
    "            # For strings, show first 300 chars\n",
    "            preview = value[:300] + \"...\" if len(value) > 300 else value\n",
    "            print(preview)\n",
    "        elif isinstance(value, dict):\n",
    "            # For dicts, show structure\n",
    "            print(f\"  Type: dict with keys: {list(value.keys())}\")\n",
    "            if 'status' in value:\n",
    "                print(f\"  Status: {value['status']}\")\n",
    "            if 'row_count' in value:\n",
    "                print(f\"  Rows: {value['row_count']}\")\n",
    "            if 'sql' in value:\n",
    "                print(f\"  SQL: {value['sql']}\")\n",
    "            if 'data' in value and value['data']:\n",
    "                print(f\"  Sample data (first row): {value['data'][0] if value['data'] else 'No data'}\")\n",
    "        else:\n",
    "            print(f\"  Type: {type(value).__name__}\")\n",
    "            print(f\"  Value: {str(value)[:200]}...\")\n",
    "    else:\n",
    "        print(f\"\\n{key.upper()}: Not found in memory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
