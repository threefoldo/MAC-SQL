{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Refiner Agent Tool Test\n",
    "\n",
    "This notebook demonstrates how to use the `MemoryAgentTool` with our KeyValueMemory implementation to create a SQL refiner agent that can read from and write to memory.\n",
    "\n",
    "The SQL refiner agent improves and optimizes generated SQL queries based on database schema knowledge, error information, and execution results.\n",
    "\n",
    "The `MemoryAgentTool` class provides:\n",
    "1. **Memory integration** for agents by extending BaseTool\n",
    "2. **Pre-processing** via reader callbacks that fetch relevant context from memory before agent execution\n",
    "3. **Post-processing** via parser callbacks that extract and store information from agent outputs after execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Reduce noise from autogen\n",
    "logging.getLogger('autogen_core').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our KeyValueMemory and MemoryAgentTool\n",
    "from memory import KeyValueMemory\n",
    "from memory_agent_tool import MemoryAgentTool, MemoryAgentToolArgs\n",
    "\n",
    "# Import necessary AutoGen components\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up our memory store and model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the shared memory store\n",
    "memory = KeyValueMemory(name=\"text_to_sql_memory\")\n",
    "\n",
    "# Set up the model client - replace with your specific model\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",  # or other appropriate model\n",
    "    temperature=0.1,\n",
    "    timeout=120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define memory callback functions for our refiner agent\n",
    "\n",
    "The agent will have custom reader and parser functions that define how it interacts with memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Refiner Agent memory callbacks\n",
    "async def sql_refiner_reader(memory, task, cancellation_token):\n",
    "    \"\"\"Read relevant information for the SQL refiner agent.\"\"\"\n",
    "    context = {}\n",
    "    \n",
    "    # Get database schema if available\n",
    "    schema = await memory.get(\"current_schema\") or await memory.get(\"full_database_schema\")\n",
    "    if schema:\n",
    "        context[\"schema\"] = schema\n",
    "    \n",
    "    # Get the original SQL if available\n",
    "    original_sql = await memory.get(\"original_sql\")\n",
    "    if original_sql:\n",
    "        context[\"original_sql\"] = original_sql\n",
    "    \n",
    "    # Get error information if available\n",
    "    error_info = await memory.get(\"sql_error_info\")\n",
    "    if error_info:\n",
    "        context[\"error_info\"] = error_info\n",
    "    \n",
    "    # Get execution results if available\n",
    "    execution_results = await memory.get(\"sql_execution_results\")\n",
    "    if execution_results:\n",
    "        context[\"execution_results\"] = execution_results\n",
    "        \n",
    "    # Get refinement history if available\n",
    "    refinement_history_json = await memory.get(\"refinement_history\")\n",
    "    if refinement_history_json:\n",
    "        try:\n",
    "            refinement_history = json.loads(refinement_history_json)\n",
    "            if refinement_history:\n",
    "                context[\"refinement_history\"] = refinement_history\n",
    "        except json.JSONDecodeError:\n",
    "            logging.error(\"Failed to parse refinement history JSON\")\n",
    "    \n",
    "    # Get database dialect/preferences if available\n",
    "    db_info_json = await memory.get(\"db_info\")\n",
    "    if db_info_json:\n",
    "        try:\n",
    "            db_info = json.loads(db_info_json)\n",
    "            context[\"db_info\"] = db_info\n",
    "        except json.JSONDecodeError:\n",
    "            logging.error(\"Failed to parse DB info JSON\")\n",
    "            \n",
    "    # Add the original query for context\n",
    "    original_query = await memory.get(\"original_query\")\n",
    "    if original_query:\n",
    "        context[\"original_query\"] = original_query\n",
    "    \n",
    "    return context\n",
    "\n",
    "async def sql_refiner_parser(memory, task, result, cancellation_token):\n",
    "    \"\"\"Parse and store SQL refinement results.\"\"\"\n",
    "    if result.messages:\n",
    "        last_message = result.messages[-1].content\n",
    "        print(f\"Parsing refiner result: {last_message[:100]}...\")\n",
    "        \n",
    "        # Extract the refined SQL query\n",
    "        sql_matches = re.findall(r'```sql\\s*(.+?)\\s*```', last_message, re.DOTALL)\n",
    "        if sql_matches:\n",
    "            refined_sql = sql_matches[0].strip()\n",
    "            await memory.set(\"refined_sql\", refined_sql)\n",
    "            print(f\"Stored refined SQL in memory: {refined_sql[:100]}...\")\n",
    "            \n",
    "            # Extract the original SQL before refinement (if not already in memory)\n",
    "            original_sql = await memory.get(\"original_sql\")\n",
    "            if not original_sql:\n",
    "                # Try to parse from task\n",
    "                try:\n",
    "                    task_obj = json.loads(task) if isinstance(task, str) else task\n",
    "                    if \"sql\" in task_obj:\n",
    "                        original_sql = task_obj[\"sql\"]\n",
    "                        await memory.set(\"original_sql\", original_sql)\n",
    "                except (json.JSONDecodeError, AttributeError):\n",
    "                    logging.error(\"Failed to extract original SQL from task\")\n",
    "            \n",
    "            # Store in refinement history\n",
    "            refinement_entry = {\n",
    "                \"timestamp\": str(datetime.datetime.now()),\n",
    "                \"original_sql\": original_sql,\n",
    "                \"refined_sql\": refined_sql,\n",
    "                \"refinement_explanation\": last_message\n",
    "            }\n",
    "            \n",
    "            # Update the refinement history\n",
    "            refinement_history = []\n",
    "            refinement_history_json = await memory.get(\"refinement_history\")\n",
    "            if refinement_history_json:\n",
    "                try:\n",
    "                    refinement_history = json.loads(refinement_history_json)\n",
    "                except json.JSONDecodeError:\n",
    "                    logging.error(\"Failed to parse refinement history, creating new one\")\n",
    "            \n",
    "            refinement_history.append(refinement_entry)\n",
    "            # Keep only the last 5 refinements\n",
    "            if len(refinement_history) > 5:\n",
    "                refinement_history = refinement_history[-5:]\n",
    "            \n",
    "            await memory.set(\"refinement_history\", json.dumps(refinement_history))\n",
    "            print(\"Updated refinement history\")\n",
    "            \n",
    "            # Extract optimization notes if available\n",
    "            optimization_match = re.search(r'<optimization_notes>(.+?)</optimization_notes>', last_message, re.DOTALL)\n",
    "            if optimization_match:\n",
    "                optimization_notes = optimization_match.group(1).strip()\n",
    "                await memory.set(\"optimization_notes\", optimization_notes)\n",
    "                print(\"Stored optimization notes\")\n",
    "        else:\n",
    "            print(\"No SQL query found in refiner output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create our SQL Refiner Agent with System Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Define system message for the SQL refiner agent\n",
    "SQL_REFINER_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a SQL refinement and optimization expert. Your role is to:\n",
    "1. Review and analyze SQL queries\n",
    "2. Correct any syntax or logical errors\n",
    "3. Optimize queries for better performance\n",
    "4. Ensure queries correctly match the database schema\n",
    "\n",
    "For each SQL query you review, you should:\n",
    "- Check for proper table and column names based on the provided schema\n",
    "- Verify join conditions and relationships\n",
    "- Suggest index usage and query optimization techniques\n",
    "- Improve readability with proper formatting and comments\n",
    "\n",
    "If error information is provided, focus on fixing those specific issues.\n",
    "\n",
    "Always return your refined SQL in a code block using ```sql ``` format.\n",
    "\n",
    "Optionally, include optimization notes in XML format:\n",
    "<optimization_notes>\n",
    "Your detailed notes about the optimizations applied and why they improve the query.\n",
    "</optimization_notes>\n",
    "\"\"\"\n",
    "\n",
    "# Create the agent\n",
    "sql_refiner_agent = AssistantAgent(\n",
    "    name=\"sql_refiner\",\n",
    "    system_message=SQL_REFINER_SYSTEM_MESSAGE,\n",
    "    model_client=model_client,\n",
    "    description=\"Refines and optimizes SQL queries based on schema and execution feedback\"\n",
    ")\n",
    "\n",
    "# Wrap the agent with memory capabilities\n",
    "sql_refiner_tool = MemoryAgentTool(\n",
    "    agent=sql_refiner_agent,\n",
    "    memory=memory,\n",
    "    reader_callback=sql_refiner_reader,\n",
    "    parser_callback=sql_refiner_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set up Sample Database Schema and Information\n",
    "\n",
    "We'll use the same sample database schema as in the schema selector test, plus additional database information for the refiner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:39:46,546 - root - INFO - [KeyValueMemory] Memory cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full database schema stored in memory\n",
      "Database information stored in memory\n",
      "Refinement history initialized\n"
     ]
    }
   ],
   "source": [
    "# Reset memory for a fresh run\n",
    "await memory.clear()\n",
    "\n",
    "# Set up a sample database schema\n",
    "full_schema = \"\"\"\n",
    "<database_schema>\n",
    "  <table name=\"customers\">\n",
    "    <column name=\"customer_id\" type=\"INTEGER\" primary_key=\"true\" />\n",
    "    <column name=\"name\" type=\"TEXT\" />\n",
    "    <column name=\"email\" type=\"TEXT\" />\n",
    "    <column name=\"join_date\" type=\"DATE\" />\n",
    "  </table>\n",
    "  <table name=\"orders\">\n",
    "    <column name=\"order_id\" type=\"INTEGER\" primary_key=\"true\" />\n",
    "    <column name=\"customer_id\" type=\"INTEGER\" foreign_key=\"customers.customer_id\" />\n",
    "    <column name=\"order_date\" type=\"DATE\" />\n",
    "    <column name=\"total_amount\" type=\"DECIMAL\" />\n",
    "  </table>\n",
    "  <table name=\"products\">\n",
    "    <column name=\"product_id\" type=\"INTEGER\" primary_key=\"true\" />\n",
    "    <column name=\"name\" type=\"TEXT\" />\n",
    "    <column name=\"price\" type=\"DECIMAL\" />\n",
    "    <column name=\"category\" type=\"TEXT\" />\n",
    "  </table>\n",
    "  <table name=\"order_items\">\n",
    "    <column name=\"item_id\" type=\"INTEGER\" primary_key=\"true\" />\n",
    "    <column name=\"order_id\" type=\"INTEGER\" foreign_key=\"orders.order_id\" />\n",
    "    <column name=\"product_id\" type=\"INTEGER\" foreign_key=\"products.product_id\" />\n",
    "    <column name=\"quantity\" type=\"INTEGER\" />\n",
    "    <column name=\"price\" type=\"DECIMAL\" />\n",
    "  </table>\n",
    "  <table name=\"inventory\">\n",
    "    <column name=\"inventory_id\" type=\"INTEGER\" primary_key=\"true\" />\n",
    "    <column name=\"product_id\" type=\"INTEGER\" foreign_key=\"products.product_id\" />\n",
    "    <column name=\"quantity\" type=\"INTEGER\" />\n",
    "    <column name=\"warehouse\" type=\"TEXT\" />\n",
    "  </table>\n",
    "</database_schema>\n",
    "\"\"\"\n",
    "\n",
    "# Store the schema\n",
    "await memory.set(\"full_database_schema\", full_schema)\n",
    "print(\"Full database schema stored in memory\")\n",
    "\n",
    "# Set up database information\n",
    "db_info = {\n",
    "    \"dialect\": \"SQLite\",\n",
    "    \"version\": \"3.39.0\",\n",
    "    \"indexes\": [\n",
    "        {\"table\": \"orders\", \"column\": \"customer_id\", \"name\": \"idx_orders_customer\"},\n",
    "        {\"table\": \"order_items\", \"column\": \"order_id\", \"name\": \"idx_items_order\"},\n",
    "        {\"table\": \"order_items\", \"column\": \"product_id\", \"name\": \"idx_items_product\"}\n",
    "    ],\n",
    "    \"row_counts\": {\n",
    "        \"customers\": 5000,\n",
    "        \"orders\": 20000,\n",
    "        \"products\": 1000,\n",
    "        \"order_items\": 50000,\n",
    "        \"inventory\": 2000\n",
    "    }\n",
    "}\n",
    "\n",
    "await memory.set(\"db_info\", json.dumps(db_info))\n",
    "print(\"Database information stored in memory\")\n",
    "\n",
    "# Initialize empty refinement history\n",
    "await memory.set(\"refinement_history\", json.dumps([]))\n",
    "print(\"Refinement history initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test SQL Refiner with a Query Needing Optimization\n",
    "\n",
    "Let's test our refiner with a SQL query that could be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:39:50,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing refiner result: The original SQL query is mostly correct, but there are a few optimizations and improvements that ca...\n",
      "Stored refined SQL in memory: SELECT c.name, c.email\n",
      "FROM customers c\n",
      "WHERE EXISTS (\n",
      "    SELECT 1\n",
      "    FROM orders o\n",
      "    WHERE o.cu...\n",
      "Updated refinement history\n",
      "Stored optimization notes\n",
      "\n",
      "Agent Response:\n",
      "The original SQL query is mostly correct, but there are a few optimizations and improvements that can be made for better performance and readability. Here's the refined query:\n",
      "\n",
      "```sql\n",
      "SELECT c.name, c.email\n",
      "FROM customers c\n",
      "WHERE EXISTS (\n",
      "    SELECT 1\n",
      "    FROM orders o\n",
      "    WHERE o.customer_id = c.customer_id\n",
      "      AND o.total_amount > 100\n",
      ");\n",
      "```\n",
      "\n",
      "<optimization_notes>\n",
      "- **Replaced IN with EXISTS**: Using `EXISTS` is generally more efficient than `IN` when checking for the existence of rows in a subquery, especially when dealing with large datasets. This is because `EXISTS` can stop processing as soon as it finds a matching row, whereas `IN` may need to process all rows.\n",
      "- **Index Usage**: The query benefits from the existing index on `orders.customer_id` (`idx_orders_customer`), which helps speed up the lookup of orders for each customer.\n",
      "- **Readability**: The query is formatted for better readability, with clear alignment and indentation.\n",
      "</optimization_notes>\n"
     ]
    }
   ],
   "source": [
    "# Define the original query intent\n",
    "original_query = \"Find all customers who have placed orders with a total amount greater than $100\"\n",
    "await memory.set(\"original_query\", original_query)\n",
    "\n",
    "# A SQL query with room for improvement\n",
    "unoptimized_sql = \"\"\"\n",
    "SELECT c.name, c.email \n",
    "FROM customers c\n",
    "WHERE c.customer_id IN (\n",
    "    SELECT customer_id \n",
    "    FROM orders \n",
    "    WHERE total_amount > 100\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "await memory.set(\"original_sql\", unoptimized_sql)\n",
    "\n",
    "# Create a task for the refiner\n",
    "task1 = json.dumps({\n",
    "    \"sql\": unoptimized_sql,\n",
    "    \"query\": original_query,\n",
    "    \"optimize_for\": \"readability and performance\"\n",
    "})\n",
    "\n",
    "# Create a cancellation token\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Create the proper arguments object\n",
    "args = MemoryAgentToolArgs(task=task1)\n",
    "\n",
    "# Run the agent\n",
    "result1 = await sql_refiner_tool.run(\n",
    "    args=args,\n",
    "    cancellation_token=cancellation_token\n",
    ")\n",
    "\n",
    "# Display result\n",
    "print(f\"\\nAgent Response:\\n{result1.messages[-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test SQL Refiner with an Erroneous Query\n",
    "\n",
    "Let's test our refiner with a SQL query that has an error that needs to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:39:54,026 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing refiner result: The error in the provided SQL query is due to the incorrect table name `ordered_items`. The correct ...\n",
      "Stored refined SQL in memory: SELECT p.name, SUM(oi.quantity) AS total_ordered\n",
      "FROM products p\n",
      "JOIN order_items oi ON p.product_id...\n",
      "Updated refinement history\n",
      "Stored optimization notes\n",
      "\n",
      "Agent Response:\n",
      "The error in the provided SQL query is due to the incorrect table name `ordered_items`. The correct table name is `order_items`. Let's refine the query to fix this error and ensure optimal performance:\n",
      "\n",
      "```sql\n",
      "SELECT p.name, SUM(oi.quantity) AS total_ordered\n",
      "FROM products p\n",
      "JOIN order_items oi ON p.product_id = oi.product_id  -- Corrected table name\n",
      "GROUP BY p.product_id\n",
      "ORDER BY total_ordered DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "<optimization_notes>\n",
      "- **Corrected Table Name**: Changed `ordered_items` to `order_items` to match the schema.\n",
      "- **Index Usage**: The query benefits from the existing index on `order_items.product_id` (`idx_items_product`), which helps speed up the join operation between `products` and `order_items`.\n",
      "- **Readability**: The query is formatted for better readability, with clear alignment and indentation.\n",
      "- **Performance**: The use of `LIMIT 10` ensures that only the top 10 results are returned, which is efficient for large datasets.\n",
      "</optimization_notes>\n"
     ]
    }
   ],
   "source": [
    "# A SQL query with an error\n",
    "error_sql = \"\"\"\n",
    "SELECT p.name, SUM(oi.quantity) as total_ordered\n",
    "FROM products p\n",
    "JOIN ordered_items oi ON p.product_id = oi.product_id  -- Error: table name should be order_items\n",
    "GROUP BY p.product_id\n",
    "ORDER BY total_ordered DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Simulated error info\n",
    "error_info = \"Error: no such table: ordered_items\"\n",
    "await memory.set(\"sql_error_info\", error_info)\n",
    "\n",
    "# Create a task for the refiner\n",
    "task2 = json.dumps({\n",
    "    \"sql\": error_sql,\n",
    "    \"query\": \"Find the top 10 most ordered products\",\n",
    "    \"error\": error_info\n",
    "})\n",
    "\n",
    "# Create the proper arguments object\n",
    "args = MemoryAgentToolArgs(task=task2)\n",
    "\n",
    "# Run the agent\n",
    "result2 = await sql_refiner_tool.run(\n",
    "    args=args,\n",
    "    cancellation_token=cancellation_token\n",
    ")\n",
    "\n",
    "# Display result\n",
    "print(f\"\\nAgent Response:\\n{result2.messages[-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test SQL Refiner with Execution Feedback\n",
    "\n",
    "Let's test our refiner with a SQL query that produces unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 17:39:57,713 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing refiner result: The query provided is intended to find customers who have placed more than 5 orders. However, it ret...\n",
      "Stored refined SQL in memory: SELECT c.name, COUNT(o.order_id) AS order_count\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o....\n",
      "Updated refinement history\n",
      "Stored optimization notes\n",
      "\n",
      "Agent Response:\n",
      "The query provided is intended to find customers who have placed more than 5 orders. However, it returned no results, which is unexpected given the sample data. Let's refine the query to ensure it accurately reflects the intended logic and correct any potential issues:\n",
      "\n",
      "```sql\n",
      "SELECT c.name, COUNT(o.order_id) AS order_count\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.name\n",
      "HAVING COUNT(o.order_id) > 5;\n",
      "```\n",
      "\n",
      "<optimization_notes>\n",
      "- **Corrected Grouping**: The original query grouped by `c.name`, which could lead to incorrect results if there are customers with the same name. Grouping by `c.customer_id` ensures that each customer is uniquely identified.\n",
      "- **Explicit Count**: Changed `COUNT(*)` to `COUNT(o.order_id)` to explicitly count the number of orders per customer, which is more semantically clear.\n",
      "- **Index Usage**: The query benefits from the existing index on `orders.customer_id` (`idx_orders_customer`), which helps speed up the join operation.\n",
      "- **Readability**: The query is formatted for better readability, with clear alignment and indentation.\n",
      "</optimization_notes>\n"
     ]
    }
   ],
   "source": [
    "# A SQL query with unexpected results\n",
    "unexpected_sql = \"\"\"\n",
    "SELECT c.name, COUNT(*) as order_count\n",
    "FROM customers c\n",
    "JOIN orders o ON c.customer_id = o.customer_id\n",
    "GROUP BY c.name\n",
    "HAVING order_count > 5\n",
    "\"\"\"\n",
    "\n",
    "# Simulated execution results\n",
    "execution_results = \"\"\"\n",
    "Query executed successfully but returned 0 rows. The database has 5000 customers and 20000 orders.\n",
    "Sample data:\n",
    "- customers table has customers with multiple orders\n",
    "- Average orders per customer is 4\n",
    "- Some customers have up to 20 orders\n",
    "\"\"\"\n",
    "await memory.set(\"sql_execution_results\", execution_results)\n",
    "\n",
    "# Create a task for the refiner\n",
    "task3 = json.dumps({\n",
    "    \"sql\": unexpected_sql,\n",
    "    \"query\": \"Find customers who have placed more than 5 orders\",\n",
    "    \"execution_results\": execution_results,\n",
    "    \"feedback\": \"Query returned no results but we expect to see customers with more than 5 orders\"\n",
    "})\n",
    "\n",
    "# Create the proper arguments object\n",
    "args = MemoryAgentToolArgs(task=task3)\n",
    "\n",
    "# Run the agent\n",
    "result3 = await sql_refiner_tool.run(\n",
    "    args=args,\n",
    "    cancellation_token=cancellation_token\n",
    ")\n",
    "\n",
    "# Display result\n",
    "print(f\"\\nAgent Response:\\n{result3.messages[-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Check Memory Contents\n",
    "\n",
    "Let's examine what's stored in memory after our agent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent refined SQL:\n",
      "SELECT c.name, COUNT(o.order_id) AS order_count\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.name\n",
      "HAVING COUNT(o.order_id) > 5;\n",
      "\n",
      "Optimization Notes:\n",
      "- **Corrected Grouping**: The original query grouped by `c.name`, which could lead to incorrect results if there are customers with the same name. Grouping by `c.customer_id` ensures that each customer is uniquely identified.\n",
      "- **Explicit Count**: Changed `COUNT(*)` to `COUNT(o.order_id)` to explicitly count the number of orders per customer, which is more semantically clear.\n",
      "- **Index Usage**: The query benefits from the existing index on `orders.customer_id` (`idx_orders_customer`), which helps speed up the join operation.\n",
      "- **Readability**: The query is formatted for better readability, with clear alignment and indentation.\n",
      "\n",
      "Refinement History (3 entries):\n",
      "\n",
      "Entry 1:\n",
      "Timestamp: 2025-05-21 17:39:50.037501\n",
      "Original SQL: \n",
      "SELECT c.name, c.email \n",
      "FROM customers c\n",
      "WHERE c....\n",
      "Refined SQL: SELECT c.name, c.email\n",
      "FROM customers c\n",
      "WHERE EXIS...\n",
      "\n",
      "Entry 2:\n",
      "Timestamp: 2025-05-21 17:39:54.027951\n",
      "Original SQL: \n",
      "SELECT c.name, c.email \n",
      "FROM customers c\n",
      "WHERE c....\n",
      "Refined SQL: SELECT p.name, SUM(oi.quantity) AS total_ordered\n",
      "F...\n",
      "\n",
      "Entry 3:\n",
      "Timestamp: 2025-05-21 17:39:57.714610\n",
      "Original SQL: \n",
      "SELECT c.name, c.email \n",
      "FROM customers c\n",
      "WHERE c....\n",
      "Refined SQL: SELECT c.name, COUNT(o.order_id) AS order_count\n",
      "FR...\n"
     ]
    }
   ],
   "source": [
    "# Check the refined SQL\n",
    "refined_sql = await memory.get(\"refined_sql\")\n",
    "print(f\"Most recent refined SQL:\\n{refined_sql}\\n\")\n",
    "\n",
    "# Check optimization notes if available\n",
    "optimization_notes = await memory.get(\"optimization_notes\")\n",
    "if optimization_notes:\n",
    "    print(f\"Optimization Notes:\\n{optimization_notes}\\n\")\n",
    "else:\n",
    "    print(\"No optimization notes available\\n\")\n",
    "    \n",
    "# Get refinement history\n",
    "refinement_history_json = await memory.get(\"refinement_history\")\n",
    "if refinement_history_json:\n",
    "    refinement_history = json.loads(refinement_history_json)\n",
    "    print(f\"Refinement History ({len(refinement_history)} entries):\")\n",
    "    for i, entry in enumerate(refinement_history):\n",
    "        print(f\"\\nEntry {i+1}:\")\n",
    "        print(f\"Timestamp: {entry['timestamp']}\")\n",
    "        print(f\"Original SQL: {entry['original_sql'][:50]}...\")\n",
    "        print(f\"Refined SQL: {entry['refined_sql'][:50]}...\")\n",
    "else:\n",
    "    print(\"No refinement history found in memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Demonstrate Using Refinement Results\n",
    "\n",
    "Let's demonstrate how we might use the refined SQL in a workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the refined SQL in a workflow:\n",
      "\n",
      "Refined SQL:\n",
      "SELECT c.name, COUNT(o.order_id) AS order_count\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.name\n",
      "HAVING COUNT(o.order_id) > 5;\n",
      "\n",
      "In a real workflow:\n",
      "1. We would execute this SQL against the database\n",
      "2. Process the results for the user\n",
      "3. Store the execution metrics for future optimization\n",
      "\n",
      "Optimization insights for the user:\n",
      "- **Corrected Grouping**: The original query grouped by `c.name`, which could lead to incorrect results if there are customers with the same name. Grouping by `c.customer_id` ensures that each customer is uniquely identified.\n",
      "- **Explicit Count**: Changed `COUNT(*)` to `COUNT(o.order_id)` to explicitly count the number of orders per customer, which is more semantically clear.\n",
      "- **Index Usage**: The query benefits from the existing index on `orders.customer_id` (`idx_orders_customer`), which helps speed up the join operation.\n",
      "- **Readability**: The query is formatted for better readability, with clear alignment and indentation.\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent refined SQL\n",
    "refined_sql = await memory.get(\"refined_sql\")\n",
    "if refined_sql:\n",
    "    print(\"Using the refined SQL in a workflow:\")\n",
    "    print(f\"\\nRefined SQL:\\n{refined_sql}\")\n",
    "    \n",
    "    # In a real workflow, we would execute this SQL against a database\n",
    "    print(\"\\nIn a real workflow:\")\n",
    "    print(\"1. We would execute this SQL against the database\")\n",
    "    print(\"2. Process the results for the user\")\n",
    "    print(\"3. Store the execution metrics for future optimization\")\n",
    "    \n",
    "    # Extract any optimization info for the user\n",
    "    optimization_notes = await memory.get(\"optimization_notes\")\n",
    "    if optimization_notes:\n",
    "        print(f\"\\nOptimization insights for the user:\\n{optimization_notes}\")\n",
    "else:\n",
    "    print(\"No refined SQL available to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook demonstrates how the `MemoryAgentTool` allows a SQL refiner agent to improve and optimize queries while maintaining context through memory. The key features demonstrated include:\n",
    "\n",
    "1. Reading schema, original SQL, and error information from memory before refinement\n",
    "2. Using execution feedback to guide refinements\n",
    "3. Storing optimized SQL and optimization notes after agent execution\n",
    "4. Maintaining a history of refinements for context and learning\n",
    "\n",
    "The SQL refiner agent demonstrated three key capabilities:\n",
    "1. **Optimization**: Improving a working but suboptimal query\n",
    "2. **Error correction**: Fixing syntax and schema-related errors\n",
    "3. **Results-driven refinement**: Adjusting queries based on unexpected execution results\n",
    "\n",
    "This pattern is essential in real-world text-to-SQL workflows, where initial SQL generation may not be perfect and requires iterative refinement based on database feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
