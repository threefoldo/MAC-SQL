{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexible Coordinator Workflow\n",
    "\n",
    "This notebook demonstrates a flexible text-to-SQL workflow where the coordinator makes intelligent decisions about which agent to run based on the current state of the query tree.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. **Non-linear Execution**: Coordinator decides which agent to call based on node state\n",
    "2. **Automatic Node Management**: Current node is tracked in memory\n",
    "3. **State-based Decisions**: Coordinator examines what each node needs\n",
    "4. **Error Recovery**: Can retry specific steps without restarting\n",
    "5. **Complex Query Support**: Handles multi-node query trees intelligently\n",
    "\n",
    "## Workflow Logic\n",
    "\n",
    "The coordinator examines the current node and decides:\n",
    "- No intent? → Run query_analyzer\n",
    "- No mapping? → Run schema_linker\n",
    "- No SQL? → Run sql_generator\n",
    "- No execution/evaluation? → Run sql_evaluator\n",
    "- Poor quality? → Retry the appropriate step\n",
    "- All good? → Check for workflow completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OPENAI_API_KEY found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append('../src')\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"WARNING: OPENAI_API_KEY not found in environment\")\n",
    "else:\n",
    "    print(\"✓ OPENAI_API_KEY found\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Reduce noise\n",
    "logging.getLogger('autogen_core').setLevel(logging.WARNING)\n",
    "logging.getLogger('httpx').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import All Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory and managers\n",
    "from keyvalue_memory import KeyValueMemory\n",
    "from task_context_manager import TaskContextManager\n",
    "from query_tree_manager import QueryTreeManager\n",
    "from database_schema_manager import DatabaseSchemaManager\n",
    "from node_history_manager import NodeHistoryManager\n",
    "\n",
    "# Schema reader\n",
    "from schema_reader import SchemaReader\n",
    "\n",
    "# All 4 agents\n",
    "from query_analyzer_agent import QueryAnalyzerAgent\n",
    "from schema_linker_agent import SchemaLinkerAgent\n",
    "from sql_generator_agent import SQLGeneratorAgent\n",
    "from sql_evaluator_agent import SQLEvaluatorAgent\n",
    "\n",
    "# Memory types\n",
    "from memory_content_types import (\n",
    "    TaskContext, QueryNode, NodeStatus, TaskStatus,\n",
    "    QueryMapping, TableMapping, ColumnMapping, JoinMapping,\n",
    "    TableSchema, ColumnInfo, ExecutionResult\n",
    ")\n",
    "\n",
    "# AutoGen components\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Memory and Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Initialized memory and managers\n"
     ]
    }
   ],
   "source": [
    "# Initialize shared memory\n",
    "memory = KeyValueMemory()\n",
    "\n",
    "# Initialize managers\n",
    "task_manager = TaskContextManager(memory)\n",
    "tree_manager = QueryTreeManager(memory)\n",
    "schema_manager = DatabaseSchemaManager(memory)\n",
    "history_manager = NodeHistoryManager(memory)\n",
    "\n",
    "print(\"✓ Initialized memory and managers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:25,149 - TaskContextManager - INFO - Initialized task context for task flexible_demo_001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the highest eligible free rate for K-12 students in schools located in Alameda County?\n",
      "--------------------------------------------------------------------------------\n",
      "load json file from /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_tables.json\n",
      "\n",
      "Loading all database info...\n",
      "Found 11 databases in bird dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:37,651 - DatabaseSchemaManager - INFO - Initialized empty database schema\n",
      "2025-05-25 12:43:37,652 - DatabaseSchemaManager - INFO - Added table 'frpm' to schema\n",
      "2025-05-25 12:43:37,652 - DatabaseSchemaManager - INFO - Added table 'satscores' to schema\n",
      "2025-05-25 12:43:37,653 - DatabaseSchemaManager - INFO - Added table 'schools' to schema\n",
      "2025-05-25 12:43:37,653 - DatabaseSchemaManager - INFO - Loaded schema for database 'california_schools' with 3 tables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 'california_schools' database:\n",
      "  Tables: 3\n",
      "  Columns: 89\n",
      "  Foreign keys: 2\n"
     ]
    }
   ],
   "source": [
    "# Database configuration\n",
    "data_path = \"/home/norman/work/text-to-sql/MAC-SQL/data/bird\"\n",
    "tables_json_path = Path(data_path) / \"dev_tables.json\"\n",
    "db_name = \"california_schools\"\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What is the highest eligible free rate for K-12 students in schools located in Alameda County?\",\n",
    "    \"Show me schools with SAT scores above 1400 and their free lunch eligibility rates\",\n",
    "    \"Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate\"\n",
    "]\n",
    "\n",
    "# Pick a query (try different ones!)\n",
    "test_query = test_queries[0]\n",
    "print(f\"Query: {test_query}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Initialize task\n",
    "task_id = \"flexible_demo_001\"\n",
    "await task_manager.initialize(task_id, test_query, db_name)\n",
    "\n",
    "# Load schema\n",
    "schema_reader = SchemaReader(\n",
    "    data_path=data_path,\n",
    "    tables_json_path=str(tables_json_path),\n",
    "    dataset_name=\"bird\",\n",
    "    lazy=False\n",
    ")\n",
    "\n",
    "await schema_manager.load_from_schema_reader(schema_reader, db_name)\n",
    "\n",
    "# Get schema summary\n",
    "summary = await schema_manager.get_schema_summary()\n",
    "print(f\"\\nLoaded '{db_name}' database:\")\n",
    "print(f\"  Tables: {summary['table_count']}\")\n",
    "print(f\"  Columns: {summary['total_columns']}\")\n",
    "print(f\"  Foreign keys: {summary['total_foreign_keys']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize All Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:37,674 - QueryAnalyzerAgent - INFO - Initialized query_analyzer with model gpt-4o\n",
      "2025-05-25 12:43:37,686 - SchemaLinkerAgent - INFO - Initialized schema_linker with model gpt-4o\n",
      "2025-05-25 12:43:37,697 - SQLGeneratorAgent - INFO - Initialized sql_generator with model gpt-4o\n",
      "2025-05-25 12:43:37,708 - SQLEvaluatorAgent - INFO - Initialized sql_evaluator with model gpt-4o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Initialized all agents\n"
     ]
    }
   ],
   "source": [
    "# LLM configuration\n",
    "llm_config = {\n",
    "    \"model_name\": \"gpt-4o\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"timeout\": 60\n",
    "}\n",
    "\n",
    "# Initialize all agents\n",
    "query_analyzer = QueryAnalyzerAgent(memory, llm_config)\n",
    "schema_linker = SchemaLinkerAgent(memory, llm_config)\n",
    "sql_generator = SQLGeneratorAgent(memory, llm_config)\n",
    "sql_evaluator = SQLEvaluatorAgent(memory, llm_config)\n",
    "\n",
    "print(\"✓ Initialized all agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Flexible Coordinator\n",
    "\n",
    "This coordinator examines the current state and makes intelligent decisions about what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created flexible coordinator with termination rules\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client for coordinator\n",
    "coordinator_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.1,\n",
    "    timeout=120,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create flexible coordinator\n",
    "coordinator = AssistantAgent(\n",
    "    name=\"coordinator\",\n",
    "    system_message=\"\"\"You are a flexible coordinator for a text-to-SQL workflow.\n",
    "\n",
    "Your agents:\n",
    "- query_analyzer: Analyzes queries and creates query trees\n",
    "- schema_linker: Links queries to database schema\n",
    "- sql_generator: Generates SQL from linked schema\n",
    "- sql_evaluator: Executes and evaluates SQL results\n",
    "\n",
    "HOW TO CALL AGENTS:\n",
    "- query_analyzer: Call with the user's query directly\n",
    "- Other agents: Just call with a simple task description like:\n",
    "  - \"Link query to database schema\"\n",
    "  - \"Generate SQL query\"\n",
    "  - \"Analyze SQL execution results\"\n",
    "  \n",
    "The agents automatically work on the current node stored in memory.\n",
    "\n",
    "DECISION PROCESS:\n",
    "\n",
    "1. First, always check the logs to understand the current state:\n",
    "   - Look for \"current node\" mentions\n",
    "   - Check what components the node already has\n",
    "   - Check the quality of any evaluations\n",
    "\n",
    "2. Based on the current node's state, decide what to do:\n",
    "   - If no query tree exists → call query_analyzer with the user's query\n",
    "   - If node lacks mapping → call schema_linker with \"Link query to database schema\"\n",
    "   - If node lacks SQL → call sql_generator with \"Generate SQL query\"\n",
    "   - If node lacks evaluation → call sql_evaluator with \"Analyze SQL execution results\"\n",
    "   - If evaluation quality is poor → analyze the issue and retry appropriate step\n",
    "\n",
    "3. After sql_evaluator runs:\n",
    "   - Check if it says \"workflow complete\" in the logs\n",
    "   - If workflow is complete → summarize the final answer and say \"TERMINATE\"\n",
    "   - If not complete → continue with the next node\n",
    "\n",
    "4. TERMINATION RULES:\n",
    "   - You MUST say \"TERMINATE\" at the end of your message when workflow is complete\n",
    "   - Look for \"workflow complete\" in the sql_evaluator logs\n",
    "   - When all nodes have good quality results, summarize and say \"TERMINATE\"\n",
    "   - Example: \"The highest rate is 75.0%. TERMINATE\"\n",
    "\n",
    "5. For poor quality results:\n",
    "   - Wrong tables? → retry schema_linker with guidance\n",
    "   - Bad SQL? → retry sql_generator with error details\n",
    "   - Missing data? → check if schema linking was complete\n",
    "\n",
    "CRITICAL: You must end your final answer with the word \"TERMINATE\" to end the conversation.\"\"\",\n",
    "    model_client=coordinator_client,\n",
    "    tools=[query_analyzer.get_tool(), schema_linker.get_tool(), \n",
    "           sql_generator.get_tool(), sql_evaluator.get_tool()]\n",
    ")\n",
    "\n",
    "print(\"✓ Created flexible coordinator with termination rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def display_current_state():\n",
    "    \"\"\"Display the current workflow state\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CURRENT WORKFLOW STATE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Current node\n",
    "    current_node_id = await memory.get(\"current_node_id\")\n",
    "    print(f\"\\nCurrent Node: {current_node_id or 'None'}\")\n",
    "    \n",
    "    # Workflow status\n",
    "    is_complete = await memory.get(\"workflow_complete\")\n",
    "    print(f\"Workflow Complete: {'Yes' if is_complete else 'No'}\")\n",
    "    \n",
    "    # Tree overview\n",
    "    tree = await tree_manager.get_tree()\n",
    "    if tree and \"nodes\" in tree:\n",
    "        print(f\"\\nQuery Tree:\")\n",
    "        print(f\"  Total nodes: {len(tree['nodes'])}\")\n",
    "        \n",
    "        # Count by status\n",
    "        status_counts = {}\n",
    "        for node_id, node_data in tree[\"nodes\"].items():\n",
    "            status = node_data.get(\"status\", \"unknown\")\n",
    "            status_counts[status] = status_counts.get(status, 0) + 1\n",
    "        \n",
    "        for status, count in status_counts.items():\n",
    "            print(f\"  {status}: {count}\")\n",
    "\n",
    "async def check_workflow_completion():\n",
    "    \"\"\"Check if workflow is truly complete and provide summary\"\"\"\n",
    "    is_complete = await memory.get(\"workflow_complete\")\n",
    "    tree = await tree_manager.get_tree()\n",
    "    \n",
    "    if is_complete:\n",
    "        print(\"\\n✅ WORKFLOW MARKED AS COMPLETE\")\n",
    "    \n",
    "    if tree and \"nodes\" in tree:\n",
    "        all_good = True\n",
    "        results_summary = []\n",
    "        \n",
    "        for node_id, node_data in tree[\"nodes\"].items():\n",
    "            if node_data.get(\"sql\") and node_data.get(\"executionResult\"):\n",
    "                analysis = await memory.get(f\"node_{node_id}_analysis\")\n",
    "                if analysis:\n",
    "                    quality = analysis.get(\"result_quality\", \"unknown\")\n",
    "                    if quality not in [\"excellent\", \"good\"]:\n",
    "                        all_good = False\n",
    "                    \n",
    "                    # Collect results\n",
    "                    exec_result = node_data[\"executionResult\"]\n",
    "                    if exec_result.get(\"data\") and len(exec_result[\"data\"]) > 0:\n",
    "                        results_summary.append({\n",
    "                            \"intent\": node_data.get(\"intent\", \"\"),\n",
    "                            \"result\": exec_result[\"data\"][0] if exec_result[\"data\"] else None,\n",
    "                            \"quality\": quality\n",
    "                        })\n",
    "        \n",
    "        if all_good:\n",
    "            print(\"✅ All nodes have good quality results\")\n",
    "        else:\n",
    "            print(\"⚠️  Some nodes still need improvement\")\n",
    "        \n",
    "        if results_summary:\n",
    "            print(\"\\n📊 Results Summary:\")\n",
    "            for item in results_summary:\n",
    "                print(f\"  • {item['intent'][:50]}...\")\n",
    "                print(f\"    Result: {item['result']}\")\n",
    "                print(f\"    Quality: {item['quality']}\")\n",
    "    \n",
    "    return is_complete\n",
    "\n",
    "async def display_node_details(node_id: str):\n",
    "    \"\"\"Display detailed information about a specific node\"\"\"\n",
    "    node = await tree_manager.get_node(node_id)\n",
    "    if not node:\n",
    "        print(f\"Node {node_id} not found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nNode: {node_id}\")\n",
    "    print(f\"  Status: {node.status.value if node.status else 'None'}\")\n",
    "    print(f\"  Intent: {node.intent[:50]}...\" if node.intent else \"  Intent: None\")\n",
    "    print(f\"  Has mapping: {'Yes' if node.mapping else 'No'}\")\n",
    "    print(f\"  Has SQL: {'Yes' if node.sql else 'No'}\")\n",
    "    print(f\"  Has execution: {'Yes' if node.executionResult else 'No'}\")\n",
    "    \n",
    "    # Check evaluation\n",
    "    analysis = await memory.get(f\"node_{node_id}_analysis\")\n",
    "    if analysis:\n",
    "        print(f\"  Evaluation:\")\n",
    "        print(f\"    Answers intent: {analysis.get('answers_intent')}\")\n",
    "        print(f\"    Quality: {analysis.get('result_quality')}\")\n",
    "\n",
    "async def display_progress():\n",
    "    \"\"\"Display workflow progress\"\"\"\n",
    "    tree = await tree_manager.get_tree()\n",
    "    if not tree or \"nodes\" not in tree:\n",
    "        print(\"No query tree found\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"WORKFLOW PROGRESS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    current_node_id = await memory.get(\"current_node_id\")\n",
    "    \n",
    "    for node_id, node_data in tree[\"nodes\"].items():\n",
    "        is_current = \"→\" if node_id == current_node_id else \" \"\n",
    "        \n",
    "        # Build status indicators\n",
    "        indicators = []\n",
    "        if node_data.get(\"intent\"):\n",
    "            indicators.append(\"I\")\n",
    "        if node_data.get(\"mapping\"):\n",
    "            indicators.append(\"M\")\n",
    "        if node_data.get(\"sql\"):\n",
    "            indicators.append(\"S\")\n",
    "        if node_data.get(\"executionResult\"):\n",
    "            indicators.append(\"E\")\n",
    "        \n",
    "        # Check evaluation\n",
    "        analysis = await memory.get(f\"node_{node_id}_analysis\")\n",
    "        if analysis:\n",
    "            quality = analysis.get(\"result_quality\", \"?\")[0].upper()\n",
    "            indicators.append(f\"Q:{quality}\")\n",
    "        \n",
    "        status_str = \"[\"+\",\".join(indicators)+\"]\" if indicators else \"[empty]\"        \n",
    "        intent_preview = node_data.get(\"intent\", \"No intent\")[:40] + \"...\"\n",
    "        \n",
    "        print(f\"{is_current} {node_id[-8:]} {status_str} {intent_preview}\")\n",
    "    \n",
    "    print(\"\\nLegend: I=Intent, M=Mapping, S=SQL, E=Executed, Q=Quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Flexible Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flexible workflow...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create team with termination condition\n",
    "termination_condition = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[coordinator],\n",
    "    termination_condition=termination_condition\n",
    ")\n",
    "\n",
    "print(\"Starting flexible workflow...\\n\")\n",
    "stream = team.run_stream(task=test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1] Coordinator:\n",
      "  → Calling query_analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:40,113 - QueryTreeManager - INFO - Initialized query tree with root node node_1748191420.113068_root\n",
      "2025-05-25 12:43:40,113 - NodeHistoryManager - INFO - Added create operation for node node_1748191420.113068_root\n",
      "2025-05-25 12:43:40,113 - QueryAnalyzerAgent - INFO - Simple query - set root node_1748191420.113068_root as current node\n",
      "2025-05-25 12:43:40,113 - QueryAnalyzerAgent - INFO - Query analysis completed. Complexity: simple. Root node: node_1748191420.113068_root\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2] Coordinator:\n",
      "  → Calling query_analyzer\n",
      "\n",
      "[Step 3] Coordinator:\n",
      "  Decision: {\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"query_analyzer\", \"models_usage\": {\"prompt_tokens\": 3167, \"completion_tokens\": 108}, \"metadata\": {}}], \"stop_reason\":...\n",
      "\n",
      "[Step 4] Coordinator:\n",
      "  → Calling schema_linker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:43,495 - QueryTreeManager - INFO - Updated node node_1748191420.113068_root\n",
      "2025-05-25 12:43:43,495 - NodeHistoryManager - INFO - Added revise operation for node node_1748191420.113068_root\n",
      "2025-05-25 12:43:43,495 - SchemaLinkerAgent - INFO - Updated node node_1748191420.113068_root with schema mapping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 5] Coordinator:\n",
      "  → Calling schema_linker\n",
      "\n",
      "[Step 6] Coordinator:\n",
      "  Decision: {\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"schema_linker\", \"models_usage\": {\"prompt_tokens\": 5012, \"completion_tokens\": 214}, \"metadata\": {}}], \"stop_reason\": ...\n",
      "\n",
      "[Step 7] Coordinator:\n",
      "  → Calling sql_generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:46,759 - QueryTreeManager - INFO - Updated node node_1748191420.113068_root\n",
      "2025-05-25 12:43:46,759 - NodeHistoryManager - INFO - Added generate_sql operation for node node_1748191420.113068_root\n",
      "2025-05-25 12:43:46,760 - SQLGeneratorAgent - INFO - Updated node node_1748191420.113068_root with generated SQL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 8] Coordinator:\n",
      "  → Calling sql_generator\n",
      "\n",
      "[Step 9] Coordinator:\n",
      "  Decision: {\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_generator\", \"models_usage\": {\"prompt_tokens\": 380, \"completion_tokens\": 175}, \"metadata\": {}}], \"stop_reason\": n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:47,382 - SQLEvaluatorAgent - INFO - Using current node from memory: node_1748191420.113068_root\n",
      "2025-05-25 12:43:47,383 - SQLEvaluatorAgent - INFO - Executing SQL for node node_1748191420.113068_root on database california_schools\n",
      "2025-05-25 12:43:47,385 - QueryTreeManager - INFO - Updated node node_1748191420.113068_root\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SQLExecutor] Connecting to database: /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "\n",
      "[Step 10] Coordinator:\n",
      "  → Calling sql_evaluator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:49,739 - SQLEvaluatorAgent - INFO - Stored analysis for node node_1748191420.113068_root - Answers intent: yes, Quality: excellent\n",
      "2025-05-25 12:43:49,739 - SQLEvaluatorAgent - INFO - Root node node_1748191420.113068_root and all descendants are good - workflow complete\n",
      "2025-05-25 12:43:49,739 - SQLEvaluatorAgent - INFO - Analysis complete - Answers intent: yes, Quality: excellent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 11] Coordinator:\n",
      "  → Calling sql_evaluator\n",
      "\n",
      "[Step 12] Coordinator:\n",
      "  Decision: {\"messages\": [{\"source\": \"user\", \"models_usage\": null, \"metadata\": {}}, {\"source\": \"sql_evaluator\", \"models_usage\": {\"prompt_tokens\": 402, \"completion_tokens\": 194}, \"metadata\": {}}], \"stop_reason\": n...\n",
      "\n",
      "[Step 13] Coordinator:\n",
      "  Decision: The highest eligible free rate for K-12 students in schools located in Alameda County is 75.0%. TERMINATE\n",
      "\n",
      "================================================================================\n",
      "WORKFLOW COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Process messages and show coordinator decisions\n",
    "step_count = 0\n",
    "max_steps = 50  # Safety limit to prevent infinite loops\n",
    "\n",
    "async for message in stream:\n",
    "    if hasattr(message, 'source') and message.source == 'coordinator':\n",
    "        step_count += 1\n",
    "        print(f\"\\n[Step {step_count}] Coordinator:\")\n",
    "        \n",
    "        if hasattr(message, 'content'):\n",
    "            if isinstance(message.content, list) and len(message.content) > 0:\n",
    "                # Tool calls\n",
    "                for tool_call in message.content:\n",
    "                    if hasattr(tool_call, 'name'):\n",
    "                        print(f\"  → Calling {tool_call.name}\")\n",
    "            elif isinstance(message.content, str):\n",
    "                # Show decision reasoning\n",
    "                preview = message.content[:200] + \"...\" if len(message.content) > 200 else message.content\n",
    "                print(f\"  Decision: {preview}\")\n",
    "        \n",
    "        # Safety check for max steps\n",
    "        if step_count >= max_steps:\n",
    "            print(f\"\\n⚠️  Reached maximum steps ({max_steps}). Stopping to prevent infinite loop.\")\n",
    "            print(\"The workflow may not have completed properly.\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WORKFLOW COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ WORKFLOW MARKED AS COMPLETE\n",
      "✅ All nodes have good quality results\n",
      "\n",
      "📊 Results Summary:\n",
      "  • Find the highest percentage of students eligible f...\n",
      "    Result: [1.0]\n",
      "    Quality: excellent\n"
     ]
    }
   ],
   "source": [
    "# Check if workflow actually completed\n",
    "is_complete = await check_workflow_completion()\n",
    "\n",
    "if not is_complete:\n",
    "    print(\"\\n⚠️  Workflow did not complete properly!\")\n",
    "    print(\"The coordinator may have failed to detect completion.\")\n",
    "    print(\"Check the logs above for 'workflow complete' messages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CURRENT WORKFLOW STATE\n",
      "============================================================\n",
      "\n",
      "Current Node: node_1748191420.113068_root\n",
      "Workflow Complete: Yes\n",
      "\n",
      "Query Tree:\n",
      "  Total nodes: 1\n",
      "  executed_success: 1\n"
     ]
    }
   ],
   "source": [
    "# Show current state\n",
    "await display_current_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WORKFLOW PROGRESS\n",
      "============================================================\n",
      "→ 068_root [I,M,S,E,Q:E] Find the highest percentage of students ...\n",
      "\n",
      "Legend: I=Intent, M=Mapping, S=SQL, E=Executed, Q=Quality\n"
     ]
    }
   ],
   "source": [
    "# Show progress\n",
    "await display_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL SQL RESULTS\n",
      "============================================================\n",
      "\n",
      "Node: node_1748191420.113068_root\n",
      "Intent: Find the highest percentage of students eligible for free meals in K-12 schools located in Alameda County.\n",
      "\n",
      "SQL:\n",
      "SELECT MAX(f.\"Percent (%) Eligible Free (K-12)\") AS max_percentage FROM frpm AS f WHERE f.\"County Name\" = 'Alameda'\n",
      "\n",
      "Result: 1 rows\n",
      "Data:\n",
      "  [1.0]\n"
     ]
    }
   ],
   "source": [
    "# Show final results\n",
    "tree = await tree_manager.get_tree()\n",
    "if tree and \"nodes\" in tree:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL SQL RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for node_id, node_data in tree[\"nodes\"].items():\n",
    "        if node_data.get(\"sql\") and node_data.get(\"executionResult\"):\n",
    "            print(f\"\\nNode: {node_id}\")\n",
    "            print(f\"Intent: {node_data['intent']}\")\n",
    "            print(f\"\\nSQL:\\n{node_data['sql']}\")\n",
    "            \n",
    "            result = node_data['executionResult']\n",
    "            print(f\"\\nResult: {result.get('rowCount', 0)} rows\")\n",
    "            if result.get('data'):\n",
    "                print(\"Data:\")\n",
    "                for row in result['data'][:5]:\n",
    "                    print(f\"  {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test with Complex Query\n",
    "\n",
    "Let's test the flexible workflow with a more complex query that creates multiple nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:50,379 - root - INFO - [KeyValueMemory] Memory cleared.\n",
      "2025-05-25 12:43:50,379 - TaskContextManager - INFO - Initialized task context for task complex_demo\n",
      "2025-05-25 12:43:50,379 - DatabaseSchemaManager - INFO - Initialized empty database schema\n",
      "2025-05-25 12:43:50,379 - DatabaseSchemaManager - INFO - Added table 'frpm' to schema\n",
      "2025-05-25 12:43:50,380 - DatabaseSchemaManager - INFO - Added table 'satscores' to schema\n",
      "2025-05-25 12:43:50,381 - DatabaseSchemaManager - INFO - Added table 'schools' to schema\n",
      "2025-05-25 12:43:50,381 - DatabaseSchemaManager - INFO - Loaded schema for database 'california_schools' with 3 tables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Query: Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Clear memory for fresh start\n",
    "await memory.clear()\n",
    "\n",
    "# Use a complex query\n",
    "complex_query = test_queries[2]  # Top 5 counties query\n",
    "print(f\"Complex Query: {complex_query}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Reinitialize\n",
    "await task_manager.initialize(\"complex_demo\", complex_query, db_name)\n",
    "await schema_manager.load_from_schema_reader(schema_reader, db_name)\n",
    "\n",
    "# Run workflow\n",
    "stream = team.run_stream(task=complex_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] → query_analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:55,165 - QueryTreeManager - INFO - Initialized query tree with root node node_1748191435.165911_root\n",
      "2025-05-25 12:43:55,166 - NodeHistoryManager - INFO - Added create operation for node node_1748191435.165911_root\n",
      "2025-05-25 12:43:55,166 - QueryTreeManager - INFO - Added node node_1748191435.166639_1 to tree\n",
      "2025-05-25 12:43:55,167 - NodeHistoryManager - INFO - Added create operation for node node_1748191435.166639_1\n",
      "2025-05-25 12:43:55,167 - QueryTreeManager - INFO - Added node node_1748191435.167253_2 to tree\n",
      "2025-05-25 12:43:55,167 - NodeHistoryManager - INFO - Added create operation for node node_1748191435.167253_2\n",
      "2025-05-25 12:43:55,167 - QueryTreeManager - INFO - Added node node_1748191435.167859_3 to tree\n",
      "2025-05-25 12:43:55,168 - NodeHistoryManager - INFO - Added create operation for node node_1748191435.167859_3\n",
      "2025-05-25 12:43:55,168 - QueryTreeManager - INFO - Updated node node_1748191435.165911_root\n",
      "2025-05-25 12:43:55,168 - QueryAnalyzerAgent - INFO - Complex query - set first child node_1748191435.166639_1 as current node\n",
      "2025-05-25 12:43:55,168 - QueryAnalyzerAgent - INFO - Query analysis completed. Complexity: complex. Root node: node_1748191435.165911_root\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] → query_analyzer\n",
      "[4] → schema_linker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:43:58,647 - QueryTreeManager - INFO - Updated node node_1748191435.166639_1\n",
      "2025-05-25 12:43:58,648 - NodeHistoryManager - INFO - Added revise operation for node node_1748191435.166639_1\n",
      "2025-05-25 12:43:58,648 - SchemaLinkerAgent - INFO - Updated node node_1748191435.166639_1 with schema mapping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] → schema_linker\n",
      "[7] → sql_generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:44:02,438 - QueryTreeManager - INFO - Updated node node_1748191435.166639_1\n",
      "2025-05-25 12:44:02,438 - NodeHistoryManager - INFO - Added generate_sql operation for node node_1748191435.166639_1\n",
      "2025-05-25 12:44:02,439 - SQLGeneratorAgent - INFO - Updated node node_1748191435.166639_1 with generated SQL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] → sql_generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:44:03,050 - SQLEvaluatorAgent - INFO - Using current node from memory: node_1748191435.166639_1\n",
      "2025-05-25 12:44:03,051 - SQLEvaluatorAgent - INFO - Executing SQL for node node_1748191435.166639_1 on database california_schools\n",
      "2025-05-25 12:44:03,052 - QueryTreeManager - INFO - Updated node node_1748191435.166639_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SQLExecutor] Connecting to database: /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "[10] → sql_evaluator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:44:05,507 - SQLEvaluatorAgent - INFO - Stored analysis for node node_1748191435.166639_1 - Answers intent: yes, Quality: excellent\n",
      "2025-05-25 12:44:05,508 - SQLEvaluatorAgent - INFO - Root node node_1748191435.166639_1 and all descendants are good - workflow complete\n",
      "2025-05-25 12:44:05,508 - SQLEvaluatorAgent - INFO - Analysis complete - Answers intent: yes, Quality: excellent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] → sql_evaluator\n",
      "\n",
      "Complex query workflow complete!\n"
     ]
    }
   ],
   "source": [
    "# Process complex query\n",
    "step_count = 0\n",
    "max_steps = 50\n",
    "\n",
    "async for message in stream:\n",
    "    if hasattr(message, 'source') and message.source == 'coordinator':\n",
    "        step_count += 1\n",
    "        if hasattr(message, 'content') and isinstance(message.content, list):\n",
    "            for tool_call in message.content:\n",
    "                if hasattr(tool_call, 'name'):\n",
    "                    print(f\"[{step_count}] → {tool_call.name}\")\n",
    "        \n",
    "        if step_count >= max_steps:\n",
    "            print(f\"\\n⚠️  Reached maximum steps ({max_steps})\")\n",
    "            break\n",
    "\n",
    "print(\"\\nComplex query workflow complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WORKFLOW PROGRESS\n",
      "============================================================\n",
      "  911_root [I,M] Identify the top 5 counties based on ave...\n",
      "→ 166639_1 [I,M,S,E,Q:E] Calculate average SAT scores for each co...\n",
      "  167253_2 [I,M] Count the number of schools in each coun...\n",
      "  167859_3 [I,M] Calculate the average free lunch rate fo...\n",
      "\n",
      "Legend: I=Intent, M=Mapping, S=SQL, E=Executed, Q=Quality\n",
      "\n",
      "============================================================\n",
      "CURRENT WORKFLOW STATE\n",
      "============================================================\n",
      "\n",
      "Current Node: node_1748191435.166639_1\n",
      "Workflow Complete: Yes\n",
      "\n",
      "Query Tree:\n",
      "  Total nodes: 4\n",
      "  created: 3\n",
      "  executed_success: 1\n"
     ]
    }
   ],
   "source": [
    "# Show complex query results\n",
    "await display_progress()\n",
    "await display_current_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Benefits of Flexible Workflow\n",
    "\n",
    "This flexible coordinator approach provides several advantages:\n",
    "\n",
    "1. **Intelligent Decision Making**: Coordinator examines current state before deciding\n",
    "2. **Error Recovery**: Can retry specific steps without starting over\n",
    "3. **Adaptive Behavior**: Handles both simple and complex queries naturally\n",
    "4. **Efficiency**: Skips unnecessary steps if components already exist\n",
    "5. **Debugging**: Clear visibility into decision process\n",
    "\n",
    "The coordinator can:\n",
    "- Skip schema linking if mapping already exists\n",
    "- Retry SQL generation with error context\n",
    "- Handle partial failures gracefully\n",
    "- Work with complex multi-node trees intelligently\n",
    "\n",
    "This makes the workflow more robust and efficient than a purely linear approach!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
