{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexible Orchestrator Workflow\n",
    "\n",
    "This notebook demonstrates a simplified text-to-SQL workflow where:\n",
    "1. The orchestrator only decides which tool to call next\n",
    "2. Each tool operates on the current node (determined by the code, not LLM)\n",
    "3. Tools are called with minimal input - they know what to do\n",
    "4. The orchestrator's job is to call tools or TERMINATE\n",
    "\n",
    "## Key Differences from Previous Versions:\n",
    "- **No node IDs in tool calls** - the current node is managed automatically\n",
    "- **Simple tool calls** - tools need minimal parameters\n",
    "- **Task status checker** - provides clear ACTION directives for the orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment loaded successfully\n",
      "‚úÖ OPENAI_API_KEY found in environment\n",
      "‚úÖ Logging configured for clean output\n",
      "üìù Ready to initialize memory system and agents\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add src path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Load environment variables\n",
    "try:\n",
    "    load_dotenv()\n",
    "    print(\"‚úÖ Environment loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Warning: Could not load .env file: {e}\")\n",
    "\n",
    "# Important: For running this notebook, ensure OPENAI_API_KEY is set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è  WARNING: OPENAI_API_KEY not found in environment\")\n",
    "    print(\"üìã Run: source ../.env && export OPENAI_API_KEY\")\n",
    "    print(\"üìã Or set it manually in the environment\")\n",
    "else:\n",
    "    print(\"‚úÖ OPENAI_API_KEY found in environment\")\n",
    "\n",
    "# Set up clean logging - minimal noise, focus on workflow\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,  # Higher level to reduce noise\n",
    "    format='%(name)s - %(levelname)s - %(message)s'  # Simpler format\n",
    ")\n",
    "\n",
    "# Only show agent-specific logs at INFO level\n",
    "agent_loggers = [\n",
    "    'QueryAnalyzerAgent', 'SchemaLinkerAgent', \n",
    "    'SQLGeneratorAgent', 'SQLEvaluatorAgent', 'TaskStatusChecker'\n",
    "]\n",
    "\n",
    "for logger_name in agent_loggers:\n",
    "    logging.getLogger(logger_name).setLevel(logging.INFO)\n",
    "\n",
    "# Silence very noisy libraries completely\n",
    "noisy_loggers = [\n",
    "    'autogen_core', 'autogen_agentchat', 'httpx', 'openai', \n",
    "    'httpcore', 'httpcore.connection', 'httpcore.http11'\n",
    "]\n",
    "\n",
    "for logger_name in noisy_loggers:\n",
    "    logging.getLogger(logger_name).setLevel(logging.ERROR)\n",
    "\n",
    "print(\"‚úÖ Logging configured for clean output\")\n",
    "print(\"üìù Ready to initialize memory system and agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory and managers\n",
    "from keyvalue_memory import KeyValueMemory\n",
    "from task_context_manager import TaskContextManager\n",
    "from query_tree_manager import QueryTreeManager\n",
    "from database_schema_manager import DatabaseSchemaManager\n",
    "from node_history_manager import NodeHistoryManager\n",
    "\n",
    "# Schema reader\n",
    "from schema_reader import SchemaReader\n",
    "\n",
    "# All 4 agents + task status checker\n",
    "from query_analyzer_agent import QueryAnalyzerAgent\n",
    "from schema_linker_agent import SchemaLinkerAgent\n",
    "from sql_generator_agent import SQLGeneratorAgent\n",
    "from sql_evaluator_agent import SQLEvaluatorAgent\n",
    "from task_status_checker import TaskStatusChecker\n",
    "\n",
    "# Memory types - updated imports based on actual content\n",
    "from memory_content_types import (\n",
    "    TaskContext, QueryNode, NodeStatus, TaskStatus,\n",
    "    TableSchema, ColumnInfo, ExecutionResult, NodeOperation\n",
    ")\n",
    "\n",
    "# AutoGen components\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Initializing shared memory system...\n",
      "üìã Initializing workflow managers...\n",
      "‚úÖ Shared memory and managers initialized\n",
      "   - Memory system ready for multi-agent coordination\n",
      "   - All managers connected to shared memory\n",
      "   - Ready for flexible orchestrator workflow\n"
     ]
    }
   ],
   "source": [
    "# Initialize shared memory system - foundation for all agents\n",
    "try:\n",
    "    print(\"üß† Initializing shared memory system...\")\n",
    "    memory = KeyValueMemory()\n",
    "\n",
    "    # Initialize all managers that coordinate workflow\n",
    "    print(\"üìã Initializing workflow managers...\")\n",
    "    task_manager = TaskContextManager(memory)\n",
    "    tree_manager = QueryTreeManager(memory)\n",
    "    schema_manager = DatabaseSchemaManager(memory)\n",
    "    history_manager = NodeHistoryManager(memory)\n",
    "\n",
    "    print(\"‚úÖ Shared memory and managers initialized\")\n",
    "    print(\"   - Memory system ready for multi-agent coordination\")\n",
    "    print(\"   - All managers connected to shared memory\")\n",
    "    print(\"   - Ready for flexible orchestrator workflow\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing memory system: {e}\")\n",
    "    import traceback\n",
    "    print(f\"Full error: {traceback.format_exc()}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Target Query: Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate\n",
      "üéØ Evidence: Eligible free rate for K-12 = `Free Meal Count (K-12)` / `Enrollment (K-12)`\n",
      "üìä Database: california_schools\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìù Initializing task context in shared memory...\n",
      "üìö Loading database schema into shared memory...\n",
      "load json file from /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_tables.json\n",
      "\n",
      "Loading all database info...\n",
      "Found 11 databases in bird dataset\n",
      "üå≥ Initializing query tree with root node...\n",
      "‚úÖ Query tree initialized with root node: root\n",
      "\n",
      "Loaded 'california_schools' database:\n",
      "  Tables: 3\n",
      "  Columns: 89\n",
      "  Foreign keys: 2\n",
      "\n",
      "‚úÖ All initialization complete - ready for orchestrator workflow\n"
     ]
    }
   ],
   "source": [
    "# Database configuration\n",
    "data_path = \"/home/norman/work/text-to-sql/MAC-SQL/data/bird\"\n",
    "tables_json_path = Path(data_path) / \"dev_tables.json\"\n",
    "db_name = \"california_schools\"\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What is the highest eligible free rate for K-12 students in schools located in Alameda County?\",\n",
    "    \"Show me schools with SAT scores above 1400 and their free lunch eligibility rates\",\n",
    "    \"Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate\"\n",
    "]\n",
    "\n",
    "# Pick a query (try different ones!)\n",
    "test_query = test_queries[2]  # Use the complex query that matches the output\n",
    "evidence = \"Eligible free rate for K-12 = `Free Meal Count (K-12)` / `Enrollment (K-12)`\"\n",
    "\n",
    "print(f\"üéØ Target Query: {test_query}\")\n",
    "print(f\"üéØ Evidence: {evidence}\")\n",
    "print(f\"üìä Database: {db_name}\")\n",
    "print(\"‚îÄ\" * 80)\n",
    "\n",
    "# Initialize task context in shared memory\n",
    "print(\"üìù Initializing task context in shared memory...\")\n",
    "task_id = \"flexible_demo_001\"\n",
    "await task_manager.initialize(task_id, test_query, db_name, evidence)\n",
    "\n",
    "# Load schema into shared memory\n",
    "print(\"üìö Loading database schema into shared memory...\")\n",
    "schema_reader = SchemaReader(\n",
    "    data_path=data_path,\n",
    "    tables_json_path=str(tables_json_path),\n",
    "    dataset_name=\"bird\",\n",
    "    lazy=False\n",
    ")\n",
    "\n",
    "await schema_manager.load_from_schema_reader(schema_reader, db_name)\n",
    "\n",
    "# Initialize query tree with root node\n",
    "print(\"üå≥ Initializing query tree with root node...\")\n",
    "root_id = await tree_manager.initialize(test_query, evidence)\n",
    "print(f\"‚úÖ Query tree initialized with root node: {root_id}\")\n",
    "\n",
    "# Get schema summary\n",
    "summary = await schema_manager.get_schema_summary()\n",
    "print(f\"\\nLoaded '{db_name}' database:\")\n",
    "print(f\"  Tables: {summary['table_count']}\")\n",
    "print(f\"  Columns: {summary['total_columns']}\")\n",
    "print(f\"  Foreign keys: {summary['total_foreign_keys']}\")\n",
    "print(\"\\n‚úÖ All initialization complete - ready for orchestrator workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QueryAnalyzerAgent - INFO - Initialized query_analyzer with model gpt-4o\n",
      "SchemaLinkerAgent - INFO - Initialized schema_linker with model gpt-4o\n",
      "SQLGeneratorAgent - INFO - Initialized sql_generator with model gpt-4o\n",
      "SQLEvaluatorAgent - INFO - Initialized sql_evaluator with model gpt-4o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing all agents with shared memory connection...\n",
      "‚úÖ All agents initialized and connected to shared memory\n",
      "   - QueryAnalyzerAgent: Ready for query decomposition\n",
      "   - SchemaLinkerAgent: Ready for schema mapping\n",
      "   - SQLGeneratorAgent: Ready for SQL generation\n",
      "   - SQLEvaluatorAgent: Ready for execution and evaluation\n",
      "   - TaskStatusChecker: Ready for workflow coordination\n",
      "   - All agents share the same memory space for coordination\n"
     ]
    }
   ],
   "source": [
    "# LLM configuration for all agents\n",
    "llm_config = {\n",
    "    \"model_name\": \"gpt-4o\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"timeout\": 60\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"ü§ñ Initializing all agents with shared memory connection...\")\n",
    "\n",
    "    # Initialize all agents with shared memory access\n",
    "    query_analyzer = QueryAnalyzerAgent(memory, llm_config)\n",
    "    schema_linker = SchemaLinkerAgent(memory, llm_config)\n",
    "    sql_generator = SQLGeneratorAgent(memory, llm_config)\n",
    "    sql_evaluator = SQLEvaluatorAgent(memory, llm_config)\n",
    "\n",
    "    # Initialize TaskStatusChecker (deterministic - no LLM needed)\n",
    "    task_status_checker = TaskStatusChecker(memory)\n",
    "\n",
    "    print(\"‚úÖ All agents initialized and connected to shared memory\")\n",
    "    print(\"   - QueryAnalyzerAgent: Ready for query decomposition\")\n",
    "    print(\"   - SchemaLinkerAgent: Ready for schema mapping\")\n",
    "    print(\"   - SQLGeneratorAgent: Ready for SQL generation\")\n",
    "    print(\"   - SQLEvaluatorAgent: Ready for execution and evaluation\")\n",
    "    print(\"   - TaskStatusChecker: Ready for workflow coordination\")\n",
    "    print(\"   - All agents share the same memory space for coordination\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing agents: {e}\")\n",
    "    import traceback\n",
    "    print(f\"Full error: {traceback.format_exc()}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator Agent\n",
    "The text-to-sql task is represented in a tree, the root node represent the initial user query. If it's simple, then there is only one node. If it's complex, it will be decomposed first, then process the simpler child nodes. The generated SQL of the parent node is the combination of the SQL of children nodes. TaskStatusChecker will report the overall status by navigating the complete tree. Orchestrator will based on that status report to decide how to process each node. There are 4 tools in total: schema_linker (select which tables and columns will be used in the SQL), query_analyzer (understand the intent of query, give hints for SQL generation), sql_generator (generate SQL based on all available information), sql_evaluator (execute the SQL and analyze the result, give suggestions if the SQL needs improvement). There is no order of these tools, just call them when necessary, until TaskStatusChecker report all nodes are successfuly processed (with good SQLs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Coordinator initialized successfully\n",
      "   - OpenAI client configured\n",
      "   - All agent tools registered\n",
      "   - Ready for workflow orchestration\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client for coordinator\n",
    "try:\n",
    "    coordinator_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.1,\n",
    "        timeout=120,\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    # Create flexible coordinator with status-based decision making\n",
    "    coordinator = AssistantAgent(\n",
    "        name=\"coordinator\",\n",
    "        system_message=\"\"\"You are an orchestrator for a tree-based text-to-SQL workflow system with context-aware processing.\n",
    "\n",
    "## System Overview\n",
    "- User queries are represented as a tree structure in shared memory\n",
    "- Simple queries = single root node\n",
    "- Complex queries = root node with decomposed child nodes\n",
    "- Parent node SQL = combination of child node SQLs\n",
    "- Each node maintains context including previous attempts, errors, and feedback\n",
    "- Your goal: Process all nodes until all have successful SQLs\n",
    "\n",
    "## Available Tools\n",
    "1. **schema_linker** - Identifies relevant tables/columns for the current node\n",
    "2. **query_analyzer** - Understands query intent and decomposes complex queries into subtrees\n",
    "3. **sql_generator** - Generates SQL based on linked schema and query analysis\n",
    "4. **sql_evaluator** - Executes SQL and analyzes results, suggests improvements\n",
    "5. **task_status_checker** - Reports tree status and next required action\n",
    "\n",
    "## Tool Dependencies & Constraints\n",
    "- **sql_generator** REQUIRES: Schema from current node OR parent node\n",
    "- **sql_evaluator** REQUIRES: Existing SQL in current node (skip if no SQL exists)\n",
    "- **sql_generator** LIMIT: Maximum 2 attempts per node (for easy fixes only)\n",
    "- **NEVER call same tool twice consecutively on same node** (especially schema_linker and sql_evaluator)\n",
    "\n",
    "## Tool Parameters\n",
    "All tools accept a **\"goal\"** parameter that specifies the expected action. The goal should be:\n",
    "- Contextual to the current node's state and needs\n",
    "- May include summary of previous tool outputs\n",
    "- May reference errors or feedback from prior attempts\n",
    "- Adapted based on the node's current status\n",
    "\n",
    "Example goals:\n",
    "- \"Link schema for customer orders query, focusing on date filters\"\n",
    "- \"Generate SQL incorporating feedback: add GROUP BY clause for aggregation\"\n",
    "- \"Retry SQL generation fixing the column name error\"\n",
    "- \"Evaluate SQL results, check if totals match expected business logic\"\n",
    "\n",
    "## Processing Workflow\n",
    "1. **Start**: Call task_status_checker with goal=\"check overall task status\"\n",
    "2. **Interpret status** to determine current node and its needs\n",
    "3. **Call appropriate tool** with contextual goal based on:\n",
    "   - Current node status\n",
    "   - Tool dependencies (check if prerequisites met)\n",
    "   - Previous attempts/errors (if any)\n",
    "   - Tool call history (avoid consecutive duplicates)\n",
    "4. **Iterate** until OVERALL_STATUS indicates completion\n",
    "\n",
    "## Status-Based Actions\n",
    "- **needs_schema** ‚Üí schema_linker with goal=\"link schema for [node intent]\"\n",
    "- **needs_analysis** ‚Üí query_analyzer with goal=\"analyze [node intent] for decomposition\"\n",
    "- **needs_sql** ‚Üí Check if schema exists (current/parent), then sql_generator\n",
    "- **needs_eval** ‚Üí Check if SQL exists, then sql_evaluator (skip if no SQL)\n",
    "- **bad_sql** ‚Üí \n",
    "  - If first failure: sql_generator with goal addressing specific error\n",
    "  - If second failure: Consider alternative approach or escalate\n",
    "\n",
    "## Error Handling\n",
    "- **No schema for SQL generation**: Check parent node for schema inheritance\n",
    "- **SQL generation failed twice**: Mark node as requiring manual intervention\n",
    "- **No SQL for evaluation**: Skip evaluator, check why SQL is missing\n",
    "- **Consecutive tool calls detected**: Switch to different tool or check status\n",
    "\n",
    "## Key Principles\n",
    "- Tools automatically access full context (previous attempts, errors, feedback)\n",
    "- Respect tool dependencies and constraints\n",
    "- Track SQL generation attempts per node (max 2)\n",
    "- Avoid tool repetition patterns\n",
    "- Parent nodes wait for child completion\n",
    "\n",
    "## Termination\n",
    "Say \"TERMINATE\" only when:\n",
    "- TREE OVERVIEW shows X/X nodes complete (all done)\n",
    "- No PENDING nodes remain\n",
    "- OVERALL_STATUS confirms completion\n",
    "\n",
    "Begin by calling task_status_checker with goal=\"check initial task status and identify starting point\".\n",
    "        \"\"\",\n",
    "        model_client=coordinator_client,\n",
    "        tools=[\n",
    "            schema_linker.get_tool(),\n",
    "            query_analyzer.get_tool(), \n",
    "            sql_generator.get_tool(), \n",
    "            sql_evaluator.get_tool(),\n",
    "            task_status_checker.get_tool()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Coordinator initialized successfully\")\n",
    "    print(\"   - OpenAI client configured\")\n",
    "    print(\"   - All agent tools registered\")\n",
    "    print(\"   - Ready for workflow orchestration\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing coordinator: {e}\")\n",
    "    import traceback\n",
    "    print(f\"Full error: {traceback.format_exc()}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting flexible orchestrator workflow...\n",
      "   - Query tree already initialized with root node\n",
      "   - Shared memory contains task context and database schema\n",
      "   - Coordinator will manage the workflow sequence\n",
      "‚úÖ Workflow stream created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create a team with termination condition\n",
    "try:\n",
    "    termination_condition = TextMentionTermination(\"TERMINATE\")\n",
    "    team = RoundRobinGroupChat(\n",
    "        participants=[coordinator],\n",
    "        termination_condition=termination_condition\n",
    "    )\n",
    "\n",
    "    # Run the workflow - let the coordinator manage the shared memory workflow\n",
    "    print(\"üöÄ Starting flexible orchestrator workflow...\")\n",
    "    print(\"   - Query tree already initialized with root node\")\n",
    "    print(\"   - Shared memory contains task context and database schema\")\n",
    "    print(\"   - Coordinator will manage the workflow sequence\")\n",
    "\n",
    "    stream = team.run_stream(task=\"Process the text-to-SQL workflow using shared memory\")\n",
    "    print(\"‚úÖ Workflow stream created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error starting workflow: {e}\")\n",
    "    import traceback\n",
    "    print(f\"Full error: {traceback.format_exc()}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WORKFLOW EXECUTION (Status-Based)\n",
      "================================================================================\n",
      "\n",
      "[Step 1] Calling: task_status_checker\n",
      "\n",
      "[Step 2] Calling: task_status_checker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SchemaLinkerAgent - INFO - Available tables in schema: ['frpm', 'satscores', 'schools']\n",
      "SchemaLinkerAgent - INFO - Schema linking context prepared for node: root\n",
      "SchemaLinkerAgent - INFO - Node details: {'nodeId': 'root', 'status': 'created', 'childIds': [], 'intent': 'Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate', 'schema_linking': {}, 'generation': {}, 'evaluation': {}, 'evidence': 'Eligible free rate for K-12 = `Free Meal Count (K-12)` / `Enrollment (K-12)`'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 4] Calling: schema_linker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SchemaLinkerAgent - INFO - Raw LLM output: ```xml\n",
      "<schema_linking>\n",
      "  <available_schema>\n",
      "    <tables>\n",
      "      <table name=\"frpm\">\n",
      "        <columns>\n",
      "          <column name=\"CDSCode\" type=\"text\" sample_values=\"['12345678901234', '98765432109876']\"/>\n",
      "          <column name=\"County Name\" type=\"text\" sample_values=\"['Los Angeles', 'San Diego', 'Orange']\"/>\n",
      "          <column name=\"Enrollment (K-12)\" type=\"real\" sample_values=\"[1000, 2000, 1500]\"/>\n",
      "          <column name=\"Free Meal Count (K-12)\" type=\"real\" sample_values=\"[500, 800, 600]\"/>\n",
      "        </columns>\n",
      "      </table>\n",
      "      <table name=\"satscores\">\n",
      "        <columns>\n",
      "          <column name=\"cds\" type=\"text\" sample_values=\"['12345678901234', '98765432109876']\"/>\n",
      "          <column name=\"cname\" type=\"text\" sample_values=\"['Los Angeles', 'San Diego', 'Orange']\"/>\n",
      "          <column name=\"AvgScrRead\" type=\"integer\" sample_values=\"[500, 550, 600]\"/>\n",
      "          <column name=\"AvgScrMath\" type=\"integer\" sample_values=\"[520, 530, 610]\"/>\n",
      "          <column name=\"AvgScrWrite\" type=\"integer\" sample_values=\"[510, 540, 620]\"/>\n",
      "        </columns>\n",
      "      </table>\n",
      "      <table name=\"schools\">\n",
      "        <columns>\n",
      "          <column name=\"CDSCode\" type=\"text\" sample_values=\"['12345678901234', '98765432109876']\"/>\n",
      "          <column name=\"County\" type=\"text\" sample_values=\"['Los Angeles', 'San Diego', 'Orange']\"/>\n",
      "        </columns>\n",
      "      </table>\n",
      "    </tables>\n",
      "  </available_schema>\n",
      "  \n",
      "  <column_discovery>\n",
      "    <query_term original=\"average SAT scores\">\n",
      "      <all_candidates>\n",
      "        <candidate table=\"satscores\" column=\"AvgScrRead\" confidence=\"high\">\n",
      "          <typical_values><![CDATA[[500, 550, 600]]]></typical_values>\n",
      "          <exact_match_value>500</exact_match_value>\n",
      "          <reason>Exact match found in typical_values</reason>\n",
      "        </candidate>\n",
      "        <candidate table=\"satscores\" column=\"AvgScrMath\" confidence=\"high\">\n",
      "          <typical_values><![CDATA[[520, 530, 610]]]></typical_values>\n",
      "          <exact_match_value>520</exact_match_value>\n",
      "          <reason>Exact match found in typical_values</reason>\n",
      "        </candidate>\n",
      "        <candidate table=\"satscores\" column=\"AvgScrWrite\" confidence=\"high\">\n",
      "          <typical_values><![CDATA[[510, 540, 620]]]></typical_values>\n",
      "          <exact_match_value>510</exact_match_value>\n",
      "          <reason>Exact match found in typical_values</reason>\n",
      "        </candidate>\n",
      "      </all_candidates>\n",
      "      <selected_columns>\n",
      "        <column table=\"satscores\" column=\"AvgScrRead\">\n",
      "          <exact_value>500</exact_value>\n",
      "          <reason>Selected because of exact value match and single-table solution possible</reason>\n",
      "        </column>\n",
      "        <column table=\"satscores\" column=\"AvgScrMath\">\n",
      "          <exact_value>520</exact_value>\n",
      "          <reason>Selected because of exact value match and single-table solution possible</reason>\n",
      "        </column>\n",
      "        <column table=\"satscores\" column=\"AvgScrWrite\">\n",
      "          <exact_value>510</exact_value>\n",
      "          <reason>Selected because of exact value match and single-table solution possible</reason>\n",
      "        </column>\n",
      "      </selected_columns>\n",
      "    </query_term>\n",
      "    <query_term original=\"number of schools\">\n",
      "      <all_candidates>\n",
      "        <candidate table=\"schools\" column=\"CDSCode\" confidence=\"medium\">\n",
      "          <typical_values><![CDATA[['12345678901234', '98765432109876']]]></typical_values>\n",
      "          <partial_match_value>12345678901234</partial_match_value>\n",
      "          <reason>Partial match or column name similarity</reason>\n",
      "        </candidate>\n",
      "      </all_candidates>\n",
      "      <selected_columns>\n",
      "        <column table=\"schools\" column=\"CDSCode\">\n",
      "          <exact_value>12345678901234</exact_value>\n",
      "          <reason>Selected for counting number of schools</reason>\n",
      "        </column>\n",
      "      </selected_columns>\n",
      "    </query_term>\n",
      "    <query_term original=\"average free lunch rate\">\n",
      "      <all_candidates>\n",
      "        <candidate table=\"frpm\" column=\"Free Meal Count (K-12)\" confidence=\"high\">\n",
      "          <typical_values><![CDATA[[500, 800, 600]]]></typical_values>\n",
      "          <exact_match_value>500</exact_match_value>\n",
      "          <reason>Exact match found in typical_values</reason>\n",
      "        </candidate>\n",
      "        <candidate table=\"frpm\" column=\"Enrollment (K-12)\" confidence=\"high\">\n",
      "          <typical_values><![CDATA[[1000, 2000, 1500]]]></typical_values>\n",
      "          <exact_match_value>1000</exact_match_value>\n",
      "          <reason>Exact match found in typical_values</reason>\n",
      "        </candidate>\n",
      "      </all_candidates>\n",
      "      <selected_columns>\n",
      "        <column table=\"frpm\" column=\"Free Meal Count (K-12)\">\n",
      "          <exact_value>500</exact_value>\n",
      "          <reason>Selected because of exact value match and calculation requirement</reason>\n",
      "        </column>\n",
      "        <column table=\"frpm\" column=\"Enrollment (K-12)\">\n",
      "          <exact_value>1000</exact_value>\n",
      "          <reason>Selected because of exact value match and calculation requirement</reason>\n",
      "        </column>\n",
      "      </selected_columns>\n",
      "    </query_term>\n",
      "  </column_discovery>\n",
      "  \n",
      "  <single_table_analysis>\n",
      "    <possible>false</possible>\n",
      "    <best_single_table></best_single_table>\n",
      "    <reason>Multiple tables are needed to gather all required data: SAT scores, number of schools, and free lunch rate.</reason>\n",
      "  </single_table_analysis>\n",
      "  \n",
      "  <selected_tables>\n",
      "    <table name=\"satscores\" alias=\"ss\">\n",
      "      <purpose>To calculate average SAT scores</purpose>\n",
      "      <single_table_solution>false</single_table_solution>\n",
      "      <columns>\n",
      "        <column name=\"cname\" used_for=\"group\">\n",
      "          <reason>To group by county name</reason>\n",
      "        </column>\n",
      "        <column name=\"AvgScrRead\" used_for=\"aggregate\">\n",
      "          <reason>To calculate average SAT reading score</reason>\n",
      "        </column>\n",
      "        <column name=\"AvgScrMath\" used_for=\"aggregate\">\n",
      "          <reason>To calculate average SAT math score</reason>\n",
      "        </column>\n",
      "        <column name=\"AvgScrWrite\" used_for=\"aggregate\">\n",
      "          <reason>To calculate average SAT writing score</reason>\n",
      "        </column>\n",
      "      </columns>\n",
      "    </table>\n",
      "    <table name=\"schools\" alias=\"s\">\n",
      "      <purpose>To count the number of schools per county</purpose>\n",
      "      <single_table_solution>false</single_table_solution>\n",
      "      <columns>\n",
      "        <column name=\"County\" used_for=\"group\">\n",
      "          <reason>To group by county name</reason>\n",
      "        </column>\n",
      "        <column name=\"CDSCode\" used_for=\"count\">\n",
      "          <reason>To count the number of schools</reason>\n",
      "        </column>\n",
      "      </columns>\n",
      "    </table>\n",
      "    <table name=\"frpm\" alias=\"f\">\n",
      "      <purpose>To calculate the average free lunch rate</purpose>\n",
      "      <single_table_solution>false</single_table_solution>\n",
      "      <columns>\n",
      "        <column name=\"County Name\" used_for=\"group\">\n",
      "          <reason>To group by county name</reason>\n",
      "        </column>\n",
      "        <column name=\"Free Meal Count (K-12)\" used_for=\"aggregate\">\n",
      "          <reason>To calculate total free meal count</reason>\n",
      "        </column>\n",
      "        <column name=\"Enrollment (K-12)\" used_for=\"aggregate\">\n",
      "          <reason>To calculate total enrollment for free lunch rate</reason>\n",
      "        </column>\n",
      "      </columns>\n",
      "    </table>\n",
      "  </selected_tables>\n",
      "  \n",
      "  <joins>\n",
      "    <join>\n",
      "      <from_table>satscores</from_table>\n",
      "      <from_column>cds</from_column>\n",
      "      <to_table>schools</to_table>\n",
      "      <to_column>CDSCode</to_column>\n",
      "      <join_type>INNER</join_type>\n",
      "    </join>\n",
      "    <join>\n",
      "      <from_table>schools</from_table>\n",
      "      <from_column>CDSCode</from_column>\n",
      "      <to_table>frpm</to_table>\n",
      "      <to_column>CDSCode</to_column>\n",
      "      <join_type>INNER</join_type>\n",
      "    </join>\n",
      "  </joins>\n",
      "</schema_linking>\n",
      "```\n",
      "SchemaLinkerAgent - INFO - Stored schema linking result in query tree node root\n",
      "SchemaLinkerAgent - INFO - ============================================================\n",
      "SchemaLinkerAgent - INFO - Schema Linking\n",
      "SchemaLinkerAgent - INFO - Query intent: Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate\n",
      "SchemaLinkerAgent - INFO - Column Discovery Process:\n",
      "SchemaLinkerAgent - INFO -   {'query_term': [{'original': 'average SAT scores', 'all_candidates': {'candidate': [{'table': 'satscores', 'column': 'AvgScrRead', 'confidence': 'high', 'typical_values': '[500, 550, 600]', 'exact_match_value': '500', 'reason': 'Exact match found in typical_values'}, {'table': 'satscores', 'column': 'AvgScrMath', 'confidence': 'high', 'typical_values': '[520, 530, 610]', 'exact_match_value': '520', 'reason': 'Exact match found in typical_values'}, {'table': 'satscores', 'column': 'AvgScrWrite', 'confidence': 'high', 'typical_values': '[510, 540, 620]', 'exact_match_value': '510', 'reason': 'Exact match found in typical_values'}]}, 'selected_columns': {'column': [{'table': 'satscores', 'column': 'AvgScrRead', 'exact_value': '500', 'reason': 'Selected because of exact value match and single-table solution possible'}, {'table': 'satscores', 'column': 'AvgScrMath', 'exact_value': '520', 'reason': 'Selected because of exact value match and single-table solution possible'}, {'table': 'satscores', 'column': 'AvgScrWrite', 'exact_value': '510', 'reason': 'Selected because of exact value match and single-table solution possible'}]}}, {'original': 'number of schools', 'all_candidates': {'candidate': {'table': 'schools', 'column': 'CDSCode', 'confidence': 'medium', 'typical_values': \"['12345678901234', '98765432109876']\", 'partial_match_value': '12345678901234', 'reason': 'Partial match or column name similarity'}}, 'selected_columns': {'column': {'table': 'schools', 'column': 'CDSCode', 'exact_value': '12345678901234', 'reason': 'Selected for counting number of schools'}}}, {'original': 'average free lunch rate', 'all_candidates': {'candidate': [{'table': 'frpm', 'column': 'Free Meal Count (K-12)', 'confidence': 'high', 'typical_values': '[500, 800, 600]', 'exact_match_value': '500', 'reason': 'Exact match found in typical_values'}, {'table': 'frpm', 'column': 'Enrollment (K-12)', 'confidence': 'high', 'typical_values': '[1000, 2000, 1500]', 'exact_match_value': '1000', 'reason': 'Exact match found in typical_values'}]}, 'selected_columns': {'column': [{'table': 'frpm', 'column': 'Free Meal Count (K-12)', 'exact_value': '500', 'reason': 'Selected because of exact value match and calculation requirement'}, {'table': 'frpm', 'column': 'Enrollment (K-12)', 'exact_value': '1000', 'reason': 'Selected because of exact value match and calculation requirement'}]}}]}\n",
      "SchemaLinkerAgent - INFO - Linked 3 table(s):\n",
      "SchemaLinkerAgent - INFO -   - satscores: To calculate average SAT scores\n",
      "SchemaLinkerAgent - INFO -   - schools: To count the number of schools per county\n",
      "SchemaLinkerAgent - INFO -   - frpm: To calculate the average free lunch rate\n",
      "SchemaLinkerAgent - INFO - Joins: 2\n",
      "SchemaLinkerAgent - INFO -   - satscores ‚Üí schools\n",
      "SchemaLinkerAgent - INFO -   - schools ‚Üí frpm\n",
      "SchemaLinkerAgent - INFO - ============================================================\n",
      "SchemaLinkerAgent - INFO - Updated node root with schema mapping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 5] Calling: schema_linker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SQLGeneratorAgent - INFO - SQL generator context prepared for node: root\n",
      "SQLGeneratorAgent - INFO - Node detail: {'nodeId': 'root', 'status': 'created', 'childIds': [], 'intent': 'Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate', 'schema_linking': {'available_schema': {'tables': {'table': [{'name': 'frpm', 'columns': {'column': [{'name': 'CDSCode', 'type': 'text', 'sample_values': \"['12345678901234', '98765432109876']\"}, {'name': 'County Name', 'type': 'text', 'sample_values': \"['Los Angeles', 'San Diego', 'Orange']\"}, {'name': 'Enrollment (K-12)', 'type': 'real', 'sample_values': '[1000, 2000, 1500]'}, {'name': 'Free Meal Count (K-12)', 'type': 'real', 'sample_values': '[500, 800, 600]'}]}}, {'name': 'satscores', 'columns': {'column': [{'name': 'cds', 'type': 'text', 'sample_values': \"['12345678901234', '98765432109876']\"}, {'name': 'cname', 'type': 'text', 'sample_values': \"['Los Angeles', 'San Diego', 'Orange']\"}, {'name': 'AvgScrRead', 'type': 'integer', 'sample_values': '[500, 550, 600]'}, {'name': 'AvgScrMath', 'type': 'integer', 'sample_values': '[520, 530, 610]'}, {'name': 'AvgScrWrite', 'type': 'integer', 'sample_values': '[510, 540, 620]'}]}}, {'name': 'schools', 'columns': {'column': [{'name': 'CDSCode', 'type': 'text', 'sample_values': \"['12345678901234', '98765432109876']\"}, {'name': 'County', 'type': 'text', 'sample_values': \"['Los Angeles', 'San Diego', 'Orange']\"}]}}]}}, 'column_discovery': {'query_term': [{'original': 'average SAT scores', 'all_candidates': {'candidate': [{'table': 'satscores', 'column': 'AvgScrRead', 'confidence': 'high', 'typical_values': '[500, 550, 600]', 'exact_match_value': '500', 'reason': 'Exact match found in typical_values'}, {'table': 'satscores', 'column': 'AvgScrMath', 'confidence': 'high', 'typical_values': '[520, 530, 610]', 'exact_match_value': '520', 'reason': 'Exact match found in typical_values'}, {'table': 'satscores', 'column': 'AvgScrWrite', 'confidence': 'high', 'typical_values': '[510, 540, 620]', 'exact_match_value': '510', 'reason': 'Exact match found in typical_values'}]}, 'selected_columns': {'column': [{'table': 'satscores', 'column': 'AvgScrRead', 'exact_value': '500', 'reason': 'Selected because of exact value match and single-table solution possible'}, {'table': 'satscores', 'column': 'AvgScrMath', 'exact_value': '520', 'reason': 'Selected because of exact value match and single-table solution possible'}, {'table': 'satscores', 'column': 'AvgScrWrite', 'exact_value': '510', 'reason': 'Selected because of exact value match and single-table solution possible'}]}}, {'original': 'number of schools', 'all_candidates': {'candidate': {'table': 'schools', 'column': 'CDSCode', 'confidence': 'medium', 'typical_values': \"['12345678901234', '98765432109876']\", 'partial_match_value': '12345678901234', 'reason': 'Partial match or column name similarity'}}, 'selected_columns': {'column': {'table': 'schools', 'column': 'CDSCode', 'exact_value': '12345678901234', 'reason': 'Selected for counting number of schools'}}}, {'original': 'average free lunch rate', 'all_candidates': {'candidate': [{'table': 'frpm', 'column': 'Free Meal Count (K-12)', 'confidence': 'high', 'typical_values': '[500, 800, 600]', 'exact_match_value': '500', 'reason': 'Exact match found in typical_values'}, {'table': 'frpm', 'column': 'Enrollment (K-12)', 'confidence': 'high', 'typical_values': '[1000, 2000, 1500]', 'exact_match_value': '1000', 'reason': 'Exact match found in typical_values'}]}, 'selected_columns': {'column': [{'table': 'frpm', 'column': 'Free Meal Count (K-12)', 'exact_value': '500', 'reason': 'Selected because of exact value match and calculation requirement'}, {'table': 'frpm', 'column': 'Enrollment (K-12)', 'exact_value': '1000', 'reason': 'Selected because of exact value match and calculation requirement'}]}}]}, 'single_table_analysis': {'possible': 'false', 'best_single_table': {}, 'reason': 'Multiple tables are needed to gather all required data: SAT scores, number of schools, and free lunch rate.'}, 'selected_tables': {'table': [{'name': 'satscores', 'alias': 'ss', 'purpose': 'To calculate average SAT scores', 'single_table_solution': 'false', 'columns': {'column': [{'name': 'cname', 'used_for': 'group', 'reason': 'To group by county name'}, {'name': 'AvgScrRead', 'used_for': 'aggregate', 'reason': 'To calculate average SAT reading score'}, {'name': 'AvgScrMath', 'used_for': 'aggregate', 'reason': 'To calculate average SAT math score'}, {'name': 'AvgScrWrite', 'used_for': 'aggregate', 'reason': 'To calculate average SAT writing score'}]}}, {'name': 'schools', 'alias': 's', 'purpose': 'To count the number of schools per county', 'single_table_solution': 'false', 'columns': {'column': [{'name': 'County', 'used_for': 'group', 'reason': 'To group by county name'}, {'name': 'CDSCode', 'used_for': 'count', 'reason': 'To count the number of schools'}]}}, {'name': 'frpm', 'alias': 'f', 'purpose': 'To calculate the average free lunch rate', 'single_table_solution': 'false', 'columns': {'column': [{'name': 'County Name', 'used_for': 'group', 'reason': 'To group by county name'}, {'name': 'Free Meal Count (K-12)', 'used_for': 'aggregate', 'reason': 'To calculate total free meal count'}, {'name': 'Enrollment (K-12)', 'used_for': 'aggregate', 'reason': 'To calculate total enrollment for free lunch rate'}]}}]}, 'joins': {'join': [{'from_table': 'satscores', 'from_column': 'cds', 'to_table': 'schools', 'to_column': 'CDSCode', 'join_type': 'INNER'}, {'from_table': 'schools', 'from_column': 'CDSCode', 'to_table': 'frpm', 'to_column': 'CDSCode', 'join_type': 'INNER'}]}}, 'generation': {}, 'evaluation': {}, 'evidence': 'Eligible free rate for K-12 = `Free Meal Count (K-12)` / `Enrollment (K-12)`'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 7] Calling: sql_generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SQLGeneratorAgent - INFO - Raw LLM output: <generation>\n",
      "  <query_type>complex</query_type>\n",
      "  <sql>\n",
      "    SELECT \n",
      "      ss.cname AS County,\n",
      "      AVG((ss.AvgScrRead + ss.AvgScrMath + ss.AvgScrWrite) / 3.0) AS AvgSATScore,\n",
      "      COUNT(DISTINCT s.CDSCode) AS NumberOfSchools,\n",
      "      AVG(CAST(f.\"Free Meal Count (K-12)\" AS REAL) / f.\"Enrollment (K-12)\") AS AvgFreeLunchRate\n",
      "    FROM \n",
      "      satscores ss\n",
      "    INNER JOIN \n",
      "      schools s ON ss.cds = s.CDSCode\n",
      "    INNER JOIN \n",
      "      frpm f ON s.CDSCode = f.CDSCode\n",
      "    GROUP BY \n",
      "      ss.cname\n",
      "    ORDER BY \n",
      "      AvgSATScore DESC\n",
      "    LIMIT 5;\n",
      "  </sql>\n",
      "  <explanation>\n",
      "    This query calculates the top 5 counties by average SAT scores. It joins the `satscores`, `schools`, and `frpm` tables to gather necessary data. The average SAT score is computed by averaging the reading, math, and writing scores. The number of schools is counted using distinct `CDSCode` values from the `schools` table. The average free lunch rate is calculated using the formula provided in the evidence, dividing the total free meal count by the total enrollment. The results are grouped by county name and ordered by the average SAT score in descending order, limiting the output to the top 5 counties.\n",
      "  </explanation>\n",
      "  <considerations>\n",
      "    - Assumptions made: The average SAT score is calculated as the mean of the reading, math, and writing scores.\n",
      "    - Limitations: Assumes all necessary data is present and correctly linked across tables.\n",
      "    - Changes from previous attempt: None, as this is a new generation.\n",
      "    - Data type formatting applied: Used CAST to ensure division in the average free lunch rate calculation is performed with real numbers.\n",
      "  </considerations>\n",
      "</generation>\n",
      "SQLGeneratorAgent - INFO - ============================================================\n",
      "SQLGeneratorAgent - INFO - SQL Generation\n",
      "SQLGeneratorAgent - INFO - Generated SQL:\n",
      "SQLGeneratorAgent - INFO -   SELECT ss.cname AS County, AVG((ss.AvgScrRead + ss.AvgScrMath + ss.AvgScrWrite) / 3.0) AS AvgSATScore, COUNT(DISTINCT s.CDSCode) AS NumberOfSchools, AVG(CAST(f.\"Free Meal Count (K-12)\" AS REAL) / f.\"Enrollment (K-12)\") AS AvgFreeLunchRate FROM satscores ss INNER JOIN schools s ON ss.cds = s.CDSCode INNER JOIN frpm f ON s.CDSCode = f.CDSCode GROUP BY ss.cname ORDER BY AvgSATScore DESC LIMIT 5;\n",
      "SQLGeneratorAgent - INFO - Explanation: This query calculates the top 5 counties by average SAT scores. It joins the `satscores`, `schools`, and `frpm` tables to gather necessary data. The average SAT score is computed by averaging the reading, math, and writing scores. The number of schools is counted using distinct `CDSCode` values from the `schools` table. The average free lunch rate is calculated using the formula provided in the evidence, dividing the total free meal count by the total enrollment. The results are grouped by county name and ordered by the average SAT score in descending order, limiting the output to the top 5 counties.\n",
      "SQLGeneratorAgent - INFO - Considerations: - Assumptions made: The average SAT score is calculated as the mean of the reading, math, and writing scores.\n",
      "    - Limitations: Assumes all necessary data is present and correctly linked across tables.\n",
      "    - Changes from previous attempt: None, as this is a new generation.\n",
      "    - Data type formatting applied: Used CAST to ensure division in the average free lunch rate calculation is performed with real numbers.\n",
      "SQLGeneratorAgent - INFO - ============================================================\n",
      "SQLGeneratorAgent - INFO - Updated node root with generated SQL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 8] Calling: sql_generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SQLEvaluatorAgent - INFO - Using current node: root\n",
      "SQLEvaluatorAgent - WARNING - No data_path in database schema metadata, using default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SQLExecutor] Connecting to database: /home/norman/work/text-to-sql/MAC-SQL/data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "\n",
      "[Step 10] Calling: sql_evaluator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SQLEvaluatorAgent - INFO - Raw LLM output: <evaluation>\n",
      "  <answers_intent>yes</answers_intent>\n",
      "  <result_quality>excellent</result_quality>\n",
      "  <result_summary>The SQL query successfully retrieves the top 5 counties by average SAT scores, including the number of schools and average free lunch rate. The results are complete, accurate, and directly address the query intent.</result_summary>\n",
      "  <generator_context_review>\n",
      "    <generator_reasoning>The SQL generator correctly identified the need to calculate the average SAT score by averaging the reading, math, and writing scores. It also correctly grouped by county and calculated the number of schools and average free lunch rate.</generator_reasoning>\n",
      "    <reasoning_validity>valid</reasoning_validity>\n",
      "    <context_notes>The generator's approach was appropriate for the query intent, and the SQL logic aligns well with the expected results.</context_notes>\n",
      "  </generator_context_review>\n",
      "  <issues>\n",
      "  </issues>\n",
      "  <suggestions>\n",
      "  </suggestions>\n",
      "  <confidence_score>1.0</confidence_score>\n",
      "</evaluation>\n",
      "SQLEvaluatorAgent - INFO - Stored complete evaluation result in query tree node root\n",
      "SQLEvaluatorAgent - INFO - ============================================================\n",
      "SQLEvaluatorAgent - INFO - SQL Execution & Evaluation\n",
      "SQLEvaluatorAgent - INFO - Query intent: Find the top 5 counties by average SAT scores, including the number of schools and average free lunch rate\n",
      "SQLEvaluatorAgent - INFO - ‚úì SQL executed successfully\n",
      "SQLEvaluatorAgent - INFO -   Returned 5 row(s)\n",
      "SQLEvaluatorAgent - INFO -   Sample results:\n",
      "SQLEvaluatorAgent - INFO -     County | AvgSATScore | NumberOfSchools | AvgFreeLunchRate\n",
      "SQLEvaluatorAgent - INFO -     Marin | 539.9259259259259 | 12 | 0.24563436693810792\n",
      "SQLEvaluatorAgent - INFO -     Nevada | 538.8666666666667 | 9 | 0.37696684492338545\n",
      "SQLEvaluatorAgent - INFO -     Santa Cruz | 534.1388888888889 | 18 | 0.2982860282087291\n",
      "SQLEvaluatorAgent - INFO -     ... and 2 more row(s)\n",
      "SQLEvaluatorAgent - INFO - Evaluation results:\n",
      "SQLEvaluatorAgent - INFO -   - Answers intent: YES\n",
      "SQLEvaluatorAgent - INFO -   - Result quality: EXCELLENT\n",
      "SQLEvaluatorAgent - INFO -   - Confidence: 1.0\n",
      "SQLEvaluatorAgent - INFO -   - Summary: The SQL query successfully retrieves the top 5 counties by average SAT scores, including the number of schools and average free lunch rate. The results are complete, accurate, and directly address the query intent.\n",
      "SQLEvaluatorAgent - INFO -   Generator context review:\n",
      "SQLEvaluatorAgent - INFO -     - Generator reasoning: The SQL generator correctly identified the need to calculate the average SAT score by averaging the reading, math, and writing scores. It also correctly grouped by county and calculated the number of schools and average free lunch rate.\n",
      "SQLEvaluatorAgent - INFO -     - Reasoning validity: VALID\n",
      "SQLEvaluatorAgent - INFO -     - Context notes: The generator's approach was appropriate for the query intent, and the SQL logic aligns well with the expected results.\n",
      "SQLEvaluatorAgent - INFO - ============================================================\n",
      "SQLEvaluatorAgent - INFO - Stored analysis for node root\n",
      "SQLEvaluatorAgent - INFO - Analysis complete - Answers intent: yes, Quality: excellent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 11] Calling: sql_evaluator\n",
      "\n",
      "[Step 13] Calling: task_status_checker\n",
      "\n",
      "[Step 14] Calling: task_status_checker\n",
      "\n",
      "[Step 16] ‚úÖ WORKFLOW COMPLETE\n",
      "\n",
      "================================================================================\n",
      "WORKFLOW COMPLETED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# Process messages with proper loop control\n",
    "step_count = 0\n",
    "max_steps = 100  # Safety limit\n",
    "last_agent_called = None\n",
    "workflow_complete = False\n",
    "retry_count = {}  # Track retries per node\n",
    "last_message_content = None  # Track duplicate messages\n",
    "duplicate_count = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WORKFLOW EXECUTION (Status-Based)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "async for message in stream:\n",
    "    # Check for duplicate messages first\n",
    "    current_content = str(message.content) if hasattr(message, 'content') else None\n",
    "    if current_content and current_content == last_message_content:\n",
    "        duplicate_count += 1\n",
    "        if duplicate_count >= 3:  # Stop after 3 identical messages\n",
    "            print(f\"\\n‚ö†Ô∏è  Detected repeated messages. Stopping to prevent infinite loop.\")\n",
    "            break\n",
    "    else:\n",
    "        duplicate_count = 0\n",
    "        last_message_content = current_content\n",
    "    \n",
    "    # Process coordinator messages\n",
    "    if hasattr(message, 'source') and message.source == 'coordinator':\n",
    "        step_count += 1\n",
    "        \n",
    "        # Check max steps IMMEDIATELY after incrementing\n",
    "        if step_count >= max_steps:\n",
    "            print(f\"\\n‚ö†Ô∏è  Reached maximum steps ({max_steps}). Stopping.\")\n",
    "            break\n",
    "        \n",
    "        if hasattr(message, 'content'):\n",
    "            if isinstance(message.content, list) and len(message.content) > 0:\n",
    "                # Tool calls\n",
    "                for tool_call in message.content:\n",
    "                    if hasattr(tool_call, 'name'):\n",
    "                        agent_name = tool_call.name\n",
    "                        last_agent_called = agent_name\n",
    "                        \n",
    "                        # Show which tool is being called\n",
    "                        print(f\"\\n[Step {step_count}] Calling: {agent_name}\")\n",
    "                        \n",
    "                        # Check for error patterns\n",
    "                        if hasattr(tool_call, 'arguments'):\n",
    "                            args = str(tool_call.arguments)\n",
    "                            if \"takes 2 positional arguments\" in args:\n",
    "                                print(f\"         ‚Üí ‚ùå Tool call error detected\")\n",
    "                                print(f\"         ‚Üí The coordinator is calling the tool incorrectly\")\n",
    "                                workflow_complete = False\n",
    "                                break\n",
    "                        \n",
    "                        # Get current node info for context (only for tools that need it)\n",
    "                        if agent_name not in [\"task_status_checker\"]:\n",
    "                            current_id = await memory.get(\"current_node_id\")\n",
    "                            if current_id:\n",
    "                                node = await tree_manager.get_node(current_id)\n",
    "                                if node:\n",
    "                                    # Show node intent\n",
    "                                    if node.intent:\n",
    "                                        print(f\"         Current node: {node.intent[:50]}...\")\n",
    "                                    \n",
    "                                    # Show node status\n",
    "                                    status_info = []\n",
    "                                    if node.mapping and node.mapping.tables:\n",
    "                                        status_info.append(\"‚úìmapped\")\n",
    "                                    else:\n",
    "                                        status_info.append(\"‚úóno-mapping\")\n",
    "                                    \n",
    "                                    if node.sql:\n",
    "                                        status_info.append(\"‚úìhas-sql\")\n",
    "                                    else:\n",
    "                                        status_info.append(\"‚úóno-sql\")\n",
    "                                    \n",
    "                                    if node.executionResult:\n",
    "                                        status_info.append(\"‚úìexecuted\")\n",
    "                                        \n",
    "                                    # Check if this is a retry\n",
    "                                    if agent_name == \"sql_generator\" and node.sql:\n",
    "                                        retry_count[current_id] = retry_count.get(current_id, 0) + 1\n",
    "                                        print(f\"         Status: {' '.join(status_info)} [RETRY #{retry_count[current_id]}]\")\n",
    "                                    else:\n",
    "                                        print(f\"         Status: {' '.join(status_info)}\")\n",
    "                            \n",
    "            elif isinstance(message.content, str):\n",
    "                # Check if this is termination\n",
    "                if \"TERMINATE\" in message.content:\n",
    "                    workflow_complete = True\n",
    "                    print(f\"\\n[Step {step_count}] ‚úÖ WORKFLOW COMPLETE\")\n",
    "                    break\n",
    "                # Check for error messages\n",
    "                elif \"error\" in message.content.lower() or \"takes 2 positional arguments\" in message.content:\n",
    "                    print(f\"\\n[Step {step_count}] ‚ùå Error in coordinator message\")\n",
    "                    print(f\"         Content: {message.content[:100]}...\")\n",
    "    \n",
    "    # Capture and display tool responses\n",
    "    elif hasattr(message, 'source') and message.source != 'coordinator':\n",
    "        if hasattr(message, 'content'):\n",
    "            content = str(message.content)\n",
    "            \n",
    "            # Check for tool errors\n",
    "            if \"takes 2 positional arguments\" in content:\n",
    "                print(f\"         ‚Üí ‚ùå Tool error: Incorrect arguments provided\")\n",
    "                print(f\"         ‚Üí This is why the workflow is stuck!\")\n",
    "                # Force stop on tool errors\n",
    "                print(f\"\\n‚ö†Ô∏è  Stopping due to tool invocation error.\")\n",
    "                break\n",
    "            \n",
    "            # Special handling for task_status_checker to show ACTION and quality\n",
    "            if last_agent_called == \"task_status_checker\" and \"ACTION:\" in content:\n",
    "                import re\n",
    "                action_match = re.search(r'ACTION:\\s*(.+?)(?:\\n|$)', content)\n",
    "                if action_match:\n",
    "                    action = action_match.group(1).strip()\n",
    "                    print(f\"         ‚Üí ACTION: {action}\")\n",
    "                    \n",
    "                    # Check for quality info\n",
    "                    if \"Evaluation Quality:\" in content:\n",
    "                        quality_match = re.search(r'Evaluation Quality:\\s*(\\w+)', content)\n",
    "                        if quality_match:\n",
    "                            quality = quality_match.group(1)\n",
    "                            print(f\"         ‚Üí Quality: {quality}\")\n",
    "                    \n",
    "                    # Show what this means\n",
    "                    if \"RETRY NODE\" in action:\n",
    "                        print(\"         ‚Üí Next: Regenerate SQL due to poor quality\")\n",
    "                    elif \"PROCESS NODE\" in action:\n",
    "                        print(\"         ‚Üí Next: Continue processing this node\")\n",
    "                    elif \"TASK COMPLETE\" in action:\n",
    "                        print(\"         ‚Üí Next: TERMINATE\")\n",
    "            \n",
    "            # Show success/failure for other tools\n",
    "            elif last_agent_called and last_agent_called != \"task_status_checker\":\n",
    "                if \"error\" in content.lower():\n",
    "                    print(f\"         ‚Üí ‚ùå Error occurred\")\n",
    "                else:\n",
    "                    print(f\"         ‚Üí ‚úÖ Success\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if workflow_complete:\n",
    "    print(\"WORKFLOW COMPLETED SUCCESSFULLY\")\n",
    "else:\n",
    "    print(\"WORKFLOW STOPPED (may not have completed)\")\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"- Check tool argument compatibility\")\n",
    "    print(\"- Verify all required parameters are provided correctly\")\n",
    "    \n",
    "# Show retry statistics\n",
    "if retry_count:\n",
    "    print(\"\\nRetry Statistics:\")\n",
    "    for node_id, count in retry_count.items():\n",
    "        print(f\"  Node {node_id[-15:]}: {count} retries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total nodes created: 1\n",
      "  executed_success: 1\n",
      "\n",
      "Nodes with SQL results:\n",
      "\n",
      "  Node: root\n",
      "  Intent: Find the top 5 counties by average SAT scores, including the...\n",
      "  Result: 5 rows\n",
      "  Sample: Marin - 539.9259259259259\n"
     ]
    }
   ],
   "source": [
    "# Show summary of what was processed\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tree = await tree_manager.get_tree()\n",
    "if tree and \"nodes\" in tree:\n",
    "    # Count nodes by status\n",
    "    status_counts = {}\n",
    "    for node_id, node_data in tree[\"nodes\"].items():\n",
    "        status = node_data.get(\"status\", \"unknown\")\n",
    "        status_counts[status] = status_counts.get(status, 0) + 1\n",
    "    \n",
    "    print(f\"\\nTotal nodes created: {len(tree['nodes'])}\")\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count}\")\n",
    "    \n",
    "    # Show nodes with results\n",
    "    print(\"\\nNodes with SQL results:\")\n",
    "    for node_id, node_data in tree[\"nodes\"].items():\n",
    "        if node_data.get(\"sql\") and node_data.get(\"executionResult\"):\n",
    "            print(f\"\\n  Node: {node_id[-15:]}\")\n",
    "            print(f\"  Intent: {node_data['intent'][:60]}...\")\n",
    "            \n",
    "            result = node_data['executionResult']\n",
    "            if result.get('data'):\n",
    "                print(f\"  Result: {result.get('rowCount', 0)} rows\")\n",
    "                # Show first result\n",
    "                first_row = result['data'][0] if result['data'] else None\n",
    "                if first_row:\n",
    "                    if isinstance(first_row, list) and len(first_row) >= 2:\n",
    "                        print(f\"  Sample: {first_row[0]} - {first_row[1]}\")\n",
    "                    else:\n",
    "                        print(f\"  Sample: {str(first_row)[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
