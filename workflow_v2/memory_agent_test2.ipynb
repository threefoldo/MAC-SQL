{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Agent Tool Test\n",
    "\n",
    "This notebook demonstrates how to use the `MemoryAgentTool` with our KeyValueMemory implementation to create agents that can read from and write to a shared memory store.\n",
    "\n",
    "The `MemoryAgentTool` class provides:\n",
    "1. **Memory integration** for agents by extending BaseTool\n",
    "2. **Pre-processing** via reader callbacks that fetch relevant context from memory before agent execution\n",
    "3. **Post-processing** via parser callbacks that extract and store information from agent outputs after execution\n",
    "4. A structured way to pass information between steps in the text-to-SQL workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Reduce noise from autogen\n",
    "logging.getLogger('autogen_core').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our KeyValueMemory and MemoryAgentTool\n",
    "from memory import KeyValueMemory\n",
    "from memory_agent_tool import MemoryAgentTool\n",
    "from workflow_utils import extract_sql_from_text\n",
    "\n",
    "# Import necessary AutoGen components\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up our memory store and model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the shared memory store\n",
    "memory = KeyValueMemory(name=\"text_to_sql_memory\")\n",
    "\n",
    "# Set up the model client - replace with your specific model\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",  # or other appropriate model\n",
    "    temperature=0.1,\n",
    "    timeout=120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define memory callback functions for different agent roles\n",
    "\n",
    "Each agent will have custom reader and parser functions that define how it interacts with memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Selector Agent memory callbacks\n",
    "async def schema_selector_reader(memory, task, cancellation_token):\n",
    "    \"\"\"Read relevant info for the schema selector agent.\"\"\"\n",
    "    # For schema selection, we might want to read previously selected schemas\n",
    "    # for similar queries to maintain consistency\n",
    "    query_history = await memory.get(\"query_history\")\n",
    "    context = {}\n",
    "    \n",
    "    if query_history:\n",
    "        context[\"query_history\"] = query_history\n",
    "        \n",
    "    # We might also want to read any schema preferences\n",
    "    schema_preferences = await memory.get(\"schema_preferences\")\n",
    "    if schema_preferences:\n",
    "        context[\"schema_preferences\"] = schema_preferences\n",
    "    \n",
    "    return context\n",
    "\n",
    "async def schema_selector_parser(memory, task, result, cancellation_token):\n",
    "    \"\"\"Parse and store schema selection results.\"\"\"\n",
    "    if result.messages:\n",
    "        last_message = result.messages[-1].content\n",
    "        \n",
    "        # Look for database schema in XML format\n",
    "        schema_match = re.search(r'<database_schema>.*?</database_schema>', last_message, re.DOTALL)\n",
    "        if schema_match:\n",
    "            schema_str = schema_match.group()\n",
    "            await memory.set(\"current_schema\", schema_str)\n",
    "            print(\"Stored schema in memory\")\n",
    "            \n",
    "        # Try to extract database ID\n",
    "        db_id_match = re.search(r'\"db_id\"\\s*:\\s*\"([^\"]+)\"', task, re.DOTALL)\n",
    "        if db_id_match:\n",
    "            db_id = db_id_match.group(1)\n",
    "            await memory.set(\"current_db_id\", db_id)\n",
    "            print(f\"Stored current_db_id: {db_id}\")\n",
    "            \n",
    "        # Store the task and response for history\n",
    "        query_history = await memory.get(\"query_history\") or []\n",
    "        task_json = json.loads(task) if isinstance(task, str) and task.strip().startswith('{') else {\"query\": task}\n",
    "        query = task_json.get(\"query\", task)\n",
    "        \n",
    "        query_history.append({\"query\": query, \"role\": \"selector\"})\n",
    "        await memory.set(\"query_history\", query_history)\n",
    "\n",
    "# SQL Generator Agent memory callbacks\n",
    "async def sql_generator_reader(memory, task, cancellation_token):\n",
    "    \"\"\"Read relevant info for the SQL generator agent.\"\"\"\n",
    "    context = {}\n",
    "    \n",
    "    # Critical: Read the database schema\n",
    "    schema = await memory.get(\"current_schema\")\n",
    "    if schema:\n",
    "        context[\"schema\"] = schema\n",
    "    \n",
    "    # Read database ID\n",
    "    db_id = await memory.get(\"current_db_id\")\n",
    "    if db_id:\n",
    "        context[\"db_id\"] = db_id\n",
    "    \n",
    "    # Read previously generated SQL for similar queries\n",
    "    query_history = await memory.get(\"query_history\")\n",
    "    if query_history:\n",
    "        sql_history = [item for item in query_history if \"sql\" in item]\n",
    "        if sql_history:\n",
    "            context[\"sql_history\"] = sql_history\n",
    "    \n",
    "    return context\n",
    "\n",
    "async def sql_generator_parser(memory, task, result, cancellation_token):\n",
    "    \"\"\"Parse and store SQL generation results.\"\"\"\n",
    "    if result.messages:\n",
    "        last_message = result.messages[-1].content\n",
    "        \n",
    "        # Extract SQL query from the response\n",
    "        sql = extract_sql_from_text(last_message)\n",
    "        if sql:\n",
    "            await memory.set(\"current_sql\", sql)\n",
    "            print(f\"Stored SQL in memory: {sql[:50]}...\")\n",
    "            \n",
    "            # Update query history\n",
    "            query_history = await memory.get(\"query_history\") or []\n",
    "            # Find the current query (should be the last one without SQL)\n",
    "            for item in reversed(query_history):\n",
    "                if \"sql\" not in item:\n",
    "                    item[\"sql\"] = sql\n",
    "                    break\n",
    "            await memory.set(\"query_history\", query_history)\n",
    "\n",
    "# SQL Executor Agent memory callbacks\n",
    "async def sql_executor_reader(memory, task, cancellation_token):\n",
    "    \"\"\"Read relevant info for the SQL executor agent.\"\"\"\n",
    "    context = {}\n",
    "    \n",
    "    # Read the database schema\n",
    "    schema = await memory.get(\"current_schema\")\n",
    "    if schema:\n",
    "        context[\"schema\"] = schema\n",
    "    \n",
    "    # Read database ID\n",
    "    db_id = await memory.get(\"current_db_id\")\n",
    "    if db_id:\n",
    "        context[\"db_id\"] = db_id\n",
    "    \n",
    "    # Read the SQL to execute\n",
    "    sql = await memory.get(\"current_sql\")\n",
    "    if sql:\n",
    "        context[\"sql\"] = sql\n",
    "    \n",
    "    return context\n",
    "\n",
    "async def sql_executor_parser(memory, task, result, cancellation_token):\n",
    "    \"\"\"Parse and store SQL execution results.\"\"\"\n",
    "    if result.messages:\n",
    "        last_message = result.messages[-1].content\n",
    "        \n",
    "        # Try to extract execution results from JSON format\n",
    "        try:\n",
    "            # Look for JSON in the response\n",
    "            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', last_message)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "                execution_result = json.loads(json_str)\n",
    "                await memory.set(\"execution_result\", execution_result)\n",
    "                print(\"Stored execution result in memory\")\n",
    "                \n",
    "                # Extract the status\n",
    "                status = execution_result.get(\"status\", \"UNKNOWN\")\n",
    "                await memory.set(\"execution_status\", status)\n",
    "                \n",
    "                # Update query history\n",
    "                query_history = await memory.get(\"query_history\") or []\n",
    "                for item in reversed(query_history):\n",
    "                    if \"sql\" in item and \"execution_result\" not in item:\n",
    "                        item[\"execution_result\"] = execution_result\n",
    "                        item[\"execution_status\"] = status\n",
    "                        break\n",
    "                await memory.set(\"query_history\", query_history)\n",
    "        except:\n",
    "            # If JSON parsing fails, store the raw result\n",
    "            await memory.set(\"execution_result_raw\", last_message)\n",
    "            print(\"Stored raw execution result in memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create our Agents with System Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system messages for each agent\n",
    "SCHEMA_SELECTOR_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a database schema selector agent. Your role is to:\n",
    "1. Analyze the natural language query\n",
    "2. Extract relevant schema parts from the database\n",
    "3. Return the selected schema in XML format wrapped in <database_schema> tags\n",
    "\n",
    "Be precise and focus only on tables and columns directly related to the query.\n",
    "\"\"\"\n",
    "\n",
    "SQL_GENERATOR_SYSTEM_MESSAGE = \"\"\"\n",
    "You are an advanced SQL query generator. Your role is to:\n",
    "1. Read the database schema provided in XML format\n",
    "2. Analyze the natural language query\n",
    "3. Generate a valid SQL query that answers the question\n",
    "4. Return your SQL query inside ```sql code blocks\n",
    "\n",
    "Make sure your SQL is valid for SQLite and follows standard SQL best practices.\n",
    "\"\"\"\n",
    "\n",
    "SQL_EXECUTOR_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a SQL execution agent. Your role is to:\n",
    "1. Execute the provided SQL query against the database\n",
    "2. Verify the results are correct and complete\n",
    "3. Handle any errors or refinements needed\n",
    "4. Return the execution results in JSON format inside ```json code blocks\n",
    "\n",
    "The JSON must include: status, final_sql, and execution_result fields.\n",
    "\"\"\"\n",
    "\n",
    "# Create the agents\n",
    "schema_selector = AssistantAgent(\n",
    "    name=\"schema_selector\",\n",
    "    system_message=SCHEMA_SELECTOR_SYSTEM_MESSAGE,\n",
    "    model_client=model_client,\n",
    "    description=\"Selects relevant parts of the database schema for a query\"\n",
    ")\n",
    "\n",
    "sql_generator = AssistantAgent(\n",
    "    name=\"sql_generator\",\n",
    "    system_message=SQL_GENERATOR_SYSTEM_MESSAGE,\n",
    "    model_client=model_client,\n",
    "    description=\"Generates SQL queries from natural language\"\n",
    ")\n",
    "\n",
    "sql_executor = AssistantAgent(\n",
    "    name=\"sql_executor\",\n",
    "    system_message=SQL_EXECUTOR_SYSTEM_MESSAGE,\n",
    "    model_client=model_client,\n",
    "    description=\"Executes SQL queries and returns results\"\n",
    ")\n",
    "\n",
    "# Wrap each agent with memory capabilities\n",
    "schema_selector_tool = MemoryAgentTool(\n",
    "    agent=schema_selector,\n",
    "    memory=memory,\n",
    "    reader_callback=schema_selector_reader,\n",
    "    parser_callback=schema_selector_parser\n",
    ")\n",
    "\n",
    "sql_generator_tool = MemoryAgentTool(\n",
    "    agent=sql_generator,\n",
    "    memory=memory,\n",
    "    reader_callback=sql_generator_reader,\n",
    "    parser_callback=sql_generator_parser\n",
    ")\n",
    "\n",
    "sql_executor_tool = MemoryAgentTool(\n",
    "    agent=sql_executor,\n",
    "    memory=memory,\n",
    "    reader_callback=sql_executor_reader,\n",
    "    parser_callback=sql_executor_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How MemoryAgentTool Works\n",
    "\n",
    "The `MemoryAgentTool` is built on top of AutoGen's BaseTool and integrates with our KeyValueMemory implementation. Let's understand how it works:\n",
    "\n",
    "1. **Initialization**: Each tool is created with:\n",
    "   - An agent (the core component that performs the task)\n",
    "   - A shared memory instance (used across multiple agents)\n",
    "   - Custom reader and parser callbacks (specific to each agent's role)\n",
    "\n",
    "2. **Memory Reader Callback**: This function is called before the agent runs and reads relevant information from memory. It returns a dictionary of context that gets added to the agent's task.\n",
    "\n",
    "3. **Memory Parser Callback**: This function is called after the agent completes its task and extracts relevant information from the agent's response to store in memory.\n",
    "\n",
    "4. **Memory Flow**: \n",
    "   - Selector agent selects schema and stores it in memory\n",
    "   - Generator agent reads the schema from memory and creates SQL\n",
    "   - Executor agent reads the SQL from memory and executes it\n",
    "   - Each agent updates the memory with its results\n",
    "\n",
    "This approach allows each agent to focus on its specific task while the memory provides a persistent state between steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Coordinator with the Memory-Enabled Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a coordinating agent with the memory-enabled tools\n",
    "coordinator = AssistantAgent(\n",
    "    name=\"text_to_sql_coordinator\",\n",
    "    system_message=\"\"\"You are a text-to-SQL workflow coordinator. You have access to three specialized tools:\n",
    "1. schema_selector: Analyzes the query and selects relevant parts of the database schema\n",
    "2. sql_generator: Generates SQL queries based on the schema and natural language query\n",
    "3. sql_executor: Executes the SQL and returns the results\n",
    "\n",
    "For any natural language query about a database, you should:\n",
    "1. First use the schema_selector tool to get the relevant schema\n",
    "2. Then use the sql_generator tool to create a SQL query\n",
    "3. Finally use the sql_executor tool to run the query and get results\n",
    "4. Summarize the results in a user-friendly way\n",
    "\n",
    "These tools share a memory system so relevant information will be passed between them automatically.\n",
    "\"\"\",\n",
    "    model_client=model_client,\n",
    "    tools=[schema_selector_tool, sql_generator_tool, sql_executor_tool],\n",
    "    description=\"Coordinates the text-to-SQL workflow using memory-enabled agent tools\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reset Memory and Set Initial Database Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:45:36,038 - root - INFO - [KeyValueMemory] Memory cleared.\n",
      "2025-05-20 12:45:36,038 - root - WARNING - Cannot auto-detect MIME type for value of type <class 'list'>. Defaulting to TEXT/PLAIN.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected dict or Image instance, got <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m memory.set(\u001b[33m\"\u001b[39m\u001b[33mschema_preferences\u001b[39m\u001b[33m\"\u001b[39m, {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_tables\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minclude_foreign_keys\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minclude_examples\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      9\u001b[39m })\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Initialize empty query history\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m memory.set(\u001b[33m\"\u001b[39m\u001b[33mquery_history\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/text-to-sql/MAC-SQL/workflow/memory.py:154\u001b[39m, in \u001b[36mKeyValueMemory.set\u001b[39m\u001b[34m(self, key, value, mime_type, metadata)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata: \n\u001b[32m    152\u001b[39m     item_metadata.update(metadata)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m content_item = \u001b[43mMemoryContent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmime_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmime_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mitem_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add(content_item)\n\u001b[32m    156\u001b[39m logging.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Set key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mac2/lib/python3.12/site-packages/autogen_core/_image.py:97\u001b[39m, in \u001b[36mImage.__get_pydantic_core_schema__.<locals>.validate\u001b[39m\u001b[34m(value, validation_info)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected dict or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instance, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Expected dict or Image instance, got <class 'list'>"
     ]
    }
   ],
   "source": [
    "# Reset memory for a fresh run\n",
    "await memory.clear()\n",
    "\n",
    "# Set preferences that will be used by the schema selector\n",
    "await memory.set(\"schema_preferences\", {\n",
    "    \"max_tables\": 5,\n",
    "    \"include_foreign_keys\": True,\n",
    "    \"include_examples\": True\n",
    "})\n",
    "\n",
    "# Initialize empty query history\n",
    "await memory.set(\"query_history\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run a Text-to-SQL Workflow\n",
    "\n",
    "Let's test the workflow with a sample query from the BIRD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample task in the expected format\n",
    "sample_task = json.dumps({\n",
    "    \"db_id\": \"hospital_1\",\n",
    "    \"query\": \"What are the names of patients who have been admitted more than twice?\",\n",
    "    \"evidence\": \"The hospital_1 database tracks patient admissions. Each patient can have multiple admissions over time.\"\n",
    "})\n",
    "\n",
    "# Run the workflow\n",
    "result = await coordinator.run(task=sample_task)\n",
    "\n",
    "# Print the final response\n",
    "for message in result.messages:\n",
    "    if message.source != \"user\":\n",
    "        print(f\"\\n{message.source}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Examine Memory After Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's in memory after running the workflow\n",
    "schema = await memory.get(\"current_schema\")\n",
    "print(f\"Schema in memory: {'Yes, length=' + str(len(schema)) if schema else 'No'}\")\n",
    "\n",
    "sql = await memory.get(\"current_sql\")\n",
    "print(f\"SQL in memory: {'Yes - ' + sql[:50] + '...' if sql else 'No'}\")\n",
    "\n",
    "result = await memory.get(\"execution_result\")\n",
    "print(f\"Execution result in memory: {'Yes' if result else 'No'}\")\n",
    "\n",
    "status = await memory.get(\"execution_status\")\n",
    "print(f\"Execution status: {status if status else 'Unknown'}\")\n",
    "\n",
    "# Print query history\n",
    "history = await memory.get(\"query_history\")\n",
    "print(f\"\\nQuery history entries: {len(history) if history else 0}\")\n",
    "if history:\n",
    "    for i, entry in enumerate(history):\n",
    "        print(f\"\\nEntry {i+1}:\")\n",
    "        print(f\"Query: {entry.get('query')}\")\n",
    "        print(f\"Role: {entry.get('role', 'unknown')}\")\n",
    "        if 'sql' in entry:\n",
    "            sql = entry['sql']\n",
    "            print(f\"SQL: {sql[:50]}{'...' if len(sql) > 50 else ''}\")\n",
    "        if 'execution_status' in entry:\n",
    "            print(f\"Status: {entry['execution_status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Running Another Query Using Existing Memory\n",
    "\n",
    "Let's run another query on the same database. The agents will use the existing memory to be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a follow-up task\n",
    "follow_up_task = json.dumps({\n",
    "    \"db_id\": \"hospital_1\",\n",
    "    \"query\": \"What is the average length of stay for patients over the age of 65?\",\n",
    "    \"evidence\": \"Admission records include admission and discharge dates.\"\n",
    "})\n",
    "\n",
    "# Run the workflow\n",
    "result = await coordinator.run(task=follow_up_task)\n",
    "\n",
    "# Print the final response\n",
    "for message in result.messages:\n",
    "    if message.source != \"user\":\n",
    "        print(f\"\\n{message.source}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check Updated Query History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Integrating with Workflow Runners\n",
    "\n",
    "To fully leverage the MemoryAgentTool in your text-to-SQL pipeline, you can integrate it with the existing workflow runners. Here's a simplified example of how to adapt the workflow runner to use memory-enabled agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryWorkflowRunner:\n",
    "    \"\"\"\n",
    "    A workflow runner that uses memory-enabled agent tools for text-to-SQL processing.\n",
    "    \n",
    "    This class manages the creation and execution of memory-enabled agent tools\n",
    "    for the text-to-SQL pipeline, maintaining state between steps and across\n",
    "    multiple queries.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_client,\n",
    "        memory=None,\n",
    "        timeout: int = 120\n",
    "    ):\n",
    "        \"\"\"Initialize the memory workflow runner.\"\"\"\n",
    "        self.model_client = model_client\n",
    "        self.memory = memory or KeyValueMemory(name=\"text_to_sql_memory\")\n",
    "        self.timeout = timeout\n",
    "        \n",
    "        # Create the agents and tools\n",
    "        self._create_agents()\n",
    "    \n",
    "    def _create_agents(self):\n",
    "        \"\"\"Create memory-enabled agents and tools.\"\"\"\n",
    "        # Create the base agents with system messages\n",
    "        self.selector_agent = AssistantAgent(\n",
    "            name=\"schema_selector\",\n",
    "            system_message=SCHEMA_SELECTOR_SYSTEM_MESSAGE,\n",
    "            model_client=self.model_client\n",
    "        )\n",
    "        \n",
    "        self.generator_agent = AssistantAgent(\n",
    "            name=\"sql_generator\",\n",
    "            system_message=SQL_GENERATOR_SYSTEM_MESSAGE,\n",
    "            model_client=self.model_client\n",
    "        )\n",
    "        \n",
    "        self.executor_agent = AssistantAgent(\n",
    "            name=\"sql_executor\",\n",
    "            system_message=SQL_EXECUTOR_SYSTEM_MESSAGE,\n",
    "            model_client=self.model_client\n",
    "        )\n",
    "        \n",
    "        # Create memory-enabled tools\n",
    "        self.selector_tool = MemoryAgentTool(\n",
    "            agent=self.selector_agent,\n",
    "            memory=self.memory,\n",
    "            reader_callback=schema_selector_reader,\n",
    "            parser_callback=schema_selector_parser\n",
    "        )\n",
    "        \n",
    "        self.generator_tool = MemoryAgentTool(\n",
    "            agent=self.generator_agent,\n",
    "            memory=self.memory,\n",
    "            reader_callback=sql_generator_reader,\n",
    "            parser_callback=sql_generator_parser\n",
    "        )\n",
    "        \n",
    "        self.executor_tool = MemoryAgentTool(\n",
    "            agent=self.executor_agent,\n",
    "            memory=self.memory,\n",
    "            reader_callback=sql_executor_reader,\n",
    "            parser_callback=sql_executor_parser\n",
    "        )\n",
    "        \n",
    "        # Create coordinator\n",
    "        self.coordinator = AssistantAgent(\n",
    "            name=\"text_to_sql_coordinator\",\n",
    "            system_message=\"\"\"You are a text-to-SQL workflow coordinator. Follow these steps:\n",
    "            1. Use schema_selector to get the database schema\n",
    "            2. Use sql_generator to create the SQL query\n",
    "            3. Use sql_executor to execute and verify the query\n",
    "            4. Summarize the results in a user-friendly way\"\"\",\n",
    "            model_client=self.model_client,\n",
    "            tools=[self.selector_tool, self.generator_tool, self.executor_tool]\n",
    "        )\n",
    "    \n",
    "    async def initialize_memory(self):\n",
    "        \"\"\"Initialize the memory for a new session.\"\"\"\n",
    "        await self.memory.clear()\n",
    "        await self.memory.set(\"query_history\", [])\n",
    "        await self.memory.set(\"schema_preferences\", {\n",
    "            \"max_tables\": 5,\n",
    "            \"include_foreign_keys\": True,\n",
    "            \"include_examples\": True\n",
    "        })\n",
    "    \n",
    "    async def run_workflow(self, task_json):\n",
    "        \"\"\"Run the text-to-SQL workflow on a task.\"\"\"\n",
    "        # Convert dict to JSON string if needed\n",
    "        if isinstance(task_json, dict):\n",
    "            task_json = json.dumps(task_json)\n",
    "            \n",
    "        # Create cancellation token\n",
    "        cancellation_token = CancellationToken()\n",
    "        \n",
    "        # Run the coordinator\n",
    "        result = await self.coordinator.run(\n",
    "            task=task_json, \n",
    "            cancellation_token=cancellation_token\n",
    "        )\n",
    "        \n",
    "        # Collect final results from memory\n",
    "        final_result = {\n",
    "            \"sql\": await self.memory.get(\"current_sql\"),\n",
    "            \"execution_result\": await self.memory.get(\"execution_result\"),\n",
    "            \"status\": await self.memory.get(\"execution_status\")\n",
    "        }\n",
    "        \n",
    "        return result, final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Demo of the MemoryWorkflowRunner\n",
    "\n",
    "Let's test our MemoryWorkflowRunner with a sample task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a memory workflow runner\n",
    "runner = MemoryWorkflowRunner(model_client=model_client)\n",
    "\n",
    "# Initialize memory\n",
    "await runner.initialize_memory()\n",
    "\n",
    "# Define a sample task\n",
    "sample_task = {\n",
    "    \"db_id\": \"restaurant_1\",\n",
    "    \"query\": \"What is the average price of items in the breakfast menu?\",\n",
    "    \"evidence\": \"The restaurant_1 database contains menu items organized by category.\"\n",
    "}\n",
    "\n",
    "# Run the workflow\n",
    "print(\"Running workflow...\")\n",
    "result, final_result = await runner.run_workflow(sample_task)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nCoordinator output:\")\n",
    "for message in result.messages:\n",
    "    if message.source != \"user\":\n",
    "        print(f\"\\n{message.source}: {message.content}\")\n",
    "        \n",
    "print(\"\\nFinal result from memory:\")\n",
    "print(f\"SQL: {final_result['sql']}\")\n",
    "print(f\"Status: {final_result['status']}\")\n",
    "if final_result['execution_result']:\n",
    "    print(\"Execution result available in memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Best Practices for Using Memory-Enabled Agent Tools\n",
    "\n",
    "When implementing memory-enabled agent tools in your workflow, follow these best practices:\n",
    "\n",
    "1. **Clearly define memory schemas** - Decide what information should be stored in memory and use consistent key names across your reader/parser functions\n",
    "\n",
    "2. **Keep reader callbacks focused** - Each reader should only fetch the information relevant to its specific agent's task\n",
    "\n",
    "3. **Write robust parser callbacks** - Handle different response formats and edge cases in your parser functions\n",
    "\n",
    "4. **Format memory context properly** - When adding memory context to a task, format it clearly so the agent can understand it\n",
    "\n",
    "5. **Use a shared memory instance** - Ensure all agents use the same memory instance to maintain state between steps\n",
    "\n",
    "6. **Check memory before queries** - Look for existing information in memory to avoid redundant work\n",
    "\n",
    "7. **Update query history** - Maintain a record of query history for future reference and learning\n",
    "\n",
    "8. **Add metadata to memory entries** - Include timestamps and other metadata with memory entries for better tracking\n",
    "\n",
    "9. **Implement error handling** - Add proper error handling in reader and parser callbacks to ensure workflow continuity\n",
    "\n",
    "10. **Test with diverse queries** - Verify memory capabilities with a variety of query types and complexity levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Conclusion\n",
    "\n",
    "The `MemoryAgentTool` provides a powerful way to add state and memory capabilities to AutoGen agents in a text-to-SQL workflow. By using a shared memory store and custom callbacks, we can create a pipeline where:\n",
    "\n",
    "1. Each agent has access to relevant information from previous steps\n",
    "2. Agents can focus on their specific tasks without needing to manage state\n",
    "3. Information is efficiently passed between workflow steps\n",
    "4. Previous queries and results can inform future processing\n",
    "\n",
    "This approach makes the text-to-SQL process more efficient and allows for more complex multi-step reasoning, while maintaining a clean separation of concerns between the different agents in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print updated query history\n",
    "history = await memory.get(\"query_history\")\n",
    "print(f\"Query history entries: {len(history) if history else 0}\")\n",
    "if history:\n",
    "    for i, entry in enumerate(history):\n",
    "        print(f\"\\nEntry {i+1}:\")\n",
    "        print(f\"Query: {entry.get('query')}\")\n",
    "        if 'sql' in entry:\n",
    "            sql = entry['sql']\n",
    "            print(f\"SQL: {sql[:50]}{'...' if len(sql) > 50 else ''}\")\n",
    "        if 'execution_status' in entry:\n",
    "            print(f\"Status: {entry['execution_status']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
