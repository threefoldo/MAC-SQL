{
 "cells": [
  {
   "cell_type": "code",
   "id": "813e25ff-20f9-4941-a181-2424190fab6e",
   "metadata": {},
   "outputs": [],
   "source": "import asyncio\nimport json\nimport os\nfrom typing import Dict, List, Any\n\n# Autogen imports\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_core import CancellationToken\nfrom autogen_agentchat.messages import TextMessage\n\n# Import from project modules\nfrom const import (\n    SELECTOR_NAME, DECOMPOSER_NAME, REFINER_NAME,\n    selector_template, decompose_template_bird, refiner_template\n)\nfrom schema_manager import SchemaManager\nfrom sql_executor import SQLExecutor\n\n# Import utilities from our new module\nfrom sql_utils import (\n    parse_json, extract_sql_from_text, format_sql, format_json_result,\n    select_schema, generate_sql, refine_sql, process_text_to_sql\n)\n\n# Set constants\nMAX_REFINEMENT_ATTEMPTS = 3\nDEFAULT_TIMEOUT = 120  # seconds\nBIRD_DATA_PATH = \"../data/bird\"\nBIRD_TABLES_JSON_PATH = os.path.join(BIRD_DATA_PATH, \"dev_tables.json\")\nDATASET_NAME = \"bird\""
  },
  {
   "cell_type": "code",
   "id": "375cd36a-7425-416f-992b-e9154887f274",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize SchemaManager and SQLExecutor\nschema_manager = SchemaManager(\n    data_path=BIRD_DATA_PATH,\n    tables_json_path=BIRD_TABLES_JSON_PATH,\n    dataset_name=DATASET_NAME,\n    lazy=False\n)\n\nsql_executor = SQLExecutor(\n    data_path=BIRD_DATA_PATH,\n    dataset_name=DATASET_NAME\n)\n\n# Tool implementation for schema selection and management\nasync def get_initial_database_schema(db_id: str) -> str:\n    \"\"\"Retrieves the full database schema information for a given database.\"\"\"\n    print(f\"[Tool] Loading schema for database: {db_id}\")\n    \n    # Load database information using SchemaManager\n    if db_id not in schema_manager.db2infos:\n        schema_manager.db2infos[db_id] = schema_manager._load_single_db_info(db_id)\n    \n    # Get database information\n    db_info = schema_manager.db2dbjsons.get(db_id, {})\n    if not db_info:\n        return json.dumps({\"error\": f\"Database '{db_id}' not found\"})\n    \n    # Generate full schema description (without pruning)\n    is_complex = schema_manager._is_complex_schema(db_id)\n    full_schema_str, full_fk_str, _ = schema_manager.generate_schema_description(\n        db_id, {}, use_gold_schema=False\n    )\n    \n    # Return schema details\n    return json.dumps({\n        \"db_id\": db_id,\n        \"table_count\": db_info.get('table_count', 0),\n        \"total_column_count\": db_info.get('total_column_count', 0),\n        \"avg_column_count\": db_info.get('avg_column_count', 0),\n        \"is_complex_schema\": is_complex,\n        \"full_schema_str\": full_schema_str,\n        \"full_fk_str\": full_fk_str\n    })\n\nasync def prune_database_schema(db_id: str, pruning_rules: Dict) -> str:\n    \"\"\"Applies pruning rules to a database schema.\"\"\"\n    print(f\"[Tool] Pruning schema for database {db_id}\")\n    \n    # Generate pruned schema description\n    schema_str, fk_str, chosen_schema = schema_manager.generate_schema_description(\n        db_id, pruning_rules, use_gold_schema=False\n    )\n    \n    # Return pruned schema\n    return json.dumps({\n        \"db_id\": db_id,\n        \"pruning_applied\": True,\n        \"pruning_rules\": pruning_rules,\n        \"pruned_schema_str\": schema_str,\n        \"pruned_fk_str\": fk_str,\n        \"tables_columns_kept\": chosen_schema\n    })\n\n# Tool implementation for SQL execution\nasync def execute_sql(sql: str, db_id: str) -> str:\n    \"\"\"Executes a SQL query on the specified database.\"\"\"\n    print(f\"[Tool] Executing SQL on database {db_id}: {sql[:100]}...\")\n    \n    # Execute SQL with timeout protection\n    result = sql_executor.safe_execute(sql, db_id)\n    \n    # Add validation information\n    is_valid, reason = sql_executor.is_valid_result(result)\n    result[\"is_valid_result\"] = is_valid\n    result[\"validation_message\"] = reason\n    \n    # Convert to JSON string\n    return json.dumps(result)"
  },
  {
   "cell_type": "code",
   "id": "5ef7198e-4266-4ca7-a1b8-71090cb9b9ef",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize model client\nmodel_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n\n# Create Schema Selector Agent\nselector_agent = AssistantAgent(\n    name=SELECTOR_NAME,\n    model_client=model_client,\n    system_message=f\"\"\"You are a Database Schema Selector specialized in analyzing database schemas for text-to-SQL tasks.\n\nYour job is to help prune large database schemas to focus on the relevant tables and columns for a given query.\n\nTASK OVERVIEW:\n1. You will receive a task with database ID, query, and evidence\n2. Use the 'get_initial_database_schema' tool to retrieve the full schema\n3. Analyze the schema complexity and relevance to the query\n4. For complex schemas, determine which tables and columns are relevant\n5. Use the 'prune_database_schema' tool to generate a focused schema\n6. Return the processed schema information for the next agent\n\nWHEN ANALYZING THE SCHEMA:\n- Study the database table structure and relationships\n- Identify tables directly mentioned or implied in the query\n- Consider foreign key relationships that might be needed\n- Follow the pruning guidelines in the following template:\n{selector_template}\n\nFORMAT YOUR FINAL RESPONSE AS JSON:\n{{\n  \"db_id\": \"<database_id>\",\n  \"query\": \"<natural_language_query>\",\n  \"evidence\": \"<any_evidence_provided>\",\n  \"pruning_applied\": true/false,\n  \"schema_str\": \"<schema_description>\",\n  \"fk_str\": \"<foreign_key_information>\"\n}}\n\nRemember that high-quality schema selection improves the accuracy of SQL generation.\"\"\",\n    tools=[get_initial_database_schema, prune_database_schema],\n)\n\n# Create Decomposer Agent\ndecomposer_agent = AssistantAgent(\n    name=DECOMPOSER_NAME,\n    model_client=model_client,\n    system_message=f\"\"\"You are a Query Decomposer specialized in converting natural language questions into SQL for the BIRD dataset.\n\nYour job is to analyze a natural language query and relevant database schema, then generate the appropriate SQL query.\n\nTASK OVERVIEW:\n1. You will receive a JSON with db_id, query, evidence, and schema information\n2. Study the database schema, focusing on tables, columns, and relationships\n3. For complex queries, break down the problem into logical steps\n4. Generate a clear, efficient SQL query that answers the question\n5. Follow the specific query decomposition template for BIRD:\n{decompose_template_bird}\n\nIMPORTANT CONSIDERATIONS:\n- BIRD queries often require domain knowledge and multiple steps\n- Carefully use the evidence provided to understand domain-specific concepts\n- Apply type conversion when comparing numeric data (CAST AS REAL/INT)\n- Ensure proper handling of NULL values\n- Use table aliases (T1, T2, etc.) for clarity, especially in JOINs\n- Always use valid SQLite syntax\n\nFORMAT YOUR FINAL RESPONSE AS JSON:\n{{\n  \"db_id\": \"<database_id>\",\n  \"query\": \"<natural_language_query>\",\n  \"evidence\": \"<any_evidence_provided>\",\n  \"sql\": \"<generated_sql_query>\",\n  \"decomposition\": [\n    \"step1_description\", \n    \"step2_description\",\n    ...\n  ]\n}}\n\nYour goal is to generate SQL that will execute correctly and return the precise information requested.\"\"\",\n    tools=[],  # SQL generation is the primary LLM task\n)\n\n# Create Refiner Agent\nrefiner_agent = AssistantAgent(\n    name=REFINER_NAME,\n    model_client=model_client,\n    system_message=f\"\"\"You are an SQL Refiner specializing in executing and fixing SQL queries for the BIRD dataset.\n\nYour job is to test SQL queries against the database, identify errors, and refine them until they execute successfully.\n\nTASK OVERVIEW:\n1. You will receive a JSON with db_id, query, evidence, schema, and SQL\n2. Use the 'execute_sql' tool to run the SQL against the database\n3. Analyze execution results or errors\n4. For errors, refine the SQL using the template:\n{refiner_template}\n5. For successful execution, validate the results are appropriate for the original query\n\nIMPORTANT CONSIDERATIONS:\n- BIRD databases have specific requirements for valid results:\n  - Results should not be empty (unless that's the expected answer)\n  - Results should not contain NULL values without justification\n  - Results should match the expected types and formats\n- Focus on SQLite-specific syntax and behaviors\n- Pay special attention to:\n  - Table and column name quoting (use backticks)\n  - Type conversions (CAST AS)\n  - JOIN conditions\n  - Subquery structure and aliases\n\nFORMAT YOUR FINAL RESPONSE AS JSON:\n{{\n  \"db_id\": \"<database_id>\",\n  \"query\": \"<natural_language_query>\",\n  \"evidence\": \"<any_evidence_provided>\",\n  \"original_sql\": \"<original_sql>\",\n  \"final_sql\": \"<refined_sql>\",\n  \"status\": \"<EXECUTION_SUCCESSFUL|REFINEMENT_NEEDED|NO_CHANGE_NEEDED>\",\n  \"execution_result\": \"<execution_result_summary>\",\n  \"refinement_explanation\": \"<explanation_of_changes>\"\n}}\n\nYour goal is to ensure the SQL query executes successfully and returns relevant results.\"\"\",\n    tools=[execute_sql],\n)"
  },
  {
   "cell_type": "code",
   "id": "17cf2a9f-18e5-44af-85f7-d82625983e9a",
   "metadata": {},
   "outputs": [],
   "source": "# Define test cases for BIRD dataset\nbird_test_cases = [\n    # Test case 1: Excellence rate calculation (basic join with aggregation)\n    {\n        \"db_id\": \"california_schools\",\n        \"query\": \"List school names of charter schools with an SAT excellence rate over the average.\",\n        \"evidence\": \"Charter schools refers to `Charter School (Y/N)` = 1 in the table frpm; Excellence rate = NumGE1500 / NumTstTakr\"\n    },\n    \n    # Test case 2: Multi-table query with numeric conditions (multiple joins)\n    {\n        \"db_id\": \"game_injury\",\n        \"query\": \"Show the names of players who have been injured for more than 3 matches in the 2010 season.\",\n        \"evidence\": \"Season info is in the game table with year 2010; injury severity is measured by the number of matches a player misses.\"\n    },\n    \n    # Test case 3: Complex aggregation with grouping\n    {\n        \"db_id\": \"formula_1\",\n        \"query\": \"What is the name of the driver who has won the most races in rainy conditions?\",\n        \"evidence\": \"Weather conditions are recorded in the races table; winner information is in the results table.\"\n    },\n    \n    # Test case 4: Temporal query with date handling\n    {\n        \"db_id\": \"loan_data\",\n        \"query\": \"Find the customer with the highest total payment amount for loans taken in the first quarter of 2011.\",\n        \"evidence\": \"First quarter means January to March (months 1-3); loan dates are stored in ISO format (YYYY-MM-DD).\"\n    }\n]\n\n# Select the test case to run (0-3)\ntest_idx = 0\ncurrent_test = bird_test_cases[test_idx]\n\nprint(f\"Selected test case {test_idx + 1}:\")\nprint(f\"Database: {current_test['db_id']}\")\nprint(f\"Query: {current_test['query']}\")\nprint(f\"Evidence: {current_test['evidence']}\")"
  },
  {
   "cell_type": "code",
   "id": "eb48cd7f-e45f-41ab-b74f-cc9cc4daadd0",
   "metadata": {},
   "outputs": [],
   "source": "# Test individual components\n\nasync def run_text_to_sql_step_by_step():\n    \"\"\"Run the text-to-SQL process step by step for the current test case.\"\"\"\n    try:\n        print(\"\\n\" + \"=\"*60)\n        print(\"STEP-BY-STEP TEXT-TO-SQL EXECUTION\")\n        print(\"=\"*60)\n        \n        # Step 1: Schema Selection\n        print(\"\\n\" + \"=\"*50)\n        print(\"STEP 1: SCHEMA SELECTION\")\n        print(\"=\"*50)\n        task, selector_content = await select_schema(\n            selector_agent=selector_agent,\n            task_json=json.dumps(current_test),\n            timeout=DEFAULT_TIMEOUT\n        )\n        \n        print(\"\\nSchema selection result summary:\")\n        print(\"-\" * 40)\n        # Verify if we got schema information\n        if \"<database_schema>\" in selector_content or \"schema_str\" in selector_content:\n            print(\"✓ Schema information successfully extracted\")\n        else:\n            print(\"⚠ Schema information may be missing or malformed\")\n        \n        # Step 2: SQL Generation\n        print(\"\\n\" + \"=\"*50)\n        print(\"STEP 2: SQL GENERATION\")\n        print(\"=\"*50)\n        decomposer_content, sql = await generate_sql(\n            decomposer_agent=decomposer_agent,\n            selector_content=selector_content,\n            task=task,\n            timeout=DEFAULT_TIMEOUT\n        )\n        \n        print(\"\\nSQL generation result summary:\")\n        print(\"-\" * 40)\n        if sql:\n            print(f\"✓ SQL query generated ({len(sql)} chars)\")\n            print(\"\\nSQL Query:\")\n            print(sql[:300] + \"...\" if len(sql) > 300 else sql)\n        else:\n            print(\"⚠ No SQL query was generated\")\n        \n        # Step 3: SQL Refinement\n        print(\"\\n\" + \"=\"*50)\n        print(\"STEP 3: SQL REFINEMENT\")\n        print(\"=\"*50)\n        result = await refine_sql(\n            refiner_agent=refiner_agent,\n            decomposer_content=decomposer_content,\n            sql=sql,\n            task=task,\n            max_refinement_attempts=MAX_REFINEMENT_ATTEMPTS,\n            timeout=DEFAULT_TIMEOUT\n        )\n        \n        # Display final result\n        print(\"\\n\" + \"=\"*50)\n        print(\"FINAL RESULT\")\n        print(\"=\"*50)\n        \n        # Display database and query info\n        print(f\"Database: {result.get('db_id', '')}\")\n        print(f\"Query: {result.get('query', '')}\")\n        \n        # Try to parse and format the result\n        try:\n            final_output = parse_json(result.get(\"final_output\", \"{}\"))\n            \n            # Display status\n            status = final_output.get(\"status\") or result.get(\"status\", \"UNKNOWN\")\n            print(f\"\\nExecution Status: {status}\")\n            \n            # Display final SQL\n            final_sql = final_output.get(\"final_sql\") or result.get(\"final_sql\", \"\")\n            if final_sql:\n                print(f\"\\nFinal SQL Query:\")\n                print(final_sql)\n            else:\n                print(\"\\n⚠ No final SQL query available\")\n                \n            # Display execution result if available\n            if \"execution_result\" in final_output:\n                print(\"\\nExecution Result:\")\n                exec_result = final_output[\"execution_result\"]\n                if isinstance(exec_result, dict):\n                    for key, value in exec_result.items():\n                        print(f\"  {key}: {value}\")\n                else:\n                    print(exec_result)\n                    \n        except Exception as e:\n            print(f\"\\nError parsing final result: {str(e)}\")\n            if \"final_sql\" in result:\n                print(f\"\\nFinal SQL:\\n{result['final_sql']}\")\n                \n        return result\n            \n    except Exception as e:\n        print(f\"\\nERROR IN EXECUTION: {str(e)}\")\n        import traceback\n        print(traceback.format_exc())\n        return {\"error\": str(e)}"
  },
  {
   "cell_type": "code",
   "id": "101bc4bd-66f2-4e76-9eeb-24c8ea06ee6c",
   "metadata": {},
   "outputs": [],
   "source": "# Run the complete text-to-SQL process for the current test case\nasync def run_complete_text_to_sql():\n    \"\"\"Run the complete text-to-SQL process in a single function call.\"\"\"\n    try:\n        print(\"\\n\" + \"=\"*60)\n        print(\"COMPLETE TEXT-TO-SQL EXECUTION\")\n        print(\"=\"*60)\n        \n        result = await process_text_to_sql(\n            selector_agent=selector_agent,\n            decomposer_agent=decomposer_agent,\n            refiner_agent=refiner_agent,\n            task_json=json.dumps(current_test),\n            max_refinement_attempts=MAX_REFINEMENT_ATTEMPTS,\n            timeout=DEFAULT_TIMEOUT\n        )\n        \n        # Display final result\n        print(\"\\n\" + \"=\"*50)\n        print(\"RESULT SUMMARY\")\n        print(\"=\"*50)\n        \n        if \"error\" in result:\n            print(f\"Error: {result['error']}\")\n            return result\n            \n        # Display database and query info\n        print(f\"Database: {result.get('db_id', '')}\")\n        print(f\"Query: {result.get('query', '')}\")\n        \n        # Display final SQL and status\n        final_sql = result.get(\"final_sql\", \"\")\n        status = result.get(\"status\", \"UNKNOWN\")\n        \n        print(f\"\\nExecution Status: {status}\")\n        \n        if final_sql:\n            print(f\"\\nFinal SQL Query:\")\n            print(final_sql)\n        else:\n            print(\"\\n⚠ No final SQL query available\")\n            \n        return result\n        \n    except Exception as e:\n        print(f\"\\nERROR IN EXECUTION: {str(e)}\")\n        import traceback\n        print(traceback.format_exc())\n        return {\"error\": str(e)}"
  },
  {
   "cell_type": "code",
   "id": "545a71f8-03e4-4f69-80ef-dce54826d94e",
   "metadata": {},
   "outputs": [],
   "source": "# Function to run tests on multiple database queries\nasync def run_all_tests():\n    \"\"\"Run text-to-SQL process on all test cases and collect results.\"\"\"\n    results = []\n    for i, test_case in enumerate(bird_test_cases):\n        print(f\"\\n\\n{'='*80}\")\n        print(f\"Test {i+1}: {test_case['db_id']} - {test_case['query']}\")\n        print(f\"{'='*80}\\n\")\n        \n        # Run the test\n        try:\n            result = await process_text_to_sql(\n                selector_agent=selector_agent,\n                decomposer_agent=decomposer_agent,\n                refiner_agent=refiner_agent,\n                task_json=json.dumps(test_case),\n                max_refinement_attempts=MAX_REFINEMENT_ATTEMPTS,\n                timeout=DEFAULT_TIMEOUT\n            )\n            results.append(result)\n            \n            # Display result summary\n            if \"error\" in result:\n                print(f\"\\nTest {i+1} completed with error: {result['error']}\")\n            else:\n                try:\n                    status = result.get(\"status\", \"UNKNOWN\")\n                    print(f\"\\nTest {i+1} completed with status: {status}\")\n                    \n                    if \"final_sql\" in result:\n                        print(f\"\\nFinal SQL Query:\")\n                        print(result[\"final_sql\"])\n                except Exception:\n                    print(f\"\\nTest {i+1} completed but couldn't parse final output\")\n            \n            print(f\"\\n{'-'*40}\")\n            print(f\"Test {i+1} completed\")\n            print(f\"{'-'*40}\\n\")\n        except Exception as e:\n            print(f\"Error in test {i+1}: {str(e)}\")\n            results.append({\"error\": str(e)})\n    \n    print(\"\\nAll tests completed!\")\n    return results"
  },
  {
   "cell_type": "code",
   "id": "e18b93e6-07a5-4d50-b4a9-7eeaa6ca2920",
   "metadata": {},
   "outputs": [],
   "source": "# Execute the step-by-step version\nawait run_text_to_sql_step_by_step()"
  },
  {
   "cell_type": "code",
   "id": "b1b6a5a1-f249-4582-97aa-2ee9f12200be",
   "metadata": {},
   "outputs": [],
   "source": "# Uncomment to execute the combined version (more concise output)\n# await run_complete_text_to_sql()"
  },
  {
   "cell_type": "code",
   "id": "9ecd7b61-21a4-43a4-91e9-f33b93c1dff7",
   "metadata": {},
   "outputs": [],
   "source": "# Uncomment to run all test cases\n# results = await run_all_tests()"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a294b9bc-1135-4088-bd4b-7c85c1405521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEXT-TO-SQL PIPELINE EXECUTION\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "STEP 1: SCHEMA SELECTION\n",
      "==================================================\n",
      "[Step 1] Starting schema selection for database 'california_schools'\n",
      "[Step 1] Query: List school names of charter schools with an SAT excellence rate over the average.\n",
      "[Step 1] Evidence: Charter schools refers to `Charter School (Y/N)` = 1 in the table frpm; Excellence rate = NumGE1500 / NumTstTakr\n",
      "[Step 1] Requesting schema selection (timeout: 120s)\n",
      "[Tool] Loading schema for database: california_schools\n",
      "[Step 1] Schema selected successfully (took 1.5s)\n",
      "\n",
      "Schema selection result summary:\n",
      "----------------------------------------\n",
      "✓ Schema information successfully extracted\n",
      "\n",
      "Preview:\n",
      "{\"db_id\": \"california_schools\", \"table_count\": 3, \"total_column_count\": 89, \"avg_column_count\": 29, \"is_complex_schema\": true, \"full_schema_str\": \"<database_schema>\\n  <table name=\\\"frpm\\\">\\n    <colu...\n",
      "\n",
      "==================================================\n",
      "STEP 2: SQL GENERATION\n",
      "==================================================\n",
      "\n",
      "[Step 2] Starting SQL generation\n",
      "[Step 2] Query: List school names of charter schools with an SAT excellence rate over the average.\n",
      "[Step 2] Warning: Could not extract schema from selector output\n",
      "[Step 2] Requesting SQL generation (timeout: 120s)\n",
      "[Step 2] SQL generation completed (took 5.9s)\n",
      "[Step 2] SQL generated: SELECT T3.`County Name`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "JOIN schools...\n",
      "\n",
      "SQL generation result summary:\n",
      "----------------------------------------\n",
      "✓ SQL query generated (242 chars)\n",
      "\n",
      "SQL Query:\n",
      "SELECT T3.`County Name`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "JOIN schools AS T3 ON T1.`CDSCode` = T3.`CDSCode`\n",
      "WHERE T1.`Charter School (Y/N)` = 1\n",
      "GROUP BY T3.`County Name`\n",
      "ORDER BY AVG(T2.`AvgScrMath`) DESC\n",
      "LIMIT 1\n",
      "\n",
      "==================================================\n",
      "STEP 3: SQL REFINEMENT\n",
      "==================================================\n",
      "\n",
      "[Step 3] Starting SQL refinement\n",
      "[Step 3] Initial SQL: SELECT T3.`County Name`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "JOIN schools...\n",
      "[Step 3] Starting refinement attempt 1/3\n",
      "[Tool] Executing SQL on database california_schools: SELECT T3.`Name`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "JOIN schools AS T3 ...\n",
      "[SQLExecutor] Connecting to database: ../data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "[Step 3] Refinement attempt 1, status: \n",
      "[Step 3] New SQL detected: SELECT T3.`Name`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "JOIN schools AS T3 ...\n",
      "[Step 3] Starting refinement attempt 2/3\n",
      "[Tool] Executing SQL on database california_schools: PRAGMA table_info(schools);...\n",
      "[SQLExecutor] Connecting to database: ../data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "[Tool] Executing SQL on database california_schools: PRAGMA table_info(frpm);...\n",
      "[SQLExecutor] Connecting to database: ../data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "[Tool] Executing SQL on database california_schools: PRAGMA table_info(satscores);...\n",
      "[SQLExecutor] Connecting to database: ../data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "Error parsing JSON: Extra data: line 2 column 1 (char 518)\n",
      "[Step 3] Refinement attempt 2, status: \n",
      "Error parsing JSON: Extra data: line 2 column 1 (char 518)\n",
      "[Step 3] No SQL found in refinement output, attempt 2\n",
      "[Step 3] Starting refinement attempt 3/3\n",
      "[Tool] Executing SQL on database california_schools: SELECT T2.`sname`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "WHERE T1.`Charter ...\n",
      "[SQLExecutor] Connecting to database: ../data/bird/dev_databases/california_schools/california_schools.sqlite\n",
      "[Step 3] Refinement attempt 3, status: \n",
      "[Step 3] New SQL detected: SELECT T2.`sname`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "WHERE T1.`Charter ...\n",
      "[Step 3] Max refinements (3) reached\n",
      "[Step 3] Refinement complete - Final status: UNKNOWN\n",
      "[Step 3] Final SQL: SELECT T2.`sname`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "WHERE T1.`Charter ...\n",
      "\n",
      "==================================================\n",
      "FINAL RESULT\n",
      "==================================================\n",
      "Database: california_schools\n",
      "Query: List school names of charter schools with an SAT excellence rate over the average.\n",
      "\n",
      "Execution Status: UNKNOWN\n",
      "\n",
      "Final SQL Query:\n",
      "SELECT T2.`sname`\n",
      "FROM frpm AS T1\n",
      "JOIN satscores AS T2 ON T1.`CDSCode` = T2.`cds`\n",
      "WHERE T1.`Charter School (Y/N)` = 1\n",
      "AND (T2.`NumGE1500` / T2.`NumTstTakr`) > (\n",
      "    SELECT AVG(T2_sub.`NumGE1500` / T2_sub.`NumTstTakr`)\n",
      "    FROM satscores AS T2_sub\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Execute each step individually with proper error handling and timeout management\n",
    "try:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEXT-TO-SQL PIPELINE EXECUTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Schema Selection\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 1: SCHEMA SELECTION\")\n",
    "    print(\"=\"*50)\n",
    "    task, selector_content = await select_schema(json.dumps(current_test))\n",
    "    \n",
    "    print(\"\\nSchema selection result summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    # Verify if we got schema information\n",
    "    if \"<database_schema>\" in selector_content or \"schema_str\" in selector_content:\n",
    "        print(\"✓ Schema information successfully extracted\")\n",
    "    else:\n",
    "        print(\"⚠ Schema information may be missing or malformed\")\n",
    "    # Print a preview of the content\n",
    "    print(\"\\nPreview:\")\n",
    "    preview = selector_content[:200] + \"...\" if len(selector_content) > 200 else selector_content\n",
    "    print(preview)\n",
    "\n",
    "    # Step 2: SQL Generation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 2: SQL GENERATION\")\n",
    "    print(\"=\"*50)\n",
    "    decomposer_content, sql = await generate_sql(selector_content, task)\n",
    "    \n",
    "    print(\"\\nSQL generation result summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    if sql:\n",
    "        print(f\"✓ SQL query generated ({len(sql)} chars)\")\n",
    "        print(\"\\nSQL Query:\")\n",
    "        print(sql[:300] + \"...\" if len(sql) > 300 else sql)\n",
    "    else:\n",
    "        print(\"⚠ No SQL query was generated\")\n",
    "        print(\"\\nDecomposer output preview:\")\n",
    "        print(decomposer_content[:200] + \"...\" if len(decomposer_content) > 200 else decomposer_content)\n",
    "\n",
    "    # Step 3: SQL Refinement\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 3: SQL REFINEMENT\")\n",
    "    print(\"=\"*50)\n",
    "    if not sql:\n",
    "        print(\"\\n⚠ Skipping refinement because no SQL was generated\")\n",
    "        result = {\n",
    "            \"db_id\": task.get('db_id', ''),\n",
    "            \"query\": task.get('query', ''),\n",
    "            \"final_output\": decomposer_content,\n",
    "            \"error\": \"No SQL generated\",\n",
    "            \"status\": \"ERROR_NO_SQL\"\n",
    "        }\n",
    "    else:\n",
    "        result = await refine_sql(decomposer_content, sql, task)\n",
    "    \n",
    "    # Display final result\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Display database and query info\n",
    "    print(f\"Database: {result.get('db_id', '')}\")\n",
    "    print(f\"Query: {result.get('query', '')}\")\n",
    "    \n",
    "    # Try to parse and format the result\n",
    "    try:\n",
    "        final_output = parse_json(result.get(\"final_output\", \"{}\"))\n",
    "        \n",
    "        # Display status\n",
    "        status = final_output.get(\"status\") or result.get(\"status\", \"UNKNOWN\")\n",
    "        print(f\"\\nExecution Status: {status}\")\n",
    "        \n",
    "        # Display final SQL\n",
    "        final_sql = final_output.get(\"final_sql\") or result.get(\"final_sql\", \"\")\n",
    "        if final_sql:\n",
    "            print(f\"\\nFinal SQL Query:\")\n",
    "            print(final_sql)\n",
    "        else:\n",
    "            print(\"\\n⚠ No final SQL query available\")\n",
    "            \n",
    "        # Display execution result if available\n",
    "        if \"execution_result\" in final_output:\n",
    "            print(\"\\nExecution Result:\")\n",
    "            exec_result = final_output[\"execution_result\"]\n",
    "            if isinstance(exec_result, dict):\n",
    "                for key, value in exec_result.items():\n",
    "                    print(f\"  {key}: {value}\")\n",
    "            else:\n",
    "                print(exec_result)\n",
    "                \n",
    "        # Display any errors\n",
    "        if \"error\" in final_output or \"error\" in result:\n",
    "            error = final_output.get(\"error\") or result.get(\"error\", \"\")\n",
    "            print(f\"\\nError: {error}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError parsing final result: {str(e)}\")\n",
    "        if \"final_sql\" in result:\n",
    "            print(f\"\\nFinal SQL:\\n{result['final_sql']}\")\n",
    "        print(\"\\nRaw output preview:\")\n",
    "        raw_output = result.get(\"final_output\", \"\")\n",
    "        print(raw_output[:500] + \"...\" if len(raw_output) > 500 else raw_output)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nCRITICAL ERROR IN EXECUTION: {str(e)}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}