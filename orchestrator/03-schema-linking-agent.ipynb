{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Linking Agent Test\n",
    "\n",
    "This notebook implements and tests the Schema Linking Agent that identifies and ranks the most relevant database schema elements for processed query parts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "from dotenv import load_dotenv\nimport json\nimport re\nfrom typing import Dict, Any, List, Optional, Tuple\nfrom difflib import SequenceMatcher\nimport logging\n\nload_dotenv()\n\n# Import unified schemas from our centralized location\nfrom schemas import (\n    # Schema Linking types\n    SchemaLinkingInput,\n    SchemaLinkingOutput,\n    SchemaElement,\n    JoinPath,\n    ExtractedEntitiesAndIntent,\n    \n    # Error types\n    SchemaLinkingError,\n    \n    # Database schemas\n    SCHEMAS,\n    QUERY_PATTERNS\n)\n\nlogger = logging.getLogger(__name__)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from schema_manager import SchemaManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Schema Linking System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_LINKING_SYSTEM_PROMPT = \"\"\"You are an expert Schema Linking Agent that maps natural language queries to database schema elements.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Identify relevant tables and columns for query parts\n",
    "2. Rank schema elements by relevance\n",
    "3. Suggest join paths when multiple tables are needed\n",
    "4. Provide clear rationale for each mapping\n",
    "5. Note any unresolved elements\n",
    "\n",
    "Consider:\n",
    "- Exact matches: Query mentions match schema names\n",
    "- Semantic matches: Query concepts match schema descriptions\n",
    "- Domain knowledge: Use provided business rules and synonyms\n",
    "- Data types: Match query intent with column data types\n",
    "- Foreign keys: Identify relationships between tables\n",
    "- Value examples: Match query values with sample data\n",
    "\n",
    "Scoring guidelines:\n",
    "- 0.9-1.0: Exact match or very high confidence\n",
    "- 0.7-0.9: Strong semantic match with domain knowledge\n",
    "- 0.5-0.7: Moderate match, likely relevant\n",
    "- Below 0.5: Weak match, possibly relevant\n",
    "\n",
    "Always prefer specific column matches over table-only matches.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Schema Linking Agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "class SchemaLinkingAgent:\n    \"\"\"Agent that links natural language queries to database schema elements.\"\"\"\n    \n    def __init__(self, config: Optional[Dict] = None):\n        \"\"\"Initialize the Schema Linking Agent.\"\"\"\n        self.config = config or {}\n        self.model = self.config.get('model', 'gpt-4o')\n        self.model_client = OpenAIChatCompletionClient(model=self.model)\n        \n        # Initialize schema manager if provided\n        if 'schema_manager' in self.config:\n            self.schema_manager = self.config['schema_manager']\n        else:\n            # Create default schema manager\n            self.schema_manager = self._create_default_schema_manager()\n    \n    def _create_default_schema_manager(self):\n        \"\"\"Create a default schema manager instance.\"\"\"\n        return SchemaManager(\n            data_path=self.config.get('data_path', '../data/bird/dev_databases'),\n            tables_json_path=self.config.get('tables_json_path', '../data/bird/dev_tables.json'),\n            dataset_name=self.config.get('dataset_name', 'bird'),\n            lazy=True\n        )\n    \n    async def link_schema(self, input_data: SchemaLinkingInput) -> SchemaLinkingOutput:\n        \"\"\"\n        Main entry point for schema linking.\n        \n        Args:\n            input_data: SchemaLinkingInput containing query part and context\n            \n        Returns:\n            SchemaLinkingOutput with linked schema elements\n            \n        Raises:\n            SchemaLinkingError: If linking fails\n        \"\"\"\n        try:\n            # Get schema information\n            database_schema = input_data.database_schema or await self._get_schema_description(input_data.database_id)\n            \n            # Perform schema linking\n            relevant_elements = await self._identify_relevant_elements(\n                input_data.processed_natural_language,\n                input_data.extracted_entities_and_intent,\n                database_schema,\n                input_data.domain_knowledge_context\n            )\n            \n            # Identify join paths if multiple tables\n            join_paths = await self._identify_join_paths(\n                relevant_elements,\n                database_schema\n            )\n            \n            # Identify unresolved elements\n            unresolved = await self._identify_unresolved_elements(\n                input_data.processed_natural_language,\n                input_data.extracted_entities_and_intent,\n                relevant_elements\n            )\n            \n            # Calculate overall confidence\n            overall_confidence = self._calculate_overall_confidence(relevant_elements)\n            \n            # Create output\n            output = SchemaLinkingOutput(\n                relevant_schema_elements=relevant_elements,\n                proposed_join_paths=join_paths,\n                overall_linking_confidence=overall_confidence,\n                unresolved_elements_notes=unresolved\n            )\n            \n            return output\n            \n        except Exception as e:\n            logger.error(f\"Schema linking failed: {str(e)}\")\n            raise SchemaLinkingError(f\"Failed to link schema: {str(e)}\")\n    \n    async def _get_schema_description(self, database_id: str) -> Dict:\n        \"\"\"Get detailed schema description for a database.\"\"\"\n        try:\n            # Use the unified SCHEMAS if available\n            if database_id in SCHEMAS:\n                return self._format_unified_schema(SCHEMAS[database_id])\n            \n            # Otherwise, use schema manager\n            db_info = self.schema_manager.db2dbjsons.get(database_id, {})\n            \n            # Load detailed info if not already loaded\n            if database_id not in self.schema_manager.db2infos:\n                self.schema_manager.db2infos[database_id] = self.schema_manager._load_single_db_info(database_id)\n            \n            detailed_info = self.schema_manager.db2infos.get(database_id, {})\n            \n            # Format schema description\n            schema_desc = {\n                \"tables\": {},\n                \"foreign_keys\": [],\n                \"primary_keys\": {}\n            }\n            \n            # Add table and column information\n            for table_name in db_info.get('table_names_original', []):\n                columns_info = []\n                \n                # Get column descriptions\n                if table_name in detailed_info.get('desc_dict', {}):\n                    for col_tuple in detailed_info['desc_dict'][table_name]:\n                        col_name, description, data_type = col_tuple\n                        \n                        # Get value examples\n                        values = \"\"\n                        if table_name in detailed_info.get('value_dict', {}):\n                            for val_tuple in detailed_info['value_dict'][table_name]:\n                                if val_tuple[0] == col_name:\n                                    values = val_tuple[1]\n                                    break\n                        \n                        columns_info.append({\n                            \"name\": col_name,\n                            \"description\": description,\n                            \"data_type\": data_type,\n                            \"value_examples\": values\n                        })\n                \n                schema_desc[\"tables\"][table_name] = columns_info\n                \n                # Add primary keys\n                if table_name in detailed_info.get('pk_dict', {}):\n                    schema_desc[\"primary_keys\"][table_name] = detailed_info['pk_dict'][table_name]\n            \n            # Add foreign keys\n            for table_name, fks in detailed_info.get('fk_dict', {}).items():\n                for fk in fks:\n                    from_col, to_table, to_col = fk\n                    schema_desc[\"foreign_keys\"].append({\n                        \"from_table\": table_name,\n                        \"from_column\": from_col,\n                        \"to_table\": to_table,\n                        \"to_column\": to_col\n                    })\n            \n            return schema_desc\n            \n        except Exception as e:\n            logger.error(f\"Failed to get schema description: {e}\")\n            return {\"error\": str(e), \"tables\": {}, \"foreign_keys\": [], \"primary_keys\": {}}\n    \n    def _format_unified_schema(self, schema_data: Dict) -> Dict:\n        \"\"\"Format unified schema data to expected format.\"\"\"\n        formatted = {\n            \"tables\": {},\n            \"foreign_keys\": schema_data.get(\"foreign_keys\", []),\n            \"primary_keys\": {}\n        }\n        \n        for table_name, table_info in schema_data.get(\"tables\", {}).items():\n            columns = []\n            for col_name, col_info in table_info.get(\"columns\", {}).items():\n                columns.append({\n                    \"name\": col_name,\n                    \"data_type\": col_info.get(\"type\", \"\"),\n                    \"description\": col_info.get(\"description\", \"\"),\n                    \"value_examples\": col_info.get(\"examples\", \"\")\n                })\n                \n                # Track primary keys\n                if col_info.get(\"primary_key\"):\n                    if table_name not in formatted[\"primary_keys\"]:\n                        formatted[\"primary_keys\"][table_name] = []\n                    formatted[\"primary_keys\"][table_name].append(col_name)\n            \n            formatted[\"tables\"][table_name] = columns\n        \n        return formatted\n    \n    async def _identify_relevant_elements(\n        self,\n        query_part: str,\n        entities_and_intent: ExtractedEntitiesAndIntent,\n        schema_desc: Dict,\n        domain_knowledge: Optional[Dict]\n    ) -> List[SchemaElement]:\n        \"\"\"Identify relevant schema elements for a query part.\"\"\"\n        relevant_elements = []\n        query_lower = query_part.lower()\n        \n        # Extract entities\n        metrics = entities_and_intent.metrics\n        dimensions = entities_and_intent.dimensions\n        filters = entities_and_intent.filters\n        \n        # Check each table and column\n        for table_name, columns in schema_desc.get(\"tables\", {}).items():\n            table_score = 0.0\n            table_rationale = []\n            \n            # Check table name match\n            if self._fuzzy_match(table_name, query_lower):\n                table_score = 0.8\n                table_rationale.append(f\"Table name '{table_name}' matches query\")\n            \n            # Check columns\n            column_matches = []\n            for col_info in columns:\n                col_name = col_info[\"name\"]\n                col_desc = col_info.get(\"description\", \"\")\n                col_values = col_info.get(\"value_examples\", \"\")\n                col_type = col_info.get(\"data_type\", \"\")\n                \n                col_score = 0.0\n                col_rationale = []\n                \n                # Exact column name match\n                if self._fuzzy_match(col_name, query_lower):\n                    col_score = 0.9\n                    col_rationale.append(f\"Column name '{col_name}' matches query\")\n                \n                # Check against extracted entities\n                for metric in metrics:\n                    if self._fuzzy_match(metric, col_name):\n                        col_score = max(col_score, 0.85)\n                        col_rationale.append(f\"Column matches metric '{metric}'\")\n                \n                for dimension in dimensions:\n                    if self._fuzzy_match(dimension, col_name):\n                        col_score = max(col_score, 0.85)\n                        col_rationale.append(f\"Column matches dimension '{dimension}'\")\n                \n                # Check filters\n                for filter_item in filters:\n                    field = filter_item.get(\"field\", \"\")\n                    if self._fuzzy_match(field, col_name):\n                        col_score = max(col_score, 0.9)\n                        col_rationale.append(f\"Column matches filter field '{field}'\")\n                \n                # Add column if relevant\n                if col_score > 0.5:\n                    relevant_elements.append(SchemaElement(\n                        element_name=f\"{table_name}.{col_name}\",\n                        element_type=\"Column\",\n                        table_name=table_name,\n                        column_name=col_name,\n                        relevance_score=col_score,\n                        mapping_rationale=\"; \".join(col_rationale),\n                        data_type=col_type\n                    ))\n                    column_matches.append(col_name)\n                    table_score = max(table_score, col_score * 0.9)\n            \n            # Add table if relevant\n            if table_score > 0.5 or column_matches:\n                if column_matches:\n                    table_rationale.append(f\"Contains relevant columns: {', '.join(column_matches)}\")\n                \n                relevant_elements.append(SchemaElement(\n                    element_name=table_name,\n                    element_type=\"Table\",\n                    table_name=table_name,\n                    relevance_score=table_score,\n                    mapping_rationale=\"; \".join(table_rationale)\n                ))\n        \n        # Sort by relevance score\n        relevant_elements.sort(key=lambda x: x.relevance_score, reverse=True)\n        \n        # Use LLM for sophisticated matching if needed\n        if len(relevant_elements) < 3:\n            llm_elements = await self._llm_schema_matching(\n                query_part, entities_and_intent, schema_desc, domain_knowledge\n            )\n            relevant_elements.extend(llm_elements)\n            relevant_elements.sort(key=lambda x: x.relevance_score, reverse=True)\n        \n        return relevant_elements\n    \n    def _fuzzy_match(self, term1: str, term2: str) -> bool:\n        \"\"\"Perform fuzzy matching between terms.\"\"\"\n        term1_lower = term1.lower()\n        term2_lower = term2.lower()\n        \n        # Exact match\n        if term1_lower in term2_lower or term2_lower in term1_lower:\n            return True\n        \n        # Similarity ratio\n        ratio = SequenceMatcher(None, term1_lower, term2_lower).ratio()\n        return ratio > 0.7\n    \n    async def _llm_schema_matching(\n        self,\n        query_part: str,\n        entities_and_intent: ExtractedEntitiesAndIntent,\n        schema_desc: Dict,\n        domain_knowledge: Optional[Dict]\n    ) -> List[SchemaElement]:\n        \"\"\"Use LLM for sophisticated schema matching.\"\"\"\n        # Format entities and intent for prompt\n        entities_dict = {\n            \"metrics\": entities_and_intent.metrics,\n            \"dimensions\": entities_and_intent.dimensions,\n            \"filters\": entities_and_intent.filters,\n            \"primary_goal\": entities_and_intent.primary_goal\n        }\n        \n        prompt = f\"\"\"\n        Match this query part to relevant schema elements:\n        \n        Query: {query_part}\n        Intent: {json.dumps(entities_dict, indent=2)}\n        \n        Schema tables and columns:\n        {json.dumps(schema_desc.get('tables', {}), indent=2)}\n        \n        Domain knowledge:\n        {json.dumps(domain_knowledge, indent=2) if domain_knowledge else 'None'}\n        \n        Identify the most relevant tables and columns with scores (0-1).\n        Return as JSON list of {{\"element\": \"table.column\", \"type\": \"Column\", \"table\": \"table_name\", \"column\": \"col_name\", \"score\": 0.8, \"reason\": \"why\"}}.\n        \"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": SCHEMA_LINKING_SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        try:\n            response = await self.model_client.create(messages=messages)\n            content = response.choices[0].message.content\n            \n            # Parse LLM response\n            elements = []\n            json_match = re.search(r'\\[.*\\]', content, re.DOTALL)\n            if json_match:\n                matches = json.loads(json_match.group())\n                for match in matches:\n                    elements.append(SchemaElement(\n                        element_name=match[\"element\"],\n                        element_type=match[\"type\"],\n                        table_name=match.get(\"table\", match[\"element\"].split(\".\")[0]),\n                        column_name=match.get(\"column\", match[\"element\"].split(\".\")[-1] if \".\" in match[\"element\"] else None),\n                        relevance_score=float(match[\"score\"]),\n                        mapping_rationale=match[\"reason\"]\n                    ))\n        except Exception as e:\n            logger.warning(f\"LLM matching failed: {e}\")\n        \n        return elements\n    \n    async def _identify_join_paths(\n        self,\n        relevant_elements: List[SchemaElement],\n        schema_desc: Dict\n    ) -> List[JoinPath]:\n        \"\"\"Identify join paths between relevant tables.\"\"\"\n        join_paths = []\n        \n        # Get unique table names\n        tables = set()\n        for elem in relevant_elements:\n            tables.add(elem.table_name)\n        \n        # Find join paths using foreign keys\n        for fk in schema_desc.get(\"foreign_keys\", []):\n            from_table = fk[\"from_table\"]\n            to_table = fk[\"to_table\"]\n            \n            if from_table in tables and to_table in tables:\n                join_paths.append(JoinPath(\n                    from_table=from_table,\n                    to_table=to_table,\n                    from_column=fk[\"from_column\"],\n                    to_column=fk[\"to_column\"],\n                    join_condition=f\"{from_table}.{fk['from_column']} = {to_table}.{fk['to_column']}\",\n                    join_type=\"INNER\",\n                    confidence=0.95\n                ))\n        \n        # Infer additional joins if needed\n        if len(tables) > 1 and not join_paths:\n            await self._infer_join_paths(tables, schema_desc, join_paths)\n        \n        return join_paths\n    \n    async def _infer_join_paths(\n        self,\n        tables: set,\n        schema_desc: Dict,\n        join_paths: List[JoinPath]\n    ):\n        \"\"\"Infer join paths when foreign keys are not available.\"\"\"\n        table_list = list(tables)\n        for i in range(len(table_list)):\n            for j in range(i + 1, len(table_list)):\n                table1, table2 = table_list[i], table_list[j]\n                \n                # Check for common column names\n                cols1 = {col[\"name\"] for col in schema_desc.get(\"tables\", {}).get(table1, [])}\n                cols2 = {col[\"name\"] for col in schema_desc.get(\"tables\", {}).get(table2, [])}\n                \n                common_cols = cols1.intersection(cols2)\n                for col in common_cols:\n                    if any(keyword in col.lower() for keyword in [\"id\", \"key\", \"code\"]):\n                        join_paths.append(JoinPath(\n                            from_table=table1,\n                            to_table=table2,\n                            from_column=col,\n                            to_column=col,\n                            join_condition=f\"{table1}.{col} = {table2}.{col}\",\n                            join_type=\"INNER\",\n                            confidence=0.7\n                        ))\n    \n    async def _identify_unresolved_elements(\n        self,\n        query_part: str,\n        entities_and_intent: ExtractedEntitiesAndIntent,\n        relevant_elements: List[SchemaElement]\n    ) -> List[str]:\n        \"\"\"Identify query elements that couldn't be mapped to schema.\"\"\"\n        unresolved = []\n        \n        # Get all mapped terms\n        mapped_terms = set()\n        for elem in relevant_elements:\n            if elem.column_name:\n                mapped_terms.add(elem.column_name.lower())\n            mapped_terms.add(elem.table_name.lower())\n        \n        # Check metrics\n        for metric in entities_and_intent.metrics:\n            if metric.lower() not in mapped_terms and metric.lower() not in [\"count\", \"sum\", \"average\", \"max\", \"min\"]:\n                unresolved.append(f\"Metric '{metric}' not found in schema\")\n        \n        # Check dimensions  \n        for dimension in entities_and_intent.dimensions:\n            if dimension.lower() not in mapped_terms:\n                unresolved.append(f\"Dimension '{dimension}' not found in schema\")\n        \n        # Check filters\n        for filter_item in entities_and_intent.filters:\n            field = filter_item.get(\"field\", \"\")\n            if field.lower() not in mapped_terms and field != \"condition\":\n                unresolved.append(f\"Filter field '{field}' not found in schema\")\n        \n        return unresolved\n    \n    def _calculate_overall_confidence(self, relevant_elements: List[SchemaElement]) -> float:\n        \"\"\"Calculate overall linking confidence.\"\"\"\n        if not relevant_elements:\n            return 0.0\n        \n        # Weighted average of top elements\n        top_elements = relevant_elements[:5]\n        total_weight = 0\n        weighted_sum = 0\n        \n        for i, elem in enumerate(top_elements):\n            weight = 1 / (i + 1)  # Higher weight for top elements\n            weighted_sum += elem.relevance_score * weight\n            total_weight += weight\n        \n        return weighted_sum / total_weight if total_weight > 0 else 0.0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Components and Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize schema linking agent with configuration\nconfig = {\n    'model': 'gpt-4o',\n    'data_path': '../data/bird/dev_databases',\n    'tables_json_path': '../data/bird/dev_tables.json',\n    'dataset_name': 'bird'\n}\n\nschema_linker = SchemaLinkingAgent(config=config)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Simple Query"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test with a simple query part using the new interface\nasync def test_simple_schema_linking():\n    # Create entities and intent\n    entities_and_intent = ExtractedEntitiesAndIntent(\n        metrics=[\"list\"],\n        dimensions=[\"schools\", \"county\"],\n        filters=[{\"field\": \"county\", \"operator\": \"=\", \"value\": \"Alameda\"}],\n        primary_goal=\"retrieve\",\n        confidence=0.8\n    )\n    \n    # Create input\n    input_data = SchemaLinkingInput(\n        processed_natural_language=\"Show all schools in Alameda county\",\n        extracted_entities_and_intent=entities_and_intent,\n        database_id=\"california_schools\",\n        database_schema=None  # Will use default\n    )\n    \n    try:\n        result = await schema_linker.link_schema(input_data)\n        \n        print(f\"Overall Confidence: {result.overall_linking_confidence:.2f}\")\n        print(f\"\\nRelevant Schema Elements:\")\n        for elem in result.relevant_schema_elements[:5]:  # Show top 5\n            print(f\"  {elem.element_type}: {elem.element_name}\")\n            print(f\"    Score: {elem.relevance_score:.2f}\")\n            print(f\"    Rationale: {elem.mapping_rationale}\")\n        \n        print(f\"\\nProposed Join Paths:\")\n        for join in result.proposed_join_paths:\n            print(f\"  {join.from_table} → {join.to_table}\")\n            print(f\"    Condition: {join.join_condition}\")\n            print(f\"    Confidence: {join.confidence:.2f}\")\n        \n        if result.unresolved_elements_notes:\n            print(f\"\\nUnresolved Elements:\")\n            for note in result.unresolved_elements_notes:\n                print(f\"  - {note}\")\n        \n        return result\n    except SchemaLinkingError as e:\n        print(f\"Schema linking failed: {e}\")\n        return None\n\n# Run the test\nresult = await test_simple_schema_linking()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Complex Query Requiring Joins"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test with a query requiring joins\nasync def test_join_schema_linking():\n    # Create entities for a join query\n    entities_and_intent = ExtractedEntitiesAndIntent(\n        metrics=[\"average\", \"SAT math scores\"],\n        dimensions=[\"charter schools\"],\n        filters=[{\"field\": \"charter status\", \"operator\": \"=\", \"value\": 1}],\n        primary_goal=\"aggregation\",\n        confidence=0.85\n    )\n    \n    input_data = SchemaLinkingInput(\n        processed_natural_language=\"Calculate average SAT math scores for charter schools\",\n        extracted_entities_and_intent=entities_and_intent,\n        database_id=\"california_schools\",\n        database_schema=None\n    )\n    \n    try:\n        result = await schema_linker.link_schema(input_data)\n        \n        print(f\"Overall Confidence: {result.overall_linking_confidence:.2f}\")\n        \n        # Group elements by table\n        tables = {}\n        for elem in result.relevant_schema_elements:\n            if elem.element_type == \"Table\":\n                if elem.table_name not in tables:\n                    tables[elem.table_name] = {\"table\": elem, \"columns\": []}\n            elif elem.element_type == \"Column\":\n                if elem.table_name not in tables:\n                    tables[elem.table_name] = {\"table\": None, \"columns\": []}\n                tables[elem.table_name][\"columns\"].append(elem)\n        \n        print(\"\\nRelevant Tables and Columns:\")\n        for table_name, info in tables.items():\n            table_elem = info[\"table\"]\n            if table_elem:\n                print(f\"\\n{table_name} (Score: {table_elem.relevance_score:.2f})\")\n            else:\n                print(f\"\\n{table_name}\")\n            \n            for col in info[\"columns\"]:\n                print(f\"  - {col.column_name} ({col.data_type}) - Score: {col.relevance_score:.2f}\")\n        \n        print(\"\\nJoin Strategy:\")\n        if result.proposed_join_paths:\n            for join in result.proposed_join_paths:\n                print(f\"  JOIN {join.from_table} AND {join.to_table}\")\n                print(f\"    ON {join.join_condition}\")\n                print(f\"    Type: {join.join_type}\")\n                print(f\"    Confidence: {join.confidence:.2f}\")\n        else:\n            print(\"  No joins needed or couldn't identify join paths\")\n        \n        return result\n    except SchemaLinkingError as e:\n        print(f\"Schema linking failed: {e}\")\n        return None\n\n# Run the test\njoin_result = await test_join_schema_linking()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Value-Based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with value-based matching\n",
    "await schema_linker.query(\"\"\"\n",
    "Link schema for this query part:\n",
    "Query: \"Find schools with excellence rate over 0.8\"\n",
    "Database: california_schools\n",
    "Entities and Intent: {\n",
    "    \"metrics\": [\"excellence rate\"],\n",
    "    \"dimensions\": [\"schools\"],\n",
    "    \"filters\": [{\"field\": \"excellence rate\", \"operator\": \">\", \"value\": 0.8}],\n",
    "    \"primary_goal\": \"filtering\"\n",
    "}\n",
    "Domain Knowledge: {\n",
    "    \"business_rules\": [\"Excellence rate = NumGE1500 / NumTstTakr\"]\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Direct Function Call"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Direct function call example with new interface\nasync def test_direct_linking():\n    # Create structured input\n    entities_and_intent = ExtractedEntitiesAndIntent(\n        metrics=[\"count\"],\n        dimensions=[\"department\", \"salary range\"],\n        filters=[{\"field\": \"year\", \"operator\": \"=\", \"value\": 2023}],\n        primary_goal=\"aggregation\",\n        confidence=0.8\n    )\n    \n    input_data = SchemaLinkingInput(\n        processed_natural_language=\"Count employees by department and salary range for year 2023\",\n        extracted_entities_and_intent=entities_and_intent,\n        database_id=\"financial\",\n        database_schema=None,\n        domain_knowledge_context={\n            \"synonyms\": {\n                \"employee\": [\"staff\", \"worker\"],\n                \"department\": [\"dept\", \"division\"]\n            }\n        }\n    )\n    \n    try:\n        result = await schema_linker.link_schema(input_data)\n        \n        # Convert to JSON-serializable format\n        result_dict = {\n            \"overall_confidence\": result.overall_linking_confidence,\n            \"relevant_elements\": [\n                {\n                    \"name\": elem.element_name,\n                    \"type\": elem.element_type,\n                    \"score\": elem.relevance_score,\n                    \"rationale\": elem.mapping_rationale,\n                    \"table\": elem.table_name,\n                    \"column\": elem.column_name\n                }\n                for elem in result.relevant_schema_elements[:5]\n            ],\n            \"join_paths\": [\n                {\n                    \"from\": join.from_table,\n                    \"to\": join.to_table,\n                    \"condition\": join.join_condition,\n                    \"type\": join.join_type,\n                    \"confidence\": join.confidence\n                }\n                for join in result.proposed_join_paths\n            ],\n            \"unresolved\": result.unresolved_elements_notes\n        }\n        \n        print(json.dumps(result_dict, indent=2))\n        return result\n    except SchemaLinkingError as e:\n        print(f\"Schema linking failed: {e}\")\n        return None\n\n# Run the test\ndirect_result = await test_direct_linking()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Unresolved Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with query containing unresolvable elements\n",
    "await schema_linker.query(\"\"\"\n",
    "Link schema for this query part:\n",
    "Query: \"Show student performance metrics by teacher quality index\"\n",
    "Database: california_schools\n",
    "Entities and Intent: {\n",
    "    \"metrics\": [\"student performance\", \"teacher quality index\"],\n",
    "    \"dimensions\": [\"schools\"],\n",
    "    \"filters\": [],\n",
    "    \"primary_goal\": \"analysis\"\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Example: Complex Multi-Table Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex multi-table query\n",
    "complex_entities_and_intent = {\n",
    "    \"metrics\": [\"average salary\", \"transaction count\"],\n",
    "    \"dimensions\": [\"district\", \"account type\"],\n",
    "    \"filters\": [\n",
    "        {\"field\": \"transaction amount\", \"operator\": \">\", \"value\": 1000},\n",
    "        {\"field\": \"account age\", \"operator\": \">\", \"value\": \"1 year\"}\n",
    "    ],\n",
    "    \"primary_goal\": \"aggregation\"\n",
    "}\n",
    "\n",
    "await schema_linker.query(f\"\"\"\n",
    "Link schema for this complex query part:\n",
    "Query: \"Average district salary and transaction count for accounts older than 1 year with transactions over $1000\"\n",
    "Database: financial\n",
    "Entities and Intent: {json.dumps(complex_entities_and_intent, indent=2)}\n",
    "Domain Knowledge: {{\n",
    "    \"business_rules\": [\n",
    "        \"Average salary is A11 in district table\",\n",
    "        \"Accounts link to districts via district_id\",\n",
    "        \"Transactions link to accounts via account_id\"\n",
    "    ]\n",
    "}}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connections\n",
    "await schema_linker.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}