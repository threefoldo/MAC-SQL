{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Evaluation Agent Test\n",
    "\n",
    "This notebook implements and tests the SQL Evaluation Agent that validates and optimizes SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Any, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from schema_manager import SchemaManager\n",
    "from sql_executor import SQLExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SQL Evaluation System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_EVALUATOR_SYSTEM_PROMPT = \"\"\"You are an expert SQL Evaluation Agent specializing in validating and optimizing SQL queries.\n",
    "\n",
    "Your capabilities:\n",
    "1. Validate SQL syntax without execution\n",
    "2. Check SQL queries for common errors and issues\n",
    "3. Optimize SQL queries for better performance\n",
    "4. Provide recommendations for query improvements\n",
    "5. Analyze query complexity and efficiency\n",
    "\n",
    "Guidelines for validation:\n",
    "- Check for syntax errors\n",
    "- Verify table and column references\n",
    "- Ensure proper JOIN conditions\n",
    "- Validate aggregate function usage\n",
    "- Check for SQL injection vulnerabilities\n",
    "- Verify data type compatibility\n",
    "\n",
    "Guidelines for optimization:\n",
    "- Identify inefficient query patterns\n",
    "- Suggest better indexing strategies\n",
    "- Recommend query rewrites for performance\n",
    "- Identify unnecessary operations\n",
    "- Suggest appropriate use of indexes\n",
    "- Recommend optimal JOIN orders\n",
    "\n",
    "Always provide actionable recommendations with explanations.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the SQL Evaluation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLEvaluationAgent:\n",
    "    \"\"\"Agent that validates and optimizes SQL queries.\"\"\"\n",
    "    \n",
    "    def __init__(self, schema_manager: SchemaManager, model: str = \"gpt-4o\"):\n",
    "        self.schema_manager = schema_manager\n",
    "        self.model_client = OpenAIChatCompletionClient(model=model)\n",
    "        self.agent = self._create_agent()\n",
    "    \n",
    "    def _create_agent(self) -> AssistantAgent:\n",
    "        \"\"\"Create the SQL evaluation agent with tools.\"\"\"\n",
    "        \n",
    "        async def validate_sql_syntax(sql: str, database_id: str) -> str:\n",
    "            \"\"\"Validate SQL syntax without executing.\"\"\"\n",
    "            # Basic syntax validation\n",
    "            sql_upper = sql.upper()\n",
    "            \n",
    "            issues = []\n",
    "            warnings = []\n",
    "            \n",
    "            # Check for basic SQL structure\n",
    "            if not \"SELECT\" in sql_upper:\n",
    "                issues.append(\"Missing SELECT clause\")\n",
    "            \n",
    "            if not \"FROM\" in sql_upper:\n",
    "                issues.append(\"Missing FROM clause\")\n",
    "            \n",
    "            # Check for common syntax errors\n",
    "            if sql.count('(') != sql.count(')'):\n",
    "                issues.append(\"Unmatched parentheses\")\n",
    "            \n",
    "            if sql.count(\"'\") % 2 != 0:\n",
    "                issues.append(\"Unmatched quotes\")\n",
    "            \n",
    "            # Check for potential SQL injection patterns\n",
    "            dangerous_patterns = ['--', '/*', '*/', 'xp_', 'sp_', 'exec', 'execute']\n",
    "            for pattern in dangerous_patterns:\n",
    "                if pattern in sql.lower():\n",
    "                    warnings.append(f\"Potential SQL injection pattern detected: {pattern}\")\n",
    "            \n",
    "            # Check table references against schema\n",
    "            try:\n",
    "                db_info = self.schema_manager.db2dbjsons.get(database_id, {})\n",
    "                available_tables = [t.lower() for t in db_info.get('table_names_original', [])]\n",
    "                \n",
    "                # Extract table names from SQL\n",
    "                # Simple pattern to find tables after FROM and JOIN\n",
    "                table_pattern = r'(?:FROM|JOIN)\\s+([\\w\\.]+)'\n",
    "                found_tables = re.findall(table_pattern, sql, re.IGNORECASE)\n",
    "                \n",
    "                for table in found_tables:\n",
    "                    table_name = table.split('.')[-1].lower()  # Handle db.table format\n",
    "                    if table_name not in available_tables and not table_name.startswith('('):\n",
    "                        issues.append(f\"Table '{table}' not found in database schema\")\n",
    "                \n",
    "                # Check column references\n",
    "                if db_info and not issues:  # Only check columns if tables are valid\n",
    "                    column_pattern = r'SELECT\\s+(.+?)\\s+FROM'\n",
    "                    select_match = re.search(column_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
    "                    if select_match:\n",
    "                        select_clause = select_match.group(1)\n",
    "                        # Basic column validation (simplified)\n",
    "                        if '*' not in select_clause:\n",
    "                            columns = [col.strip() for col in select_clause.split(',')]\n",
    "                            available_columns = db_info.get('column_names_original', [])\n",
    "                            # This is a simplified check - in practice would need more sophisticated parsing\n",
    "            except Exception as e:\n",
    "                warnings.append(f\"Unable to validate against schema: {str(e)}\")\n",
    "            \n",
    "            # Advanced validation using LLM\n",
    "            validation_prompt = f\"\"\"\n",
    "            Validate this SQL query for syntax and best practices:\n",
    "            \n",
    "            SQL:\n",
    "            {sql}\n",
    "            \n",
    "            Database: {database_id}\n",
    "            \n",
    "            Check for:\n",
    "            1. Syntax errors\n",
    "            2. Logic errors\n",
    "            3. Performance issues\n",
    "            4. Best practice violations\n",
    "            \n",
    "            Provide a detailed analysis.\n",
    "            \"\"\"\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SQL_EVALUATOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": validation_prompt}\n",
    "            ]\n",
    "            \n",
    "            response = await self.model_client.create(messages=messages)\n",
    "            llm_analysis = response.choices[0].message.content\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"sql\": sql,\n",
    "                \"is_valid\": len(issues) == 0,\n",
    "                \"issues\": issues,\n",
    "                \"warnings\": warnings,\n",
    "                \"llm_analysis\": llm_analysis\n",
    "            }, indent=2)\n",
    "        \n",
    "        async def analyze_query_complexity(sql: str, database_id: str) -> str:\n",
    "            \"\"\"Analyze the complexity of a SQL query.\"\"\"\n",
    "            sql_upper = sql.upper()\n",
    "            \n",
    "            complexity_factors = {\n",
    "                \"joins\": sql_upper.count('JOIN'),\n",
    "                \"subqueries\": sql.count('(SELECT'),\n",
    "                \"aggregations\": sum(1 for func in ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN'] if func in sql_upper),\n",
    "                \"group_by\": 1 if 'GROUP BY' in sql_upper else 0,\n",
    "                \"having\": 1 if 'HAVING' in sql_upper else 0,\n",
    "                \"distinct\": 1 if 'DISTINCT' in sql_upper else 0,\n",
    "                \"union\": sql_upper.count('UNION'),\n",
    "                \"case_when\": sql_upper.count('CASE WHEN'),\n",
    "                \"cte\": sql_upper.count('WITH')\n",
    "            }\n",
    "            \n",
    "            # Calculate complexity score\n",
    "            complexity_score = (\n",
    "                complexity_factors['joins'] * 2 +\n",
    "                complexity_factors['subqueries'] * 3 +\n",
    "                complexity_factors['aggregations'] +\n",
    "                complexity_factors['group_by'] * 2 +\n",
    "                complexity_factors['having'] * 2 +\n",
    "                complexity_factors['distinct'] +\n",
    "                complexity_factors['union'] * 3 +\n",
    "                complexity_factors['case_when'] * 2 +\n",
    "                complexity_factors['cte'] * 2\n",
    "            )\n",
    "            \n",
    "            # Determine complexity level\n",
    "            if complexity_score <= 2:\n",
    "                complexity_level = \"Simple\"\n",
    "            elif complexity_score <= 6:\n",
    "                complexity_level = \"Moderate\"\n",
    "            elif complexity_score <= 12:\n",
    "                complexity_level = \"Complex\"\n",
    "            else:\n",
    "                complexity_level = \"Very Complex\"\n",
    "            \n",
    "            # Get detailed analysis from LLM\n",
    "            analysis_prompt = f\"\"\"\n",
    "            Analyze the complexity of this SQL query:\n",
    "            \n",
    "            SQL:\n",
    "            {sql}\n",
    "            \n",
    "            Database: {database_id}\n",
    "            \n",
    "            Provide:\n",
    "            1. Complexity assessment\n",
    "            2. Potential performance bottlenecks\n",
    "            3. Optimization opportunities\n",
    "            4. Readability concerns\n",
    "            \"\"\"\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SQL_EVALUATOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": analysis_prompt}\n",
    "            ]\n",
    "            \n",
    "            response = await self.model_client.create(messages=messages)\n",
    "            detailed_analysis = response.choices[0].message.content\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"sql\": sql,\n",
    "                \"complexity_level\": complexity_level,\n",
    "                \"complexity_score\": complexity_score,\n",
    "                \"complexity_factors\": complexity_factors,\n",
    "                \"detailed_analysis\": detailed_analysis\n",
    "            }, indent=2)\n",
    "        \n",
    "        async def optimize_sql(sql: str, database_id: str, optimization_goal: str = \"performance\") -> str:\n",
    "            \"\"\"Optimize SQL query for better performance or readability.\"\"\"\n",
    "            \n",
    "            # Quick checks for common optimization opportunities\n",
    "            quick_optimizations = []\n",
    "            sql_upper = sql.upper()\n",
    "            \n",
    "            # Check for SELECT *\n",
    "            if \"SELECT *\" in sql_upper:\n",
    "                quick_optimizations.append(\"Replace SELECT * with specific columns to reduce data transfer\")\n",
    "            \n",
    "            # Check for missing WHERE clause in JOINs\n",
    "            if \"JOIN\" in sql_upper and \"WHERE\" not in sql_upper and \"ON\" in sql_upper:\n",
    "                quick_optimizations.append(\"Consider adding WHERE clause to filter results and improve performance\")\n",
    "            \n",
    "            # Check for DISTINCT with GROUP BY\n",
    "            if \"DISTINCT\" in sql_upper and \"GROUP BY\" in sql_upper:\n",
    "                quick_optimizations.append(\"DISTINCT might be redundant with GROUP BY\")\n",
    "            \n",
    "            # Check for OR in WHERE clause\n",
    "            if \"WHERE\" in sql_upper and \" OR \" in sql_upper:\n",
    "                quick_optimizations.append(\"Consider using IN clause or UNION instead of OR for better index usage\")\n",
    "            \n",
    "            # Use LLM for sophisticated optimization\n",
    "            optimization_prompt = f\"\"\"\n",
    "            Optimize this SQL query for {optimization_goal}:\n",
    "            \n",
    "            Original SQL:\n",
    "            {sql}\n",
    "            \n",
    "            Database: {database_id}\n",
    "            \n",
    "            Provide:\n",
    "            1. Optimized SQL query\n",
    "            2. Explanation of changes\n",
    "            3. Expected performance improvements\n",
    "            4. Any trade-offs to consider\n",
    "            \n",
    "            Focus on:\n",
    "            - Query performance\n",
    "            - Index usage\n",
    "            - Join optimization\n",
    "            - Reducing data scans\n",
    "            - Simplifying complex logic\n",
    "            \"\"\"\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SQL_EVALUATOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": optimization_prompt}\n",
    "            ]\n",
    "            \n",
    "            response = await self.model_client.create(messages=messages)\n",
    "            optimization_response = response.choices[0].message.content\n",
    "            \n",
    "            # Extract optimized SQL from response\n",
    "            optimized_sql = self._extract_sql_from_response(optimization_response)\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"original_sql\": sql,\n",
    "                \"optimized_sql\": optimized_sql,\n",
    "                \"quick_optimizations\": quick_optimizations,\n",
    "                \"optimization_goal\": optimization_goal,\n",
    "                \"detailed_explanation\": optimization_response\n",
    "            }, indent=2)\n",
    "        \n",
    "        async def suggest_indexes(sql: str, database_id: str) -> str:\n",
    "            \"\"\"Suggest indexes to improve query performance.\"\"\"\n",
    "            \n",
    "            # Extract columns used in WHERE, JOIN, and ORDER BY clauses\n",
    "            where_pattern = r'WHERE\\s+(.+?)(?:GROUP|ORDER|HAVING|$)'\n",
    "            join_pattern = r'ON\\s+(.+?)(?:WHERE|GROUP|ORDER|JOIN|$)'\n",
    "            order_pattern = r'ORDER\\s+BY\\s+(.+?)(?:LIMIT|$)'\n",
    "            \n",
    "            where_columns = []\n",
    "            join_columns = []\n",
    "            order_columns = []\n",
    "            \n",
    "            # Extract columns from different clauses\n",
    "            where_match = re.search(where_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
    "            if where_match:\n",
    "                where_clause = where_match.group(1)\n",
    "                # Simple extraction - in practice would need more sophisticated parsing\n",
    "                column_pattern = r'([\\w\\.]+)\\s*[=<>]'\n",
    "                where_columns = re.findall(column_pattern, where_clause)\n",
    "            \n",
    "            join_match = re.findall(join_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
    "            for join_clause in join_match:\n",
    "                column_pattern = r'([\\w\\.]+)\\s*=\\s*([\\w\\.]+)'\n",
    "                matches = re.findall(column_pattern, join_clause)\n",
    "                join_columns.extend([col for pair in matches for col in pair])\n",
    "            \n",
    "            order_match = re.search(order_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
    "            if order_match:\n",
    "                order_clause = order_match.group(1)\n",
    "                order_columns = [col.strip() for col in order_clause.split(',')]\n",
    "            \n",
    "            # Use LLM for comprehensive index suggestions\n",
    "            index_prompt = f\"\"\"\n",
    "            Suggest indexes for this SQL query:\n",
    "            \n",
    "            SQL:\n",
    "            {sql}\n",
    "            \n",
    "            Database: {database_id}\n",
    "            \n",
    "            Columns used in:\n",
    "            - WHERE: {where_columns}\n",
    "            - JOIN: {join_columns}\n",
    "            - ORDER BY: {order_columns}\n",
    "            \n",
    "            Provide:\n",
    "            1. Recommended indexes with CREATE INDEX statements\n",
    "            2. Explanation for each index\n",
    "            3. Expected performance improvements\n",
    "            4. Any existing indexes that might already help\n",
    "            \"\"\"\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SQL_EVALUATOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": index_prompt}\n",
    "            ]\n",
    "            \n",
    "            response = await self.model_client.create(messages=messages)\n",
    "            index_suggestions = response.choices[0].message.content\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"sql\": sql,\n",
    "                \"where_columns\": where_columns,\n",
    "                \"join_columns\": join_columns,\n",
    "                \"order_columns\": order_columns,\n",
    "                \"index_suggestions\": index_suggestions\n",
    "            }, indent=2)\n",
    "        \n",
    "        async def evaluate_sql_performance(sql: str, database_id: str) -> str:\n",
    "            \"\"\"Evaluate potential performance of SQL query.\"\"\"\n",
    "            \n",
    "            performance_factors = {\n",
    "                \"has_select_star\": \"SELECT *\" in sql.upper(),\n",
    "                \"has_where_clause\": \"WHERE\" in sql.upper(),\n",
    "                \"has_joins\": \"JOIN\" in sql.upper(),\n",
    "                \"has_subqueries\": \"(SELECT\" in sql,\n",
    "                \"has_grouping\": \"GROUP BY\" in sql.upper(),\n",
    "                \"has_ordering\": \"ORDER BY\" in sql.upper(),\n",
    "                \"has_distinct\": \"DISTINCT\" in sql.upper(),\n",
    "                \"has_functions\": any(func in sql.upper() for func in ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN'])\n",
    "            }\n",
    "            \n",
    "            # Performance score (simplified)\n",
    "            performance_score = 100\n",
    "            \n",
    "            if performance_factors['has_select_star']:\n",
    "                performance_score -= 10\n",
    "            if not performance_factors['has_where_clause'] and performance_factors['has_joins']:\n",
    "                performance_score -= 20\n",
    "            if performance_factors['has_subqueries']:\n",
    "                performance_score -= 15\n",
    "            if performance_factors['has_distinct']:\n",
    "                performance_score -= 5\n",
    "            \n",
    "            # Detailed performance analysis from LLM\n",
    "            performance_prompt = f\"\"\"\n",
    "            Analyze the performance characteristics of this SQL query:\n",
    "            \n",
    "            SQL:\n",
    "            {sql}\n",
    "            \n",
    "            Database: {database_id}\n",
    "            \n",
    "            Evaluate:\n",
    "            1. Potential bottlenecks\n",
    "            2. Resource usage (CPU, memory, I/O)\n",
    "            3. Scalability concerns\n",
    "            4. Execution plan considerations\n",
    "            5. Data volume impact\n",
    "            \n",
    "            Provide specific recommendations for improvement.\n",
    "            \"\"\"\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SQL_EVALUATOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": performance_prompt}\n",
    "            ]\n",
    "            \n",
    "            response = await self.model_client.create(messages=messages)\n",
    "            performance_analysis = response.choices[0].message.content\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"sql\": sql,\n",
    "                \"performance_score\": performance_score,\n",
    "                \"performance_factors\": performance_factors,\n",
    "                \"detailed_analysis\": performance_analysis\n",
    "            }, indent=2)\n",
    "        \n",
    "        # Create the agent\n",
    "        return AssistantAgent(\n",
    "            name=\"sql_evaluator\",\n",
    "            model_client=self.model_client,\n",
    "            tools=[\n",
    "                validate_sql_syntax,\n",
    "                analyze_query_complexity,\n",
    "                optimize_sql,\n",
    "                suggest_indexes,\n",
    "                evaluate_sql_performance\n",
    "            ],\n",
    "            system_message=SQL_EVALUATOR_SYSTEM_PROMPT,\n",
    "            reflect_on_tool_use=True,\n",
    "            model_client_stream=True,\n",
    "        )\n",
    "    \n",
    "    def _extract_sql_from_response(self, response: str) -> str:\n",
    "        \"\"\"Extract SQL from LLM response.\"\"\"\n",
    "        # Look for SQL in code blocks\n",
    "        sql_pattern = r'```sql\\n(.*?)\\n```'\n",
    "        matches = re.findall(sql_pattern, response, re.DOTALL)\n",
    "        \n",
    "        if matches:\n",
    "            return matches[0].strip()\n",
    "        \n",
    "        # Look for SQL after certain markers\n",
    "        for marker in ['Optimized SQL:', 'SQL:', 'Query:']:\n",
    "            if marker in response:\n",
    "                sql_part = response.split(marker)[-1].strip()\n",
    "                # Extract until the next marker or end\n",
    "                for end_marker in ['\\n\\n', '---', '###']:\n",
    "                    if end_marker in sql_part:\n",
    "                        sql_part = sql_part.split(end_marker)[0]\n",
    "                return sql_part.strip()\n",
    "        \n",
    "        # If no specific format found, try to extract SELECT statement\n",
    "        lines = response.split('\\n')\n",
    "        sql_lines = []\n",
    "        in_sql = False\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'SELECT' in line.upper():\n",
    "                in_sql = True\n",
    "            if in_sql:\n",
    "                sql_lines.append(line)\n",
    "                if ';' in line:\n",
    "                    break\n",
    "        \n",
    "        return '\\n'.join(sql_lines).strip()\n",
    "    \n",
    "    async def query(self, task: str) -> None:\n",
    "        \"\"\"Run a query against the SQL evaluator agent.\"\"\"\n",
    "        await Console(self.agent.run_stream(task=task))\n",
    "    \n",
    "    async def close(self) -> None:\n",
    "        \"\"\"Close the model client connection.\"\"\"\n",
    "        await self.model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Components and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "data_path = \"../data/bird/dev_databases\"\n",
    "tables_json_path = \"../data/bird/dev_tables.json\"\n",
    "dataset_name = \"bird\"\n",
    "\n",
    "# Create schema manager\n",
    "schema_manager = SchemaManager(\n",
    "    data_path=data_path,\n",
    "    tables_json_path=tables_json_path,\n",
    "    dataset_name=dataset_name,\n",
    "    lazy=True\n",
    ")\n",
    "\n",
    "# Create SQL evaluator agent\n",
    "sql_evaluator = SQLEvaluationAgent(schema_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SQL Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test validating a correct SQL query\n",
    "valid_sql = \"SELECT School, County FROM schools WHERE County = 'Alameda'\"\n",
    "\n",
    "await sql_evaluator.query(f\"\"\"\n",
    "Validate this SQL syntax for database 'california_schools':\n",
    "{valid_sql}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test validating SQL with errors\n",
    "invalid_sql = \"SELECT School FROM invalid_table WHERE \"\n",
    "\n",
    "await sql_evaluator.query(f\"\"\"\n",
    "Validate this SQL syntax for database 'california_schools':\n",
    "{invalid_sql}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Query Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test analyzing a complex query\n",
    "complex_sql = \"\"\"\n",
    "SELECT s.School, AVG(sat.AvgScrMath) as avg_math_score\n",
    "FROM schools s\n",
    "JOIN satscores sat ON s.CDSCode = sat.cds\n",
    "WHERE s.County = 'Alameda'\n",
    "  AND sat.AvgScrMath IS NOT NULL\n",
    "GROUP BY s.School\n",
    "HAVING AVG(sat.AvgScrMath) > (\n",
    "  SELECT AVG(AvgScrMath) \n",
    "  FROM satscores \n",
    "  WHERE AvgScrMath IS NOT NULL\n",
    ")\n",
    "ORDER BY avg_math_score DESC\n",
    "\"\"\"\n",
    "\n",
    "await sql_evaluator.query(f\"\"\"\n",
    "Analyze the complexity of this SQL query for database 'california_schools':\n",
    "{complex_sql}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SQL Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test optimizing an inefficient query\n",
    "inefficient_sql = \"\"\"\n",
    "SELECT *\n",
    "FROM schools s\n",
    "JOIN satscores sat ON s.CDSCode = sat.cds\n",
    "ORDER BY sat.AvgScrMath DESC\n",
    "\"\"\"\n",
    "\n",
    "await sql_evaluator.query(f\"\"\"\n",
    "Optimize this SQL query for database 'california_schools' for better performance:\n",
    "{inefficient_sql}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Index Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test getting index suggestions\n",
    "query_needing_indexes = \"\"\"\n",
    "SELECT s.School, s.County, sat.AvgScrMath\n",
    "FROM schools s\n",
    "JOIN satscores sat ON s.CDSCode = sat.cds\n",
    "WHERE s.County = 'Alameda'\n",
    "  AND sat.AvgScrMath > 600\n",
    "ORDER BY sat.AvgScrMath DESC\n",
    "\"\"\"\n",
    "\n",
    "await sql_evaluator.query(f\"\"\"\n",
    "Suggest indexes for this SQL query on database 'california_schools':\n",
    "{query_needing_indexes}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluating query performance\n",
    "performance_test_sql = \"\"\"\n",
    "SELECT DISTINCT s.County, COUNT(*) as school_count, AVG(sat.AvgScrMath) as avg_score\n",
    "FROM schools s\n",
    "LEFT JOIN satscores sat ON s.CDSCode = sat.cds\n",
    "WHERE s.County IN (SELECT County FROM schools GROUP BY County HAVING COUNT(*) > 50)\n",
    "GROUP BY s.County\n",
    "HAVING AVG(sat.AvgScrMath) > 500\n",
    "ORDER BY avg_score DESC\n",
    "\"\"\"\n",
    "\n",
    "await sql_evaluator.query(f\"\"\"\n",
    "Evaluate the performance characteristics of this SQL query for database 'california_schools':\n",
    "{performance_test_sql}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete SQL Evaluation Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test complete evaluation workflow\n",
    "test_sql = \"\"\"\n",
    "SELECT *\n",
    "FROM schools s, satscores sat\n",
    "WHERE s.CDSCode = sat.cds\n",
    "  AND s.County = 'Los Angeles'\n",
    "\"\"\"\n",
    "\n",
    "await sql_evaluator.query(f\"\"\"\n",
    "Perform a complete evaluation of this SQL query for database 'california_schools':\n",
    "{test_sql}\n",
    "\n",
    "Please:\n",
    "1. Validate the syntax\n",
    "2. Analyze the complexity\n",
    "3. Optimize for performance\n",
    "4. Suggest indexes\n",
    "5. Evaluate performance characteristics\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connections\n",
    "await sql_evaluator.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}