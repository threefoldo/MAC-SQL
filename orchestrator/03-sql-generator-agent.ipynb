{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Generation Agent\n",
    "\n",
    "Purpose: Generates a syntactically valid and semantically plausible SQL query based on the processed natural language query part and the linked schema elements.\n",
    "\n",
    "Input:\n",
    "- processed_query_part_nl: (string) The natural language for a specific query part\n",
    "- linked_schema_elements: (list) The relevant schema elements from Agent 2\n",
    "- proposed_join_paths: (list, optional) From Agent 2\n",
    "- database_id: (string) Identifier for the target database\n",
    "- sql_dialect: (string) Specific SQL dialect (e.g., \"MySQL\", \"PostgreSQL\", \"SQLite\")\n",
    "- dependent_sub_query_results_context: (object, optional) If this query part depends on others\n",
    "- refinement_instructions: (string, optional) Specific instructions if this is a retry\n",
    "\n",
    "Output:\n",
    "- generated_sql: (string) The SQL query\n",
    "- generation_confidence: (float) Confidence that the SQL correctly represents the query part and schema\n",
    "- brief_explanation_of_sql_logic: (string) A short natural language explanation of what the SQL is intended to do\n",
    "- validation_status_self_assessed: (string) \"Presumed_Valid\", \"Potential_Issues_Noted\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import necessary modules\nimport sys\nimport os\nsys.path.append(os.path.dirname(os.path.abspath('./')))\n\nimport asyncio\nfrom typing import List, Dict, Any, Optional, Tuple\nimport json\nimport re\nimport logging\n\n# Import unified schemas\nfrom schemas import (\n    # SQL Generation types\n    SQLGenerationInput,\n    SQLGenerationOutput,\n    SchemaLinkingOutput,\n    SchemaElement,\n    JoinPath,\n    \n    # Error types\n    SQLGenerationError,\n    \n    # Database schemas\n    SCHEMAS\n)\n\nlogger = logging.getLogger(__name__)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "from autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.teams import RoundRobinGroupChat\nfrom autogen_agentchat.conditions import MaxMessageTermination\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# SQL Generation System Prompt\nSQL_GENERATOR_SYSTEM_PROMPT = \"\"\"You are an expert SQL generator. Given a natural language query part and linked schema elements,\ngenerate a syntactically valid and semantically plausible SQL query.\n\nFollow these guidelines:\n1. Use only the schema elements provided in the linked_schema_elements\n2. Pay attention to the SQL dialect specified (MySQL, PostgreSQL, SQLite)\n3. Handle joins appropriately based on proposed_join_paths\n4. If refinement_instructions are provided, incorporate them into your query\n5. Consider dependent_sub_query_results_context if provided\n6. Generate efficient and optimized SQL when possible\n7. Use appropriate SQL constructs for the query requirements\n\nFor the SQL dialect:\n- MySQL: Use DATE_SUB(CURDATE(), INTERVAL n DAY) for date arithmetic\n- PostgreSQL: Use CURRENT_DATE - INTERVAL 'n days' for date arithmetic\n- SQLite: Use date('now', '-n days') for date arithmetic\n\nAlways validate that your generated SQL:\n- Uses correct table and column names from the schema\n- Has proper JOIN conditions\n- Has correct WHERE clause syntax\n- Follows the specific dialect's syntax rules\n\nRespond in JSON format with:\n{\n  \"sql_query\": \"your generated SQL\",\n  \"confidence\": 0.0-1.0,\n  \"explanation\": \"brief explanation\",\n  \"validation_status\": \"Presumed_Valid\" or \"Potential_Issues_Noted\",\n  \"issues\": [\"list of issues if any\"]\n}\"\"\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def extract_xml_content(response: str, tag: str) -> str:\n",
    "    \"\"\"Extract content between XML tags.\"\"\"\n",
    "    pattern = f\"<{tag}>(.*?)</{tag}>\"\n",
    "    match = re.search(pattern, response, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "def format_schema_elements_for_prompt(elements: List[SchemaElement]) -> str:\n",
    "    \"\"\"Format schema elements for inclusion in the prompt.\"\"\"\n",
    "    formatted = []\n",
    "    tables_seen = set()\n",
    "    \n",
    "    for elem in elements:\n",
    "        if elem.element_type == \"table\" and elem.table_name not in tables_seen:\n",
    "            tables_seen.add(elem.table_name)\n",
    "            formatted.append(f\"TABLE: {elem.table_name} (relevance: {elem.relevance_score:.2f})\")\n",
    "        elif elem.element_type == \"column\":\n",
    "            col_info = f\"COLUMN: {elem.table_name}.{elem.column_name}\"\n",
    "            if elem.data_type:\n",
    "                col_info += f\" [{elem.data_type}]\"\n",
    "            if elem.constraints:\n",
    "                col_info += f\" {', '.join(elem.constraints)}\"\n",
    "            col_info += f\" (relevance: {elem.relevance_score:.2f})\"\n",
    "            if elem.value_examples:\n",
    "                col_info += f\" Examples: {', '.join(elem.value_examples[:3])}\"\n",
    "            formatted.append(col_info)\n",
    "    \n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "def format_join_paths_for_prompt(join_paths: List[JoinPath]) -> str:\n",
    "    \"\"\"Format join paths for inclusion in the prompt.\"\"\"\n",
    "    if not join_paths:\n",
    "        return \"No join paths provided.\"\n",
    "    \n",
    "    formatted = []\n",
    "    for join in join_paths:\n",
    "        formatted.append(\n",
    "            f\"{join.join_type} JOIN: {join.from_table}.{join.from_column} => \"\n",
    "            f\"{join.to_table}.{join.to_column} (confidence: {join.confidence:.2f})\"\n",
    "        )\n",
    "    \n",
    "    return \"\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "class SQLGenerationAgent:\n    \"\"\"Agent that generates SQL queries from natural language and schema elements.\"\"\"\n    \n    def __init__(self, config: Optional[Dict] = None):\n        \"\"\"Initialize the SQL Generation Agent.\"\"\"\n        self.config = config or {}\n        self.model = self.config.get('model', 'gpt-4o')\n        self.model_client = OpenAIChatCompletionClient(model=self.model)\n        self.max_retries = self.config.get('max_retries', 3)\n    \n    async def generate_sql(self, input_data: SQLGenerationInput) -> SQLGenerationOutput:\n        \"\"\"\n        Generate SQL query from input data.\n        \n        Args:\n            input_data: SQLGenerationInput with query and schema information\n            \n        Returns:\n            SQLGenerationOutput with generated SQL\n            \n        Raises:\n            SQLGenerationError: If generation fails\n        \"\"\"\n        try:\n            # Format the prompt\n            prompt = self._format_prompt(input_data)\n            \n            # Send to LLM\n            messages = [\n                {\"role\": \"system\", \"content\": SQL_GENERATOR_SYSTEM_PROMPT},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n            \n            response = await self.model_client.create(messages=messages)\n            content = response.choices[0].message.content\n            \n            # Parse response\n            sql_output = self._parse_response(content)\n            \n            # Validate and enhance output\n            return self._create_output(sql_output, input_data)\n            \n        except Exception as e:\n            logger.error(f\"SQL generation failed: {str(e)}\")\n            raise SQLGenerationError(f\"Failed to generate SQL: {str(e)}\")\n    \n    def _format_prompt(self, input_data: SQLGenerationInput) -> str:\n        \"\"\"Format the input data into a prompt for the LLM.\"\"\"\n        # Format schema elements\n        schema_elements_formatted = self._format_schema_elements(input_data.linked_schema.relevant_schema_elements)\n        \n        # Format join paths\n        join_paths_formatted = self._format_join_paths(input_data.linked_schema.proposed_join_paths)\n        \n        prompt = f\"\"\"Generate a SQL query for the following:\n\nQuery (Natural Language): {input_data.processed_natural_language}\n\nDatabase ID: {input_data.database_id}\nSQL Dialect: {input_data.sql_dialect}\n\nRelevant Schema Elements:\n{schema_elements_formatted}\n\nJoin Paths:\n{join_paths_formatted}\n\n\"\"\"\n        \n        # Add dependent sub-query context if provided\n        if input_data.dependent_sub_query_results:\n            prompt += f\"\"\"\nDependent Sub-Query Results:\n{json.dumps(input_data.dependent_sub_query_results, indent=2)}\n\nUse the above sub-query results in your SQL generation.\n\"\"\"\n        \n        # Add refinement instructions if provided\n        if input_data.refinement_instructions:\n            prompt += f\"\"\"\nRefinement Instructions:\n{input_data.refinement_instructions}\n\nPlease incorporate these refinements into your SQL query.\n\"\"\"\n        \n        prompt += \"\\nGenerate the SQL query based on the above information.\"\n        \n        return prompt\n    \n    def _format_schema_elements(self, elements: List[SchemaElement]) -> str:\n        \"\"\"Format schema elements for the prompt.\"\"\"\n        formatted = []\n        tables_seen = set()\n        \n        for elem in elements:\n            if elem.element_type == \"Table\" and elem.table_name not in tables_seen:\n                tables_seen.add(elem.table_name)\n                formatted.append(f\"TABLE: {elem.table_name} (relevance: {elem.relevance_score:.2f})\")\n            elif elem.element_type == \"Column\":\n                col_info = f\"COLUMN: {elem.element_name}\"\n                if elem.data_type:\n                    col_info += f\" [{elem.data_type}]\"\n                if elem.constraints:\n                    col_info += f\" {', '.join(elem.constraints)}\"\n                col_info += f\" (relevance: {elem.relevance_score:.2f})\"\n                if elem.value_examples:\n                    col_info += f\" Examples: {', '.join(str(v) for v in elem.value_examples[:3])}\"\n                formatted.append(col_info)\n        \n        return \"\\n\".join(formatted)\n    \n    def _format_join_paths(self, join_paths: List[JoinPath]) -> str:\n        \"\"\"Format join paths for the prompt.\"\"\"\n        if not join_paths:\n            return \"No join paths needed.\"\n        \n        formatted = []\n        for join in join_paths:\n            formatted.append(\n                f\"{join.join_type} JOIN: {join.join_condition} \"\n                f\"(confidence: {join.confidence:.2f})\"\n            )\n        \n        return \"\\n\".join(formatted)\n    \n    def _parse_response(self, response: str) -> Dict[str, Any]:\n        \"\"\"Parse the LLM response to extract SQL components.\"\"\"\n        try:\n            # Try to parse as JSON first\n            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n            if json_match:\n                result = json.loads(json_match.group())\n                return result\n            \n            # Fallback to structured parsing\n            sql_match = re.search(r'<sql_query>(.*?)</sql_query>', response, re.DOTALL)\n            confidence_match = re.search(r'<confidence>(.*?)</confidence>', response, re.DOTALL)\n            explanation_match = re.search(r'<explanation>(.*?)</explanation>', response, re.DOTALL)\n            validation_match = re.search(r'<validation_status>(.*?)</validation_status>', response, re.DOTALL)\n            \n            result = {\n                \"sql_query\": sql_match.group(1).strip() if sql_match else \"\",\n                \"confidence\": float(confidence_match.group(1)) if confidence_match else 0.5,\n                \"explanation\": explanation_match.group(1).strip() if explanation_match else \"\",\n                \"validation_status\": validation_match.group(1).strip() if validation_match else \"Potential_Issues_Noted\",\n                \"issues\": []\n            }\n            \n            return result\n            \n        except Exception as e:\n            logger.warning(f\"Failed to parse response: {e}\")\n            # Return a basic structure\n            return {\n                \"sql_query\": response.strip(),\n                \"confidence\": 0.3,\n                \"explanation\": \"Unable to parse structured response\",\n                \"validation_status\": \"Potential_Issues_Noted\",\n                \"issues\": [\"Failed to parse LLM response\"]\n            }\n    \n    def _create_output(self, parsed_response: Dict, input_data: SQLGenerationInput) -> SQLGenerationOutput:\n        \"\"\"Create the final output object.\"\"\"\n        # Clean and validate SQL\n        sql_query = self._clean_sql(parsed_response.get(\"sql_query\", \"\"))\n        \n        # Determine validation status\n        validation_status = parsed_response.get(\"validation_status\", \"Potential_Issues_Noted\")\n        if validation_status not in [\"Presumed_Valid\", \"Potential_Issues_Noted\"]:\n            validation_status = \"Potential_Issues_Noted\"\n        \n        # Compile issues\n        issues = parsed_response.get(\"issues\", [])\n        if not sql_query:\n            issues.append(\"Generated SQL is empty\")\n            validation_status = \"Potential_Issues_Noted\"\n        \n        # Create output\n        return SQLGenerationOutput(\n            sql_query=sql_query,\n            generation_confidence=float(parsed_response.get(\"confidence\", 0.5)),\n            brief_explanation_of_sql_logic=parsed_response.get(\"explanation\", \"\"),\n            validation_status_self_assessed=validation_status,\n            potential_issues=issues if issues else None\n        )\n    \n    def _clean_sql(self, sql: str) -> str:\n        \"\"\"Clean and format the generated SQL.\"\"\"\n        # Remove any markdown code blocks\n        sql = re.sub(r'```sql\\s*', '', sql)\n        sql = re.sub(r'```\\s*', '', sql)\n        \n        # Remove extra whitespace\n        sql = ' '.join(sql.split())\n        \n        # Ensure it ends with semicolon\n        if sql and not sql.rstrip().endswith(';'):\n            sql = sql.rstrip() + ';'\n        \n        return sql"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQL generation workflow\n",
    "\n",
    "async def generate_sql(sql_input: SQLGeneratorInput) -> SQLGeneratorOutput:\n",
    "    \"\"\"Generate SQL query from input.\"\"\"\n",
    "    \n",
    "    # Format the prompt\n",
    "    schema_elements_formatted = format_schema_elements_for_prompt(sql_input.linked_schema_elements)\n",
    "    join_paths_formatted = format_join_paths_for_prompt(sql_input.proposed_join_paths)\n",
    "    \n",
    "    prompt = f\"\"\"Generate a SQL query for the following:\n",
    "\n",
    "Query Part (Natural Language): {sql_input.processed_query_part_nl}\n",
    "\n",
    "Database ID: {sql_input.database_id}\n",
    "SQL Dialect: {sql_input.sql_dialect}\n",
    "\n",
    "Linked Schema Elements:\n",
    "{schema_elements_formatted}\n",
    "\n",
    "Proposed Join Paths:\n",
    "{join_paths_formatted}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    if sql_input.dependent_sub_query_results_context:\n",
    "        prompt += f\"\\nDependent Sub-Query Context:\\n{json.dumps(sql_input.dependent_sub_query_results_context, indent=2)}\\n\"\n",
    "    \n",
    "    if sql_input.refinement_instructions:\n",
    "        prompt += f\"\\nRefinement Instructions:\\n{sql_input.refinement_instructions}\\n\"\n",
    "    \n",
    "    prompt += \"\\nGenerate the SQL query based on the above information.\"\n",
    "    \n",
    "    # Create team with termination condition\n",
    "    termination = MaxMessageTermination(max_messages=2)\n",
    "    team = RoundRobinGroupChat([sql_generator_agent], termination_condition=termination)\n",
    "    \n",
    "    result = await team.run(prompt)\n",
    "    \n",
    "    # Parse the response\n",
    "    last_message = result.messages[-1].content\n",
    "    \n",
    "    generated_sql = extract_xml_content(last_message, \"sql_query\")\n",
    "    confidence_str = extract_xml_content(last_message, \"confidence\")\n",
    "    explanation = extract_xml_content(last_message, \"explanation\")\n",
    "    validation_status = extract_xml_content(last_message, \"validation_status\")\n",
    "    issues = extract_xml_content(last_message, \"issues_if_any\")\n",
    "    \n",
    "    # Convert confidence to float\n",
    "    try:\n",
    "        confidence = float(confidence_str)\n",
    "    except:\n",
    "        confidence = 0.5\n",
    "    \n",
    "    # Ensure validation status is valid\n",
    "    if validation_status not in [\"Presumed_Valid\", \"Potential_Issues_Noted\"]:\n",
    "        validation_status = \"Potential_Issues_Noted\" if issues else \"Presumed_Valid\"\n",
    "    \n",
    "    # Add issues to explanation if noted\n",
    "    if issues and validation_status == \"Potential_Issues_Noted\":\n",
    "        explanation += f\" [Issues: {issues}]\"\n",
    "    \n",
    "    return SQLGeneratorOutput(\n",
    "        generated_sql=generated_sql,\n",
    "        generation_confidence=confidence,\n",
    "        brief_explanation_of_sql_logic=explanation,\n",
    "        validation_status_self_assessed=validation_status\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test with simple example using new interface\nasync def test_simple_sql_generation():\n    # Create mock schema linking output\n    schema_elements = [\n        SchemaElement(\n            element_name=\"Customers\",\n            element_type=\"Table\",\n            table_name=\"Customers\",\n            relevance_score=0.9,\n            mapping_rationale=\"Query mentions customers\"\n        ),\n        SchemaElement(\n            element_name=\"Customers.CustomerName\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"CustomerName\",\n            data_type=\"VARCHAR(255)\",\n            relevance_score=0.95,\n            mapping_rationale=\"Query asks for customer names\",\n            value_examples=[\"John Smith\", \"Jane Doe\", \"Bob Johnson\"]\n        ),\n        SchemaElement(\n            element_name=\"Customers.CustomerID\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"CustomerID\",\n            data_type=\"INT\",\n            constraints=[\"PRIMARY KEY\"],\n            relevance_score=0.7,\n            mapping_rationale=\"Primary key of Customers table\"\n        )\n    ]\n    \n    linked_schema = SchemaLinkingOutput(\n        relevant_schema_elements=schema_elements,\n        proposed_join_paths=[],\n        overall_linking_confidence=0.9,\n        unresolved_elements_notes=[]\n    )\n    \n    # Create input\n    input_data = SQLGenerationInput(\n        processed_natural_language=\"Show all customer names from the customers table\",\n        linked_schema=linked_schema,\n        database_id=\"test_db\",\n        sql_dialect=\"MySQL\"\n    )\n    \n    # Initialize agent and generate SQL\n    sql_generator = SQLGenerationAgent()\n    \n    try:\n        result = await sql_generator.generate_sql(input_data)\n        \n        print(\"Generated SQL:\", result.sql_query)\n        print(\"Confidence:\", result.generation_confidence)\n        print(\"Explanation:\", result.brief_explanation_of_sql_logic)\n        print(\"Validation Status:\", result.validation_status_self_assessed)\n        if result.potential_issues:\n            print(\"Issues:\", result.potential_issues)\n        \n        return result\n    except SQLGenerationError as e:\n        print(f\"SQL generation failed: {e}\")\n        return None\n\n# Run the test\nsimple_result = await test_simple_sql_generation()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test with joins using new interface\nasync def test_join_sql_generation():\n    # Create schema elements for join scenario\n    schema_elements = [\n        SchemaElement(\n            element_name=\"Orders\",\n            element_type=\"Table\",\n            table_name=\"Orders\",\n            relevance_score=0.95,\n            mapping_rationale=\"Query mentions orders\"\n        ),\n        SchemaElement(\n            element_name=\"Customers\",\n            element_type=\"Table\",\n            table_name=\"Customers\",\n            relevance_score=0.9,\n            mapping_rationale=\"Query mentions customers\"\n        ),\n        SchemaElement(\n            element_name=\"Orders.OrderDate\",\n            element_type=\"Column\",\n            table_name=\"Orders\",\n            column_name=\"OrderDate\",\n            data_type=\"DATE\",\n            relevance_score=0.85,\n            mapping_rationale=\"Query mentions recent orders\"\n        ),\n        SchemaElement(\n            element_name=\"Orders.CustomerID\",\n            element_type=\"Column\",\n            table_name=\"Orders\",\n            column_name=\"CustomerID\",\n            data_type=\"INT\",\n            constraints=[\"FOREIGN KEY\"],\n            relevance_score=0.8\n        ),\n        SchemaElement(\n            element_name=\"Customers.CustomerName\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"CustomerName\",\n            data_type=\"VARCHAR(255)\",\n            relevance_score=0.9\n        ),\n        SchemaElement(\n            element_name=\"Customers.CustomerID\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"CustomerID\",\n            data_type=\"INT\",\n            constraints=[\"PRIMARY KEY\"],\n            relevance_score=0.8\n        )\n    ]\n    \n    # Create join paths\n    join_paths = [\n        JoinPath(\n            from_table=\"Orders\",\n            to_table=\"Customers\",\n            from_column=\"CustomerID\",\n            to_column=\"CustomerID\",\n            join_condition=\"Orders.CustomerID = Customers.CustomerID\",\n            join_type=\"INNER\",\n            confidence=0.95\n        )\n    ]\n    \n    linked_schema = SchemaLinkingOutput(\n        relevant_schema_elements=schema_elements,\n        proposed_join_paths=join_paths,\n        overall_linking_confidence=0.9,\n        unresolved_elements_notes=[]\n    )\n    \n    # Create input\n    input_data = SQLGenerationInput(\n        processed_natural_language=\"Find customer names who placed orders in the last 30 days\",\n        linked_schema=linked_schema,\n        database_id=\"test_db\",\n        sql_dialect=\"MySQL\"\n    )\n    \n    # Generate SQL\n    sql_generator = SQLGenerationAgent(config={'model': 'gpt-4o'})\n    \n    try:\n        result = await sql_generator.generate_sql(input_data)\n        \n        print(\"Generated SQL:\", result.sql_query)\n        print(\"Confidence:\", result.generation_confidence)\n        print(\"Explanation:\", result.brief_explanation_of_sql_logic)\n        print(\"Validation Status:\", result.validation_status_self_assessed)\n        \n        return result\n    except SQLGenerationError as e:\n        print(f\"SQL generation failed: {e}\")\n        return None\n\n# Run the test\njoin_result = await test_join_sql_generation()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test with refinement instructions\nasync def test_refinement_sql_generation():\n    # Reuse the join scenario schema\n    schema_elements = [\n        SchemaElement(\n            element_name=\"Orders\",\n            element_type=\"Table\",\n            table_name=\"Orders\",\n            relevance_score=0.95,\n            mapping_rationale=\"Query mentions orders\"\n        ),\n        SchemaElement(\n            element_name=\"Customers\",\n            element_type=\"Table\",\n            table_name=\"Customers\",\n            relevance_score=0.9,\n            mapping_rationale=\"Query mentions customers\"\n        ),\n        SchemaElement(\n            element_name=\"Orders.OrderDate\",\n            element_type=\"Column\",\n            table_name=\"Orders\",\n            column_name=\"OrderDate\",\n            data_type=\"DATE\",\n            relevance_score=0.85,\n            mapping_rationale=\"Query mentions recent orders\"\n        ),\n        SchemaElement(\n            element_name=\"Customers.CustomerName\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"CustomerName\",\n            data_type=\"VARCHAR(255)\",\n            relevance_score=0.9\n        )\n    ]\n    \n    join_paths = [\n        JoinPath(\n            from_table=\"Orders\",\n            to_table=\"Customers\",\n            from_column=\"CustomerID\",\n            to_column=\"CustomerID\",\n            join_condition=\"Orders.CustomerID = Customers.CustomerID\",\n            join_type=\"INNER\",\n            confidence=0.95\n        )\n    ]\n    \n    linked_schema = SchemaLinkingOutput(\n        relevant_schema_elements=schema_elements,\n        proposed_join_paths=join_paths,\n        overall_linking_confidence=0.9,\n        unresolved_elements_notes=[]\n    )\n    \n    # Create input with refinement instructions\n    input_data = SQLGenerationInput(\n        processed_natural_language=\"Find customer names who placed orders in the last 30 days\",\n        linked_schema=linked_schema,\n        database_id=\"test_db\",\n        sql_dialect=\"MySQL\",\n        refinement_instructions=\"The previous query was missing DISTINCT to avoid duplicates. Also ensure proper date formatting for MySQL using DATE_SUB.\"\n    )\n    \n    # Generate SQL\n    sql_generator = SQLGenerationAgent()\n    \n    try:\n        result = await sql_generator.generate_sql(input_data)\n        \n        print(\"Generated SQL with refinements:\", result.sql_query)\n        print(\"Confidence:\", result.generation_confidence)\n        print(\"Explanation:\", result.brief_explanation_of_sql_logic)\n        print(\"Validation Status:\", result.validation_status_self_assessed)\n        \n        return result\n    except SQLGenerationError as e:\n        print(f\"SQL generation failed: {e}\")\n        return None\n\n# Run the test\nrefinement_result = await test_refinement_sql_generation()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test with dependent sub-query context\nasync def test_dependent_sql_generation():\n    # Define dependent sub-query context\n    dependent_context = {\n        \"previous_part_result\": {\n            \"sql\": \"SELECT DISTINCT CustomerID FROM Orders WHERE OrderDate >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)\",\n            \"result_summary\": \"Returns 42 customer IDs who ordered in last 30 days\",\n            \"column_names\": [\"CustomerID\"],\n            \"sample_rows\": [[1], [2], [3]]  # First 3 rows\n        }\n    }\n    \n    # Create schema for dependent query\n    schema_elements = [\n        SchemaElement(\n            element_name=\"Customers\",\n            element_type=\"Table\",\n            table_name=\"Customers\",\n            relevance_score=0.95\n        ),\n        SchemaElement(\n            element_name=\"Customers.CustomerName\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"CustomerName\",\n            data_type=\"VARCHAR(255)\",\n            relevance_score=0.9\n        ),\n        SchemaElement(\n            element_name=\"Customers.Email\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"Email\",\n            data_type=\"VARCHAR(255)\",\n            relevance_score=0.9\n        ),\n        SchemaElement(\n            element_name=\"Customers.CustomerID\",\n            element_type=\"Column\",\n            table_name=\"Customers\",\n            column_name=\"CustomerID\",\n            data_type=\"INT\",\n            constraints=[\"PRIMARY KEY\"],\n            relevance_score=0.8\n        )\n    ]\n    \n    linked_schema = SchemaLinkingOutput(\n        relevant_schema_elements=schema_elements,\n        proposed_join_paths=[],\n        overall_linking_confidence=0.9,\n        unresolved_elements_notes=[]\n    )\n    \n    # Create input with dependent context\n    input_data = SQLGenerationInput(\n        processed_natural_language=\"Get the names and email addresses of customers from the previous query results\",\n        linked_schema=linked_schema,\n        database_id=\"test_db\",\n        sql_dialect=\"MySQL\",\n        dependent_sub_query_results=dependent_context\n    )\n    \n    # Generate SQL\n    sql_generator = SQLGenerationAgent()\n    \n    try:\n        result = await sql_generator.generate_sql(input_data)\n        \n        print(\"Generated SQL with dependencies:\", result.sql_query)\n        print(\"Confidence:\", result.generation_confidence)\n        print(\"Explanation:\", result.brief_explanation_of_sql_logic)\n        print(\"Validation Status:\", result.validation_status_self_assessed)\n        \n        return result\n    except SQLGenerationError as e:\n        print(f\"SQL generation failed: {e}\")\n        return None\n\n# Run the test\ndependent_result = await test_dependent_sql_generation()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The SQL Generator Agent is designed to:\n",
    "\n",
    "1. Generate syntactically valid SQL queries based on natural language input\n",
    "2. Use linked schema elements to construct appropriate queries\n",
    "3. Handle joins using proposed join paths\n",
    "4. Support different SQL dialects (MySQL, PostgreSQL, SQLite)\n",
    "5. Incorporate refinement instructions for iterative improvement\n",
    "6. Handle dependent sub-query contexts for complex queries\n",
    "7. Provide confidence scores and self-assessment of validation status\n",
    "8. Generate explanations of the SQL logic for transparency\n",
    "\n",
    "The agent can handle:\n",
    "- Simple SELECT queries\n",
    "- Complex queries with JOINs\n",
    "- Queries with WHERE clauses and date filtering\n",
    "- Queries that depend on previous sub-query results\n",
    "- Refinements based on feedback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}