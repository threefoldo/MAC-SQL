{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrator Agent Test\n",
    "\n",
    "This notebook implements and tests the Orchestrator Agent that plans and monitors the text-to-sql workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Any, List, Optional\n",
    "import xml.etree.ElementTree as ET\n",
    "from dataclasses import dataclass\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Import our agents\n",
    "from schema_manager import SchemaManager\n",
    "from schema_agent import SchemaAgent\n",
    "from sql_executor_agent import SQLExecutorAgent\n",
    "from sql_executor import SQLExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Orchestrator System Prompt and Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_SYSTEM_PROMPT = \"\"\"You are an Orchestrator Agent that coordinates the text-to-SQL workflow.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Analyze user queries to understand what information is needed\n",
    "2. Break down complex queries into steps\n",
    "3. Coordinate with other agents:\n",
    "   - Schema Agent: for database structure information\n",
    "   - Query Decomposer: for breaking complex queries\n",
    "   - SQL Generator: for creating SQL queries\n",
    "   - SQL Executor: for running and validating queries\n",
    "4. Monitor progress and ensure all information is collected\n",
    "5. Generate the final SQL query\n",
    "\n",
    "Workflow:\n",
    "1. Understand the user query\n",
    "2. Identify required information pieces\n",
    "3. For each piece:\n",
    "   - Get schema information\n",
    "   - Generate SQL\n",
    "   - Execute and verify\n",
    "4. Combine results for final SQL\n",
    "\n",
    "Always maintain a clear plan and track progress.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PLAN_TEMPLATE = \"\"\"Analyze the following query and create an execution plan:\n",
    "\n",
    "Database: {database_id}\n",
    "Query: {query}\n",
    "Evidence: {evidence}\n",
    "\n",
    "Create a plan that identifies:\n",
    "1. What information is needed to answer the query\n",
    "2. Which tables and columns are likely involved\n",
    "3. What relationships exist between the information\n",
    "4. The order in which to retrieve information\n",
    "\n",
    "Format your response as:\n",
    "<ExecutionPlan>\n",
    "    <QueryAnalysis>\n",
    "        <Intent>{what the user wants to find}</Intent>\n",
    "        <Complexity>{simple/complex}</Complexity>\n",
    "    </QueryAnalysis>\n",
    "    <InformationRequired>\n",
    "        <InfoPiece number=\"1\">\n",
    "            <Description>{what information is needed}</Description>\n",
    "            <PotentialTables>{tables that might contain this}</PotentialTables>\n",
    "            <Dependency>{if depends on other info pieces}</Dependency>\n",
    "        </InfoPiece>\n",
    "        ...\n",
    "    </InformationRequired>\n",
    "    <ExecutionOrder>{sequence of steps}</ExecutionOrder>\n",
    "</ExecutionPlan>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Workflow State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WorkflowState:\n",
    "    \"\"\"Tracks the state of the text-to-SQL workflow.\"\"\"\n",
    "    query: str\n",
    "    database_id: str\n",
    "    evidence: str\n",
    "    plan: Optional[Dict] = None\n",
    "    information_pieces: List[Dict] = None\n",
    "    schema_info: Dict = None\n",
    "    intermediate_results: List[Dict] = None\n",
    "    final_sql: Optional[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.information_pieces is None:\n",
    "            self.information_pieces = []\n",
    "        if self.intermediate_results is None:\n",
    "            self.intermediate_results = []\n",
    "        if self.schema_info is None:\n",
    "            self.schema_info = {}\n",
    "    \n",
    "    def add_information_piece(self, piece: Dict):\n",
    "        \"\"\"Add an information piece to track.\"\"\"\n",
    "        self.information_pieces.append(piece)\n",
    "    \n",
    "    def add_intermediate_result(self, result: Dict):\n",
    "        \"\"\"Add an intermediate SQL result.\"\"\"\n",
    "        self.intermediate_results.append(result)\n",
    "    \n",
    "    def update_schema_info(self, table: str, info: Dict):\n",
    "        \"\"\"Update schema information for a table.\"\"\"\n",
    "        self.schema_info[table] = info\n",
    "    \n",
    "    def is_complete(self) -> bool:\n",
    "        \"\"\"Check if all information pieces have been processed.\"\"\"\n",
    "        if not self.information_pieces:\n",
    "            return False\n",
    "        return all(piece.get('status') == 'complete' for piece in self.information_pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Orchestrator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrchestratorAgent:\n",
    "    \"\"\"Orchestrator agent that coordinates the text-to-SQL workflow.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 schema_agent: SchemaAgent,\n",
    "                 sql_executor_agent: SQLExecutorAgent,\n",
    "                 model: str = \"gpt-4o\"):\n",
    "        self.schema_agent = schema_agent\n",
    "        self.sql_executor_agent = sql_executor_agent\n",
    "        self.model_client = OpenAIChatCompletionClient(model=model)\n",
    "        self.agent = self._create_agent()\n",
    "        self.workflow_states: Dict[str, WorkflowState] = {}\n",
    "    \n",
    "    def _create_agent(self) -> AssistantAgent:\n",
    "        \"\"\"Create the orchestrator agent with tools.\"\"\"\n",
    "        \n",
    "        async def create_execution_plan(query: str, database_id: str, evidence: str = \"\") -> str:\n",
    "            \"\"\"Create an execution plan for the query.\"\"\"\n",
    "            # Create workflow state\n",
    "            state = WorkflowState(query=query, database_id=database_id, evidence=evidence)\n",
    "            self.workflow_states[query] = state\n",
    "            \n",
    "            # Generate plan using LLM\n",
    "            prompt = ORCHESTRATOR_PLAN_TEMPLATE.format(\n",
    "                database_id=database_id,\n",
    "                query=query,\n",
    "                evidence=evidence\n",
    "            )\n",
    "            \n",
    "            # For demo, return a simple plan\n",
    "            return self._create_sample_plan(query, database_id, evidence)\n",
    "        \n",
    "        async def get_schema_information(database_id: str, table_names: List[str]) -> str:\n",
    "            \"\"\"Get schema information for specified tables.\"\"\"\n",
    "            # Delegate to schema agent\n",
    "            results = {}\n",
    "            for table in table_names:\n",
    "                # In practice, this would call the schema agent\n",
    "                results[table] = f\"Schema info for {table}\"\n",
    "            \n",
    "            return json.dumps(results, indent=2)\n",
    "        \n",
    "        async def generate_sql_for_info(info_piece: Dict, schema_info: Dict) -> str:\n",
    "            \"\"\"Generate SQL for a specific information piece.\"\"\"\n",
    "            # In practice, delegate to SQL generation agent\n",
    "            description = info_piece.get('description', '')\n",
    "            \n",
    "            # Simple SQL generation logic for demo\n",
    "            if \"average\" in description.lower():\n",
    "                return \"SELECT AVG(column) FROM table\"\n",
    "            elif \"count\" in description.lower():\n",
    "                return \"SELECT COUNT(*) FROM table\"\n",
    "            else:\n",
    "                return \"SELECT * FROM table WHERE condition\"\n",
    "        \n",
    "        async def execute_and_verify_sql(sql: str, database_id: str) -> str:\n",
    "            \"\"\"Execute SQL and verify results.\"\"\"\n",
    "            # Delegate to SQL executor agent\n",
    "            # For demo, return success\n",
    "            return json.dumps({\n",
    "                \"success\": True,\n",
    "                \"sql\": sql,\n",
    "                \"row_count\": 10,\n",
    "                \"sample_data\": [[\"data1\"], [\"data2\"]]\n",
    "            })\n",
    "        \n",
    "        async def combine_results_for_final_sql(query: str, intermediate_results: List[Dict]) -> str:\n",
    "            \"\"\"Combine intermediate results to generate final SQL.\"\"\"\n",
    "            state = self.workflow_states.get(query)\n",
    "            if not state:\n",
    "                return \"Error: No workflow state found\"\n",
    "            \n",
    "            # In practice, use all intermediate results to build final SQL\n",
    "            final_sql = \"SELECT /* final SQL based on intermediate results */\"\n",
    "            state.final_sql = final_sql\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"final_sql\": final_sql,\n",
    "                \"based_on_results\": len(intermediate_results)\n",
    "            })\n",
    "        \n",
    "        async def monitor_workflow_progress(query: str) -> str:\n",
    "            \"\"\"Check the progress of the workflow.\"\"\"\n",
    "            state = self.workflow_states.get(query)\n",
    "            if not state:\n",
    "                return \"No workflow found for this query\"\n",
    "            \n",
    "            progress = {\n",
    "                \"query\": query,\n",
    "                \"database\": state.database_id,\n",
    "                \"total_pieces\": len(state.information_pieces),\n",
    "                \"completed_pieces\": sum(1 for p in state.information_pieces if p.get('status') == 'complete'),\n",
    "                \"has_final_sql\": state.final_sql is not None\n",
    "            }\n",
    "            \n",
    "            return json.dumps(progress, indent=2)\n",
    "        \n",
    "        # Create the agent\n",
    "        return AssistantAgent(\n",
    "            name=\"orchestrator\",\n",
    "            model_client=self.model_client,\n",
    "            tools=[\n",
    "                create_execution_plan,\n",
    "                get_schema_information,\n",
    "                generate_sql_for_info,\n",
    "                execute_and_verify_sql,\n",
    "                combine_results_for_final_sql,\n",
    "                monitor_workflow_progress\n",
    "            ],\n",
    "            system_message=ORCHESTRATOR_SYSTEM_PROMPT,\n",
    "            reflect_on_tool_use=True,\n",
    "            model_client_stream=True,\n",
    "        )\n",
    "    \n",
    "    def _create_sample_plan(self, query: str, database_id: str, evidence: str) -> str:\n",
    "        \"\"\"Create a sample execution plan for demonstration.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Analyze query complexity\n",
    "        is_complex = \"average\" in query_lower or \"youngest\" in query_lower or \"highest\" in query_lower\n",
    "        \n",
    "        info_pieces = []\n",
    "        \n",
    "        if \"average\" in query_lower and \"over\" in query_lower:\n",
    "            # Pattern: comparison with average\n",
    "            info_pieces.append({\n",
    "                \"number\": \"1\",\n",
    "                \"description\": \"Calculate the average value for comparison\",\n",
    "                \"potential_tables\": \"To be determined by schema analysis\",\n",
    "                \"dependency\": \"None\"\n",
    "            })\n",
    "            info_pieces.append({\n",
    "                \"number\": \"2\",\n",
    "                \"description\": \"Find items that exceed the average\",\n",
    "                \"potential_tables\": \"Same as piece 1\",\n",
    "                \"dependency\": \"Piece 1\"\n",
    "            })\n",
    "        elif any(word in query_lower for word in [\"youngest\", \"oldest\", \"highest\", \"lowest\"]):\n",
    "            info_pieces.append({\n",
    "                \"number\": \"1\",\n",
    "                \"description\": \"Find the extreme value (min/max)\",\n",
    "                \"potential_tables\": \"To be determined\",\n",
    "                \"dependency\": \"None\"\n",
    "            })\n",
    "            info_pieces.append({\n",
    "                \"number\": \"2\",\n",
    "                \"description\": \"Get detailed information for the extreme case\",\n",
    "                \"potential_tables\": \"Same as piece 1\",\n",
    "                \"dependency\": \"Piece 1\"\n",
    "            })\n",
    "        else:\n",
    "            # Simple query\n",
    "            info_pieces.append({\n",
    "                \"number\": \"1\",\n",
    "                \"description\": \"Direct query execution\",\n",
    "                \"potential_tables\": \"To be determined\",\n",
    "                \"dependency\": \"None\"\n",
    "            })\n",
    "        \n",
    "        # Format as XML\n",
    "        pieces_xml = \"\"\n",
    "        for piece in info_pieces:\n",
    "            pieces_xml += f\"\"\"\n",
    "        <InfoPiece number=\"{piece['number']}\">\n",
    "            <Description>{piece['description']}</Description>\n",
    "            <PotentialTables>{piece['potential_tables']}</PotentialTables>\n",
    "            <Dependency>{piece['dependency']}</Dependency>\n",
    "        </InfoPiece>\"\"\"\n",
    "        \n",
    "        plan_xml = f\"\"\"<ExecutionPlan>\n",
    "    <QueryAnalysis>\n",
    "        <Intent>Find {query}</Intent>\n",
    "        <Complexity>{'complex' if is_complex else 'simple'}</Complexity>\n",
    "    </QueryAnalysis>\n",
    "    <InformationRequired>{pieces_xml}\n",
    "    </InformationRequired>\n",
    "    <ExecutionOrder>Sequential execution from piece 1 to {len(info_pieces)}</ExecutionOrder>\n",
    "</ExecutionPlan>\"\"\"\n",
    "        \n",
    "        # Update workflow state\n",
    "        state = self.workflow_states[query]\n",
    "        state.plan = {\"xml\": plan_xml, \"info_pieces\": info_pieces}\n",
    "        for piece in info_pieces:\n",
    "            state.add_information_piece({**piece, \"status\": \"pending\"})\n",
    "        \n",
    "        return plan_xml\n",
    "    \n",
    "    async def query(self, task: str) -> None:\n",
    "        \"\"\"Run a query against the orchestrator agent.\"\"\"\n",
    "        await Console(self.agent.run_stream(task=task))\n",
    "    \n",
    "    async def close(self) -> None:\n",
    "        \"\"\"Close the model client connection.\"\"\"\n",
    "        await self.model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "data_path = \"../data/bird/dev_databases\"\n",
    "tables_json_path = \"../data/bird/dev_tables.json\"\n",
    "dataset_name = \"bird\"\n",
    "\n",
    "# Create schema manager\n",
    "schema_manager = SchemaManager(\n",
    "    data_path=data_path,\n",
    "    tables_json_path=tables_json_path,\n",
    "    dataset_name=dataset_name,\n",
    "    lazy=True\n",
    ")\n",
    "\n",
    "# Create SQL executor\n",
    "sql_executor = SQLExecutor(\n",
    "    data_path=data_path,\n",
    "    dataset_name=dataset_name\n",
    ")\n",
    "\n",
    "# Create agents\n",
    "schema_agent = SchemaAgent(schema_manager)\n",
    "sql_executor_agent = SQLExecutorAgent(sql_executor)\n",
    "\n",
    "# Create orchestrator\n",
    "orchestrator = OrchestratorAgent(schema_agent, sql_executor_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Orchestrator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a simple query\n",
    "simple_task = \"\"\"Process this query for database 'california_schools':\n",
    "Query: Show all schools in Alameda county\n",
    "\"\"\"\n",
    "\n",
    "await orchestrator.query(simple_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a complex query\n",
    "complex_task = \"\"\"Process this query for database 'california_schools':\n",
    "Query: List school names of charter schools with an SAT excellence rate over the average\n",
    "Evidence: Charter schools refers to `Charter School (Y/N)` = 1; Excellence rate = NumGE1500 / NumTstTakr\n",
    "\"\"\"\n",
    "\n",
    "await orchestrator.query(complex_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the full workflow\n",
    "workflow_task = \"\"\"Execute the complete workflow for this query:\n",
    "Database: california_schools\n",
    "Query: Find the average SAT score for charter schools in counties with more than 100 schools\n",
    "Evidence: Charter schools have `Charter School (Y/N)` = 1\n",
    "\n",
    "Please:\n",
    "1. Create an execution plan\n",
    "2. Get schema information for relevant tables\n",
    "3. Generate SQL for each information piece\n",
    "4. Execute and verify the SQL\n",
    "5. Combine results for final SQL\n",
    "6. Monitor progress throughout\n",
    "\"\"\"\n",
    "\n",
    "await orchestrator.query(workflow_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Orchestrator with Real Agent Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedOrchestratorAgent(OrchestratorAgent):\n",
    "    \"\"\"Enhanced orchestrator with real agent integration.\"\"\"\n",
    "    \n",
    "    def _create_agent(self) -> AssistantAgent:\n",
    "        \"\"\"Create the enhanced orchestrator agent.\"\"\"\n",
    "        \n",
    "        async def create_execution_plan(query: str, database_id: str, evidence: str = \"\") -> str:\n",
    "            \"\"\"Create an execution plan for the query.\"\"\"\n",
    "            state = WorkflowState(query=query, database_id=database_id, evidence=evidence)\n",
    "            self.workflow_states[query] = state\n",
    "            \n",
    "            # Use the actual model to create the plan\n",
    "            prompt = ORCHESTRATOR_PLAN_TEMPLATE.format(\n",
    "                database_id=database_id,\n",
    "                query=query,\n",
    "                evidence=evidence\n",
    "            )\n",
    "            \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": ORCHESTRATOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "            \n",
    "            response = await self.model_client.create(messages=messages)\n",
    "            plan_xml = response.choices[0].message.content\n",
    "            \n",
    "            # Parse and store the plan\n",
    "            self._parse_and_store_plan(query, plan_xml)\n",
    "            \n",
    "            return plan_xml\n",
    "        \n",
    "        async def execute_workflow_step(query: str, step_number: int) -> str:\n",
    "            \"\"\"Execute a specific step in the workflow.\"\"\"\n",
    "            state = self.workflow_states.get(query)\n",
    "            if not state:\n",
    "                return \"Error: No workflow state found\"\n",
    "            \n",
    "            if step_number > len(state.information_pieces):\n",
    "                return \"Error: Invalid step number\"\n",
    "            \n",
    "            info_piece = state.information_pieces[step_number - 1]\n",
    "            \n",
    "            # 1. Get schema information\n",
    "            tables = info_piece.get('potential_tables', [])\n",
    "            if isinstance(tables, str):\n",
    "                tables = [tables]\n",
    "            \n",
    "            schema_result = await self.schema_agent.agent.run(\n",
    "                f\"Get schema information for tables: {tables} in database {state.database_id}\"\n",
    "            )\n",
    "            \n",
    "            # 2. Generate SQL\n",
    "            sql_prompt = f\"\"\"\n",
    "            Generate SQL for: {info_piece['description']}\n",
    "            Database: {state.database_id}\n",
    "            Schema: {schema_result}\n",
    "            Evidence: {state.evidence}\n",
    "            \"\"\"\n",
    "            \n",
    "            sql_result = await self.model_client.create(\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Generate SQL based on the requirements\"},\n",
    "                    {\"role\": \"user\", \"content\": sql_prompt}\n",
    "                ]\n",
    "            )\n",
    "            sql = sql_result.choices[0].message.content\n",
    "            \n",
    "            # 3. Execute SQL\n",
    "            exec_result = await self.sql_executor_agent.agent.run(\n",
    "                f\"Execute this SQL on database {state.database_id}: {sql}\"\n",
    "            )\n",
    "            \n",
    "            # Update state\n",
    "            info_piece['status'] = 'complete'\n",
    "            info_piece['sql'] = sql\n",
    "            info_piece['result'] = exec_result\n",
    "            \n",
    "            state.add_intermediate_result({\n",
    "                \"step\": step_number,\n",
    "                \"sql\": sql,\n",
    "                \"result\": exec_result\n",
    "            })\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"step\": step_number,\n",
    "                \"status\": \"complete\",\n",
    "                \"sql\": sql,\n",
    "                \"result_summary\": \"Execution successful\"\n",
    "            }, indent=2)\n",
    "        \n",
    "        # Create the enhanced agent\n",
    "        return AssistantAgent(\n",
    "            name=\"enhanced_orchestrator\",\n",
    "            model_client=self.model_client,\n",
    "            tools=[\n",
    "                create_execution_plan,\n",
    "                execute_workflow_step,\n",
    "                self.monitor_workflow_progress,\n",
    "                self.generate_final_sql\n",
    "            ],\n",
    "            system_message=ORCHESTRATOR_SYSTEM_PROMPT,\n",
    "            reflect_on_tool_use=True,\n",
    "            model_client_stream=True,\n",
    "        )\n",
    "    \n",
    "    def _parse_and_store_plan(self, query: str, plan_xml: str):\n",
    "        \"\"\"Parse the execution plan XML and store in workflow state.\"\"\"\n",
    "        try:\n",
    "            root = ET.fromstring(plan_xml)\n",
    "            state = self.workflow_states[query]\n",
    "            \n",
    "            # Parse information pieces\n",
    "            for info_elem in root.findall('.//InfoPiece'):\n",
    "                piece = {\n",
    "                    \"number\": info_elem.get('number'),\n",
    "                    \"description\": info_elem.find('Description').text,\n",
    "                    \"potential_tables\": info_elem.find('PotentialTables').text,\n",
    "                    \"dependency\": info_elem.find('Dependency').text,\n",
    "                    \"status\": \"pending\"\n",
    "                }\n",
    "                state.add_information_piece(piece)\n",
    "            \n",
    "            state.plan = {\"xml\": plan_xml, \"parsed\": True}\n",
    "        except Exception as e:\n",
    "            state.plan = {\"xml\": plan_xml, \"parsed\": False, \"error\": str(e)}\n",
    "    \n",
    "    async def monitor_workflow_progress(self, query: str) -> str:\n",
    "        \"\"\"Monitor the progress of the workflow.\"\"\"\n",
    "        state = self.workflow_states.get(query)\n",
    "        if not state:\n",
    "            return \"No workflow found for this query\"\n",
    "        \n",
    "        progress = {\n",
    "            \"query\": query,\n",
    "            \"database\": state.database_id,\n",
    "            \"plan_created\": state.plan is not None,\n",
    "            \"total_steps\": len(state.information_pieces),\n",
    "            \"completed_steps\": sum(1 for p in state.information_pieces if p.get('status') == 'complete'),\n",
    "            \"intermediate_results\": len(state.intermediate_results),\n",
    "            \"has_final_sql\": state.final_sql is not None\n",
    "        }\n",
    "        \n",
    "        # Add details for each step\n",
    "        step_details = []\n",
    "        for i, piece in enumerate(state.information_pieces):\n",
    "            step_details.append({\n",
    "                \"step\": i + 1,\n",
    "                \"description\": piece['description'],\n",
    "                \"status\": piece['status']\n",
    "            })\n",
    "        progress[\"step_details\"] = step_details\n",
    "        \n",
    "        return json.dumps(progress, indent=2)\n",
    "    \n",
    "    async def generate_final_sql(self, query: str) -> str:\n",
    "        \"\"\"Generate the final SQL based on all intermediate results.\"\"\"\n",
    "        state = self.workflow_states.get(query)\n",
    "        if not state:\n",
    "            return \"Error: No workflow state found\"\n",
    "        \n",
    "        if not state.is_complete():\n",
    "            return \"Error: Not all steps are complete\"\n",
    "        \n",
    "        # Combine all intermediate results\n",
    "        context = {\n",
    "            \"original_query\": state.query,\n",
    "            \"database\": state.database_id,\n",
    "            \"evidence\": state.evidence,\n",
    "            \"steps\": []\n",
    "        }\n",
    "        \n",
    "        for i, result in enumerate(state.intermediate_results):\n",
    "            context[\"steps\"].append({\n",
    "                \"step\": i + 1,\n",
    "                \"description\": state.information_pieces[i]['description'],\n",
    "                \"sql\": result['sql'],\n",
    "                \"result\": result['result']\n",
    "            })\n",
    "        \n",
    "        # Generate final SQL\n",
    "        final_prompt = f\"\"\"\n",
    "        Based on the following intermediate results, generate the final SQL query:\n",
    "        \n",
    "        Original Query: {context['original_query']}\n",
    "        Database: {context['database']}\n",
    "        Evidence: {context['evidence']}\n",
    "        \n",
    "        Intermediate Steps:\n",
    "        {json.dumps(context['steps'], indent=2)}\n",
    "        \n",
    "        Generate the final SQL that answers the original query.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.model_client.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a SQL expert. Generate the final SQL based on intermediate results.\"},\n",
    "                {\"role\": \"user\", \"content\": final_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        final_sql = response.choices[0].message.content\n",
    "        state.final_sql = final_sql\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"final_sql\": final_sql,\n",
    "            \"based_on_steps\": len(state.intermediate_results)\n",
    "        }, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced orchestrator\n",
    "enhanced_orchestrator = EnhancedOrchestratorAgent(schema_agent, sql_executor_agent)\n",
    "\n",
    "# Test with a complete workflow\n",
    "await enhanced_orchestrator.query(\"\"\"\n",
    "Complete workflow for this query:\n",
    "Database: california_schools\n",
    "Query: List school names of charter schools with an SAT excellence rate over the average\n",
    "Evidence: Charter schools refers to `Charter School (Y/N)` = 1; Excellence rate = NumGE1500 / NumTstTakr\n",
    "\n",
    "Execute all steps:\n",
    "1. Create execution plan\n",
    "2. Execute each workflow step\n",
    "3. Monitor progress\n",
    "4. Generate final SQL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connections\n",
    "await orchestrator.close()\n",
    "await enhanced_orchestrator.close()\n",
    "await schema_agent.close()\n",
    "await sql_executor_agent.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}